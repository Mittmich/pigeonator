{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"../train_model/raw_data/digits/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dir):\n",
    "    image_arrays = []\n",
    "    labels = []\n",
    "    for i in range(10):\n",
    "        label = i\n",
    "        images = os.listdir(dir + str(i))\n",
    "        for image in images:\n",
    "            img = Image.open(dir + str(i) + '/' + image)\n",
    "            array = np.array(img)\n",
    "            grey = cv2.cvtColor(array, cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(grey, (50, 32))\n",
    "            image_arrays.append(resized.flatten())\n",
    "            labels.append(label)\n",
    "    return np.vstack(image_arrays), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_dataset(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish basline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_downsample(dir):\n",
    "    image_arrays = []\n",
    "    labels = []\n",
    "    for i in range(10):\n",
    "        label = i\n",
    "        images = os.listdir(dir + str(i))\n",
    "        for image in images:\n",
    "            img = Image.open(dir + str(i) + '/' + image)\n",
    "            array = np.array(img)\n",
    "            grey = cv2.cvtColor(array, cv2.COLOR_BGR2GRAY)\n",
    "            resized = cv2.resize(grey, (32, 50))\n",
    "            image_arrays.append(resized.flatten())\n",
    "            labels.append(label)\n",
    "    return np.vstack(image_arrays), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_dataset_downsample(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21621e02bf0>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].reshape(50, 32), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test, x_train, x_test = train_test_split(labels, images, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, clf.predict(scaler.transform(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "ConfusionMatrixDisplay.from_estimator(clf, scaler.transform(x_test), y_test, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks very good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try color info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_w_color(dir):\n",
    "    image_arrays = []\n",
    "    labels = []\n",
    "    for i in range(10):\n",
    "        label = i\n",
    "        images = os.listdir(dir + str(i))\n",
    "        for image in images:\n",
    "            img = Image.open(dir + str(i) + '/' + image)\n",
    "            array = np.array(img)\n",
    "            resized = cv2.resize(array, (8, 16))\n",
    "            image_arrays.append(resized.flatten())\n",
    "            labels.append(label)\n",
    "    return np.vstack(image_arrays), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_dataset_w_color(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 384)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test, x_train, x_test = train_test_split(labels, images, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, clf.predict(scaler.transform(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "ConfusionMatrixDisplay.from_estimator(clf, scaler.transform(x_test), y_test, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(clf, scaled, y_train, cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9762179487179488"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try edge detection filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_w_color(dir):\n",
    "    image_arrays = []\n",
    "    labels = []\n",
    "    for i in range(10):\n",
    "        label = i\n",
    "        images = os.listdir(dir + str(i))\n",
    "        for image in images:\n",
    "            img = Image.open(dir + str(i) + '/' + image)\n",
    "            array = np.array(img)\n",
    "            # blur\n",
    "            blurred = cv2.GaussianBlur(array, (5, 5), 0)\n",
    "            # canny edge detection\n",
    "            edges = cv2.Canny(blurred, 100, 200)\n",
    "            edges_resized = cv2.resize(edges, (12, 20)).flatten()\n",
    "            resized = cv2.resize(array, (12, 20)).flatten()\n",
    "            image_vector = np.concatenate((edges_resized, resized))\n",
    "            image_arrays.append(image_vector)\n",
    "            labels.append(label)\n",
    "    return np.vstack(image_arrays), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, laels = load_dataset_w_color(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 960)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test, x_train, x_test = train_test_split(labels, images, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, clf.predict(scaler.transform(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAAMeCAYAAAB1Exl6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB2NklEQVR4nO3daXgUZdr28bOTkA3SDYFACARMQFbZRGUQFHxEkMdBcEGHFx/ABWYUHBFBYZRNxKjjwigKruACAjMqKjoooCCMqKyCgGEJkiCEgEA6CZClu94PDK0tW0JSVKXr/zuOOma6urr7OlOAufq+6y6XYRiGAAAAAKCChVldAAAAAIDQRLMBAAAAwBQ0GwAAAABMQbMBAAAAwBQ0GwAAAABMQbMBAAAAwBQ0GwAAAABMQbMBAAAAwBQRVhcAAAAAWOXYsWMqKiqyuoyTREZGKjo62uoyyo1mAwAAAI507NgxpTSspuwcn9WlnCQxMVE7d+6s9A0HzQYAAAAcqaioSNk5Pu1ac4Hccfa5usCb51fD9j+pqKiIZgMAAACozNxxYXLHhVtdRkii2QAAAICj+WXIL7/VZQT4ZVhdQoWxz3gRAAAAgJBCswEAAADAFEyjAgAAgKP5DL98Npq55DPsM6WrvBjZAAAAAGAKmg0AAAAApmAaFQAAABzt+GpU9plHZadayouRDQAAAACmoNkAAAAAYAqmUQEAAMDR/La6pZ9sVk35MLIBAAAAwBQ0GwAAAABMwTQqAAAAOJrPMOQz7LMClJ1qKS9GNgAAAACYgmYDAAAAgCmYRgUAAABH46Z+5mFkAwAAAIApaDYAAAAAmIJpVAAAAHA0vwz5bDR1iWlUAAAAAHAWNBsAAAAATME0KgAAADgaq1GZh5ENAAAAAKag2QAAAABgCqZRAQAAwNF8hiGfYZ+pS3aqpbwY2QAAAABgCpoNAAAAAKZgGhUAAAAczf/fzS7sVEt5MbIBAAAAwBQ0GwAAAEAllpaWpksvvVRxcXGqXbu2+vTpo/T09KBjjh07pqFDh6pmzZqqVq2abrrpJu3bt++M72sYhsaNG6e6desqJiZG3bp107Zt28pUG80GAAAAHM0nw3ZbWSxbtkxDhw7VN998o0WLFqm4uFjdu3dXQUFB4Jj7779fH3/8sf75z39q2bJl2rNnj2688cYzvu9TTz2l559/XtOnT9e3336rqlWrqkePHjp27Fipa3MZRgitrQUAAACUktfrlcfj0aYttRUXZ5/v4PPy/GrZPEe5ublyu91lfv3+/ftVu3ZtLVu2TFdeeaVyc3OVkJCg2bNn6+abb5Yk/fjjj2revLlWrlypP/zhDye9h2EYSkpK0gMPPKCRI0dKknJzc1WnTh3NnDlTf/rTn0pVi31+qgAAAAACvF5v0FZYWFiq1+Xm5kqS4uPjJUlr1qxRcXGxunXrFjimWbNmatCggVauXHnK99i5c6eys7ODXuPxeNShQ4fTvuZUaDYAAADgaD7DfpskJScny+PxBLa0tLSzZvH7/Ro+fLg6deqkiy66SJKUnZ2tyMhIVa9ePejYOnXqKDs7+5Tvc2J/nTp1Sv2aU2HpWwAAAMCGsrKygqZRRUVFnfU1Q4cO1Q8//KAVK1aYWVqpMbIBAAAA2JDb7Q7aztZsDBs2TAsWLNCXX36p+vXrB/YnJiaqqKhIhw8fDjp+3759SkxMPOV7ndj/+xWrzvSaU6HZAAAAgKP5bbiVhWEYGjZsmD744AN98cUXSklJCXq+ffv2qlKlipYsWRLYl56erszMTHXs2PGU75mSkqLExMSg13i9Xn377benfc2p0GwAAAAAldjQoUP1zjvvaPbs2YqLi1N2drays7N19OhRSccv7L7zzjs1YsQIffnll1qzZo1uv/12dezYMWglqmbNmumDDz6QJLlcLg0fPlyPPfaYPvroI23cuFEDBgxQUlKS+vTpU+rauGYDAAAAqMSmTZsmSeratWvQ/hkzZmjQoEGSpOeee05hYWG66aabVFhYqB49euill14KOj49PT2wkpUkPfjggyooKNCQIUN0+PBhde7cWQsXLlR0dHSpa+M+GwAAAHCkE/fZWLu5jqrZ6D4b+Xl+Xdxi3znfZ8NO7PNTBQAAABBSaDYAAAAAmIJrNgAAAOBofuP4Zhd2qqW8GNkAAAAAYAqaDQAAAACmYBoVAAAAHM0nl3xyWV1GgJ1qKS9GNgAAAACYgmYDAAAAgCmYRgUAAABHYxqVeRjZAAAAAGAKmg0AAAAApmAaFQAAABzNb7jkN+wzdclOtZQXIxsAAAAATEGzAQAAAMAUTKMCAACAo7EalXkY2QAAAABgCpoNAAAAAKZgGhUAAAAczacw+Wz0HbzP6gIqkH1+qgAAAABCCs0GAAAAAFMwjQoAAACOZtjspn6GjWopL0Y2AAAAAJiCZgMAAACAKZhGBQAAAEfjpn7mYWQDAAAAgCloNgAAAACYgmlUAAAAcDSfESafYZ/v4H2G1RVUHPv8VAEAAACEFJoNAAAAAKZgGhUAAAAczS+X/Db6Dt6v0JlHZZ+fKgAAAICQUqlHNvx+v/bs2aO4uDi5XKGzHjEAAECoMAxDeXl5SkpKUlgY33M7TaVuNvbs2aPk5GSrywAAAMBZZGVlqX79+laXcUrc1M88lbrZiIuLkyTN+/oCxVZzVqf8dOtWVpcAAABwViUq1gp9Gvi9Dc5SqZuNE1OnYquFqWqcs5qNCFcVq0sAAAA4u/9e68yUd2eq1M0GAAAAUF72u6kfq1EBAAAAwBnRbAAAAAAwBdOoAAAA4GjHb+pnn2tK7FRLeTGyAQAAAMAUNBsAAAAATME0KgAAADiaX2Hy2eg7eL9YjQoAAAAAzohmAwAAAIApmEYFAAAAR+Omfuaxz08VAAAAQEih2QAAAABgCqZRAQAAwNH8CpPfRt/BsxoVAAAAAJwFzQYAAAAAUzCNCgAAAI7mM1zyGS6rywiwUy3lxcgGAAAAAFPQbAAAAAAwBdOoAAAA4Gg+hclno+/gfaxGBQAAAABnRrMBAAAAwBRMowIAAICj+Y0w+Q37fAfvN0JnGhXNxllkfldVK1+prewfYpWfU0U3T9+ppt1zA8/n74/Ql08lKWN5nI55w9Xgsnz1GL9b8SlFFlZtnl6DDujmu3MUn1CijM0xeumRekpfH2t1WaYjN7nJHbrITW5yA+axTwtnU0VHwlSn+VH1mLj7pOcMQ/rXX1J0KDNSfV/O0F0L0uWpV6RZ/9dYRUdC70fb5fpDGjJ+j2Y9m6ihPZooY3O0Js/OkKdmsdWlmYrc5CZ36CI3uckNmMsWvxG/+OKLuuCCCxQdHa0OHTrou+++s7qkgMZd89T1gWw165F70nMHd0bp53VV1XPSbiW1OaqaqYXqOWm3Sgpd2vRx9fNfrMluHHJAC2fH6/O58crcFq3nH6qvwqMu9eh30OrSTEVucpM7dJGb3OSG9OtqVHbaQoXlSebOnasRI0Zo/PjxWrt2rdq0aaMePXooJyfH6tLOyld0/O6OEVH+wD5XmBQeaWj36mpWlWWKiCp+Xdj6iNYujwvsMwyX1i2PU4v2RyyszFzkJje5yR1qyE1uJ+SGfVjebDz77LMaPHiwbr/9drVo0ULTp09XbGys3njjDatLO6uajY7JnVSkL/9eV0dzw+Urcunr6bWVtzdS+TmhdTmMO96n8Ajp8P7gXIcORKhGQolFVZmP3OSWyB2qyE1uidyA2Sz9jbioqEhr1qzRmDFjAvvCwsLUrVs3rVy58qTjCwsLVVhYGHjs9XrPS52nE15FunnaTi0Y3UDPtmslV7ihlE55atTFG0K3YgEAAAhtfkk+w2V1GQH+sx9SaVjabBw4cEA+n0916tQJ2l+nTh39+OOPJx2flpamiRMnnq/ySqVuq6Ma/Em6jnnD5Ct2qWpNn2bccKHqtgqtoUnvwXD5SqTqv/sWpEatEh3aH1qjOL9FbnJL5A5V5Ca3RG7AbJZPoyqLMWPGKDc3N7BlZWVZXVJAtNuvqjV9OrgzUns3xqrJNdaOulS0kuIwbdsQq3ad8wL7XC5DbTvna/Oa0F06j9zkJje5Qw25ye2E3LAPS1vaWrVqKTw8XPv27Qvav2/fPiUmJp50fFRUlKKios5XeZKkooIwHdz162cezopU9uYYxXhK5KlXrC2fehQb75M7qUg56dFa9Gh9NbkmV6lX5J3hXSun91+ppZFTsrT1+1ilr4vVDYP3KzrWr8/nxFtdmqnITW5yhy5yk5vckCS/wuS30XfwdqqlvCxtNiIjI9W+fXstWbJEffr0kST5/X4tWbJEw4YNs7K0gL0bY/XO/2sceLx4cj1JUuubDqrX3zOVn1NFiybXU8GBCFVLKFGrGw/qimH7Tvd2ldqyj2rIU9OnAaOyVSOhRBmbYvRw/xQdPlDF6tJMRW5ykzt0kZvc5AbM5TIMa++HPnfuXA0cOFAvv/yyLrvsMk2ZMkXz5s3Tjz/+eNK1HL/n9Xrl8Xi0YEOqqsaFTgdYGpNT21pdAgAAwFmVGMVaqg+Vm5srt9ttdTlBTvwuOW3tpYqpZp9rWI7ml+jui1fZ8mdWVpb/VG+99Vbt379f48aNU3Z2ttq2bauFCxeetdEAAAAAKoLPCJPPsM8X13aqpbwsbzYkadiwYbaZNgUAAACgYoRO2wQAAADAVmwxsgEAAABYxS+X/LLTTf3sU0t5MbIBAAAAwBQ0GwAAAABMwTQqAAAAOBqrUZkndJIAAAAAsBWaDQAAAACmYBoVAAAAHM2nMPls9B28nWopr9BJAgAAAMBWaDYAAAAAmIJpVAAAAHA0v+GS37DPjfTsVEt5MbIBAAAAVHJfffWVevXqpaSkJLlcLs2fPz/oeZfLdcrt73//+2nfc8KECScd36xZszLVRbMBAAAAVHIFBQVq06aNXnzxxVM+v3fv3qDtjTfekMvl0k033XTG923ZsmXQ61asWFGmuphGBQAAAEfz22w1Kv851NKzZ0/17NnztM8nJiYGPf7www911VVXKTU19YzvGxERcdJry8I+P1UAAAAAAV6vN2grLCyskPfdt2+fPvnkE915551nPXbbtm1KSkpSamqq+vfvr8zMzDJ9Fs0GAAAAYEPJycnyeDyBLS0trULe980331RcXJxuvPHGMx7XoUMHzZw5UwsXLtS0adO0c+dOXXHFFcrLyyv1ZzGNCgAAAI7mN8LkN+zzHfyJWrKysuR2uwP7o6KiKuT933jjDfXv31/R0dFnPO6307Jat26tDh06qGHDhpo3b16pRkUkmg0AAADAltxud1CzURGWL1+u9PR0zZ07t8yvrV69upo0aaLt27eX+jX2aeEAAAAAmOr1119X+/bt1aZNmzK/Nj8/Xzt27FDdunVL/RqaDQAAADiaTy7bbWWVn5+v9evXa/369ZKknTt3av369UEXdHu9Xv3zn//UXXfddcr3uPrqqzV16tTA45EjR2rZsmX66aef9PXXX+uGG25QeHi4+vXrV+q6mEYFAAAAVHKrV6/WVVddFXg8YsQISdLAgQM1c+ZMSdKcOXNkGMZpm4UdO3bowIEDgce7d+9Wv3799MsvvyghIUGdO3fWN998o4SEhFLXRbMBAAAAVHJdu3aVYRhnPGbIkCEaMmTIaZ//6aefgh7PmTOn3HXRbAAAAMDR7LoaVSgIiWbj6datFOGqYnUZ59WrmWW7VXyoGNygs9UlAAAAoJRCp20CAAAAYCshMbIBAAAAnCufdE4rQJnFZ3UBFYiRDQAAAACmoNkAAAAAYAqmUQEAAMDRWI3KPKGTBAAAAICt0GwAAAAAMAXTqAAAAOBoPiNMPhtNXbJTLeUVOkkAAAAA2ArNBgAAAABTMI0KAAAAjmbIJb+Nbupn2KiW8mJkAwAAAIApaDYAAAAAmIJpVAAAAHA0VqMyT+gkAQAAAGArNBsAAAAATME0KgAAADia33DJb9hnBSg71VJejGwAAAAAMAXNBgAAAABTMI0KAAAAjuZTmHw2+g7eTrWUV+gkAQAAAGArNBsAAAAATME0KgAAADgaq1GZh5ENAAAAAKag2QAAAABgCqZRnaNegw7o5rtzFJ9QoozNMXrpkXpKXx9rdVkV4tOp9bV2YU1l74hRZLRfjdrn6aYxPymx0dHAMcXHXJr3WIpWfZSgkqIwtexySP0f2yF3QrGFlZsnlM/3mZCb3OQOXeQmtxNyl5ZfYfLb6Dt4O9VSXqGT5Dzqcv0hDRm/R7OeTdTQHk2UsTlak2dnyFMzNH7R3vqtR1cN3Ksx8zfo/lmb5Ctx6bnbWqrwyK9/XOY+mqoNi+P152k/atS8DTq8L1IvDWluYdXmCfXzfTrkJje5Qxe5ye2E3LAHS5uNr776Sr169VJSUpJcLpfmz59vZTmlduOQA1o4O16fz41X5rZoPf9QfRUedalHv4NWl1Yhhr+9SZ365qhe0yNKblGg25/ZqoM/R2vXxmqSpCPecK2YW0e3jN2p5p1y1bB1gQY9vU071ri1Y22cxdVXvFA/36dDbnKTO3SRm9xOyA17sLTZKCgoUJs2bfTiiy9aWUaZRFTx68LWR7R2+a+/VBuGS+uWx6lF+yMWVmaeo3nHZ9tVrV4iSdq1sZp8xWFq3vlw4Ji6jY8qvt4xZYRYs+HE8y2Rm9zkJnfoIbezcpeVz3DZbgsVll6z0bNnT/Xs2dPKEsrMHe9TeIR0eH/wj+7QgQglNy60qCrz+P3SnAmpanxJruo1Pf6Pknd/pCIi/Yr1+IKOddcqVm5OpBVlmsZp5/sEcpNbIneoIje5pdDPDfuoVBeIFxYWqrDw178YXq/XwmqcYfYjjbRna6wefG+D1aUAAACgkqlUF4inpaXJ4/EEtuTk5PNeg/dguHwlUvWEkqD9NWqV6ND+StW7ndXssanasCReD8zZqPi6RYH97oQilRSF6UhueNDx3gNV5Kld9Pu3qdScdL5/i9zklsgdqshNbin0c5fViZv62WkLFZWq2RgzZoxyc3MDW1ZW1nmvoaQ4TNs2xKpd57zAPpfLUNvO+dq8JjSWkDOM443GuoU19cCcjUpoEDzM2rBVvsKr+LXlP9UD+7J3xOjgz9FKvThPocQJ5/tUyE1ucpM71JDbWblhH5WqpY2KilJUVJTVZej9V2pp5JQsbf0+VunrYnXD4P2KjvXr8znxVpdWIWY/0kjffpigoa9tVnRVn3JzqkiSYtw+RUb7Fev2qfOt+zRvUoqqVi9RTLUSvTu+kRq196pRiDUbUuif79MhN7nJHbrITW4n5IY9VKpmwy6WfVRDnpo+DRiVrRoJJcrYFKOH+6fo8IEqVpdWIZa+XVeS9PQtrYP2D3pmqzr1zZEk3TouQ66wFE37c7Ogm/qFolA/36dDbnKTO3SRm9xOyF0WhhEmv2GfCT+GjWopL5dhGIZVH56fn6/t27dLktq1a6dnn31WV111leLj49WgQYOzvt7r9crj8aireivC5ay/MK9mrrC6BEsMbtDZ6hIAAEAZlBjFWqoPlZubK7fbbXU5QU78LjlkWV9FVrPP75JF+cV6pcs/bfkzKytLRzZWr16tq666KvB4xIgRkqSBAwdq5syZFlUFAAAAoCJY2mx07dpVFg6sAAAAAPLJJZ/sswKUnWopr9CZEAYAAADAVmg2AAAAAJiC1agAAADgaH5DtrqRnj+ErjJgZAMAAACAKWg2AAAAAJiCaVQAAABwNL/Nbupnp1rKK3SSAAAAALAVmg0AAAAApmAaFQAAABzNL5f8NrqRnp1qKS9GNgAAAACYgmYDAAAAgCmYRgUAAABH8xku+Wx0Uz871VJejGwAAAAAMAXNBgAAAABTMI0KAAAAjsZN/cwTOkkAAAAA2ArNBgAAAABTMI0KAAAAjuaXS34brQDFTf0AAAAA4CxoNgAAAACYgmlUAAAAcDRDLltNXTJsVEt5MbIBAAAAwBQ0GwAAAABMwTSqSmpwg85Wl2CJz/ast7oES/RIamt1CQAAhCy/YbPVqGxUS3kxsgEAAADAFDQbAAAAAEzBNCoAAAA4mt8Ik9+wz3fwdqqlvEInCQAAAABbodkAAAAAYAqmUQEAAMDRWI3KPIxsAAAAADAFzQYAAAAAUzCNCgAAAI7ml0t+2Wfqkp1qKS9GNgAAAACYgmYDAAAAgCmYRgUAAABHYzUq8zCyAQAAAMAUNBsAAAAATME0KgAAADga06jMw8gGAAAAAFPQbAAAAAAwBc0GAAAAHO3ENCo7bWX11VdfqVevXkpKSpLL5dL8+fODnh80aJBcLlfQdu211571fV988UVdcMEFio6OVocOHfTdd9+VqS6aDQAAAKCSKygoUJs2bfTiiy+e9phrr71We/fuDWzvvvvuGd9z7ty5GjFihMaPH6+1a9eqTZs26tGjh3JyckpdFxeIAwAAAJVcz5491bNnzzMeExUVpcTExFK/57PPPqvBgwfr9ttvlyRNnz5dn3zyid544w2NHj26VO/ByAYAAAAczeopU6ebRuX1eoO2wsLCcuVcunSpateuraZNm+ruu+/WL7/8ctpji4qKtGbNGnXr1i2wLywsTN26ddPKlStL/Zk0GwAAAIANJScny+PxBLa0tLRzfq9rr71Wb731lpYsWaInn3xSy5YtU8+ePeXz+U55/IEDB+Tz+VSnTp2g/XXq1FF2dnapP5dpVAAAAIANZWVlye12Bx5HRUWd83v96U9/Cvz/Vq1aqXXr1mrUqJGWLl2qq6++ulx1ngnNBgAAABzNkOSXfW6kZ/z3f91ud1CzUZFSU1NVq1Ytbd++/ZTNRq1atRQeHq59+/YF7d+3b1+ZrvtgGhUAAADgMLt379Yvv/yiunXrnvL5yMhItW/fXkuWLAns8/v9WrJkiTp27Fjqz2Fk4xz1GnRAN9+do/iEEmVsjtFLj9RT+vpYq8syXSjnnvNCbf3n0+rK2h6lyGi/WlxyRHc+vEfJjX+9GOvTd2rqyw9qaPvGGB3JD9d7WzaqmufUcx1DQSif7zMhN7nJHbrI7azcTpKfn6/t27cHHu/cuVPr169XfHy84uPjNXHiRN10001KTEzUjh079OCDD6px48bq0aNH4DVXX321brjhBg0bNkySNGLECA0cOFCXXHKJLrvsMk2ZMkUFBQWB1alKg5GNc9Dl+kMaMn6PZj2bqKE9mihjc7Qmz86Qp2ax1aWZKtRzb1hZTb0GHdCUBduUNmeHfCXS3/o10rEjv/41OXY0TJd09epP9+47wzuFhlA/36dDbnKTO3SR21m5y8Lqlacq4qZ+q1evVrt27dSuXTtJxxuFdu3aady4cQoPD9eGDRt0/fXXq0mTJrrzzjvVvn17LV++POg6kB07dujAgQOBx7feequefvppjRs3Tm3bttX69eu1cOHCky4aPxOXYRjG2Q8zR1pamt5//339+OOPiomJ0eWXX64nn3xSTZs2LdXrvV6vPB6Puqq3IlxVTK72V/9YsE1bv4/Riw/XlyS5XIbeWb1ZH86opXlTS//Dr2zskPuzPevPy+dI0uFfwnVrq1Z6+v1tavWHgqDnvv+6mh68ufF5G9nokdTW9M/4PTucbyuQm9zkJneosTp3iVGspfpQubm5pl1/cK5O/C75P5/8RRFVz/3i64pWUlCoL66bbsufWVlZOrKxbNkyDR06VN98840WLVqk4uJide/eXQUFBWd/sUUiqvh1YesjWrs8LrDPMFxatzxOLdofsbAyczkxd4E3XJIUVz10p0mdjhPPt0RucpOb3KHHqblhH5Zes7Fw4cKgxzNnzlTt2rW1Zs0aXXnllRZVdWbueJ/CI6TD+4N/dIcORATN7Q81Tsvt90vTx9dTy0vzdUGzY1aXc9457XyfQG5yS+QOVeR2Vu6yOtepS2axUy3lZasLxHNzcyVJ8fHxp3y+sLAw6M6JXq/3vNQF55n6t/ra9WOMnpm/zepSAAAAKi3bXCDu9/s1fPhwderUSRdddNEpj0lLSwu6i2JycvJ5rlLyHgyXr0SqnlAStL9GrRId2m+r3q1COSn31L/V07eL3HrqX9uVkOTMi+ecdL5/i9zklsgdqsjtrNywD9s0G0OHDtUPP/ygOXPmnPaYMWPGKDc3N7BlZWWdxwqPKykO07YNsWrXOS+wz+Uy1LZzvjavCd0l5JyQ2zCONxpfL/ToqX9uV2KDIqtLsowTzvepkJvc5CZ3qHFq7rKyeuWpiliNyq5s0dIOGzZMCxYs0FdffaX69euf9rioqKhy3aa9orz/Si2NnJKlrd/HKn1drG4YvF/RsX59PufU079CRajnnvq3+vrygxqaMCNDMdX8Ophz/K9H1TifomKOL9p2MCdCh3KqaM/OSEnSzh+jFVvVr4R6RXLXCK0LyUP9fJ8OuclN7tBFbmflhj1Y2mwYhqF7771XH3zwgZYuXaqUlBQryym1ZR/VkKemTwNGZatGQokyNsXo4f4pOnzg/C2/a4VQz73gzVqSpFE3XRi0/4HnMtX91oOSpE/eqqV3nk0MPDfyhgtPOiZUhPr5Ph1yk5vcoYvczsoNe7D0Phv33HOPZs+erQ8//DDo3hoej0cxMTFnfb1V99mAdc7nfTbsxIr7bAAAUBEqw302On801Hb32Vhx/Yu2/JmVlaXXbEybNk25ubnq2rWr6tatG9jmzp1rZVkAAAAAKoDl06gAAAAAhCZbXCAOAAAAWMUwXDJstAKUnWopL9ssfQsAAAAgtNBsAAAAADAF06gAAADgaH655Jd9pi7ZqZbyYmQDAAAAgCloNgAAAACYgmlUAAAAcDS/4ZLfRitA2amW8mJkAwAAAIApaDYAAAAAmIJpVAAAAHA0bupnHkY2AAAAAJiCZgMAAACAKZhGBQAAAEdjNSrzMLIBAAAAwBQ0GwAAAABMwTQqAAAAOBqrUZmHkQ0AAAAApqDZAAAAAGAKplEBAADA0QybrUbFNCoAAAAAOAuaDQAAAACmYBoVAAAAHM2QZBhWV/ErG5VSboxsAAAAADAFIxuoVHoktbW6BEu8mrnC6hIsMbhBZ6tLAAAA5UCzAQAAAEfzyyWX7LMClN9GtZQX06gAAAAAmIJmAwAAAIApmEYFAAAARzMMl61upGenWsqLkQ0AAAAApqDZAAAAAGAKplEBAADA0fyGSy4bTV3y26iW8mJkAwAAAIApaDYAAAAAmIJpVAAAAHA0wzi+2YWdaikvRjYAAAAAmIJmAwAAAIApmEYFAAAAR+OmfuZhZAMAAACAKWg2AAAAAJiCaVQAAABwNKZRmYeRDQAAAACmoNkAAAAAYAqmUQEAAMDR/IZLLhtNXfLbqJbyYmQDAAAAgCloNgAAAACYgmlUAAAAcDTDOL7ZhZ1qKS9GNgAAAACYgmYDAAAAgCmYRgUAAABHOz6Nyj4rQIXSNCqajXPUa9AB3Xx3juITSpSxOUYvPVJP6etjrS7LdOQOvdyfTq2vtQtrKntHjCKj/WrUPk83jflJiY2OBo4pPubSvMdStOqjBJUUhalll0Pq/9gOuROKLazcPKF8vs+E3OQmd+hyam5Yj2lU56DL9Yc0ZPwezXo2UUN7NFHG5mhNnp0hT83Q/MXrBHKHZu6t33p01cC9GjN/g+6ftUm+Epeeu62lCo/8+s/D3EdTtWFxvP487UeNmrdBh/dF6qUhzS2s2jyhfr5Ph9zkJnfocmpu2IOlzca0adPUunVrud1uud1udezYUf/+97+tLKlUbhxyQAtnx+vzufHK3Bat5x+qr8KjLvXod9Dq0kxF7tDMPfztTerUN0f1mh5RcosC3f7MVh38OVq7NlaTJB3xhmvF3Dq6ZexONe+Uq4atCzTo6W3ascatHWvjLK6+4oX6+T4dcpOb3KHLqbnLwjBctttChaXNRv369fXEE09ozZo1Wr16tf7nf/5HvXv31qZNm6ws64wiqvh1YesjWrv811+yDMOldcvj1KL9EQsrMxe5nZP7aN7x2ZVVq5dIknZtrCZfcZiadz4cOKZu46OKr3dMGSHWbDjxfEvkJje5yQ2Yx9Jmo1evXvrf//1fXXjhhWrSpIkmT56satWq6ZtvvrGyrDNyx/sUHiEd3h98ucuhAxGqkVBiUVXmI7czcvv90pwJqWp8Sa7qNT3+HyHv/khFRPoV6/EFHeuuVazcnEgryjSN0873CeQmt0TuUOXU3LAP21wg7vP59M9//lMFBQXq2LHjKY8pLCxUYWFh4LHX6z1f5QGOMPuRRtqzNVYPvrfB6lIAADhvjP9udmGnWsrL8gvEN27cqGrVqikqKkp/+ctf9MEHH6hFixanPDYtLU0ejyewJScnn+dqJe/BcPlKpOq/+zagRq0SHdpvm96twpE79HPPHpuqDUvi9cCcjYqvWxTY704oUklRmI7khgcd7z1QRZ7aRb9/m0rNSef7t8hNboncocqpuWEfljcbTZs21fr16/Xtt9/q7rvv1sCBA7V58+ZTHjtmzBjl5uYGtqysrPNcrVRSHKZtG2LVrnNeYJ/LZaht53xtXhO6S8iRO3RzG8bxRmPdwpp6YM5GJTQoDHq+Yat8hVfxa8t/qgf2Ze+I0cGfo5V6cZ5CiRPO96mQm9zkJjdgFstb2sjISDVu3FiS1L59e61atUr/+Mc/9PLLL590bFRUlKKios53iSd5/5VaGjklS1u/j1X6uljdMHi/omP9+nxOvNWlmYrcoZl79iON9O2HCRr62mZFV/UpN6eKJCnG7VNktF+xbp8637pP8yalqGr1EsVUK9G74xupUXuvGoVYsyGF/vk+HXKTm9yhy6m5y8JuK0DZqZbysrzZ+D2/3x90XYYdLfuohjw1fRowKls1EkqUsSlGD/dP0eEDVawuzVTkDs3cS9+uK0l6+pbWQfsHPbNVnfrmSJJuHZchV1iKpv25WdBN/UJRqJ/v0yE3uckdupyaG/bgMgzrbog+ZswY9ezZUw0aNFBeXp5mz56tJ598Up999pmuueaas77e6/XK4/Goq3orwsVfGISuVzNXWF2CJQY36Gx1CQCAcioxirVUHyo3N1dut9vqcoKc+F0y9a2/KTw22upyAnxHjiljwOO2/JmVlaUjGzk5ORowYID27t0rj8ej1q1bl7rRAAAAACoEy1GZxtJm4/XXX7fy4wEAAACYyPLVqAAAAACEJttdIA4AAACcVzZbjUp2qqWcGNkAAAAAYAqaDQAAAACmYBoVAAAAHM0wjm92YadayouRDQAAAACmoNkAAAAAYAqmUQEAAMDRDJutRmWnWsqLkQ0AAACgkvvqq6/Uq1cvJSUlyeVyaf78+YHniouL9dBDD6lVq1aqWrWqkpKSNGDAAO3Zs+eM7zlhwgS5XK6grVmzZmWqi2YDAAAAqOQKCgrUpk0bvfjiiyc9d+TIEa1du1Zjx47V2rVr9f777ys9PV3XX3/9Wd+3ZcuW2rt3b2BbsWJFmepiGhUAAACczXDZ60Z651BLz5491bNnz1M+5/F4tGjRoqB9U6dO1WWXXabMzEw1aNDgtO8bERGhxMTEMtdzAiMbAAAAgA15vd6grbCwsMLeOzc3Vy6XS9WrVz/jcdu2bVNSUpJSU1PVv39/ZWZmlulzaDYAAAAAG0pOTpbH4wlsaWlpFfK+x44d00MPPaR+/frJ7Xaf9rgOHTpo5syZWrhwoaZNm6adO3fqiiuuUF5eXqk/i2lUAAAAcDS73tQvKysrqBmIiooq93sXFxfrlltukWEYmjZt2hmP/e20rNatW6tDhw5q2LCh5s2bpzvvvLNUn0ezAQAAANiQ2+0+48hDWZ1oNHbt2qUvvviizO9dvXp1NWnSRNu3by/1a5hGBQAAAIS4E43Gtm3btHjxYtWsWbPM75Gfn68dO3aobt26pX4NzQYAAACczbDhVkb5+flav3691q9fL0nauXOn1q9fr8zMTBUXF+vmm2/W6tWrNWvWLPl8PmVnZys7O1tFRUWB97j66qs1derUwOORI0dq2bJl+umnn/T111/rhhtuUHh4uPr161fquphGBQAAAFRyq1ev1lVXXRV4PGLECEnSwIEDNWHCBH300UeSpLZt2wa97ssvv1TXrl0lSTt27NCBAwcCz+3evVv9+vXTL7/8ooSEBHXu3FnffPONEhISSl0XzQYAAABQyXXt2lXGGa5yP9NzJ/z0009Bj+fMmVPesmg2AAAA4GyG4ZJho5v62amW8uKaDQAAAACmoNkAAAAAYAqmUQEAAAA2uqlfKKHZACqBwQ06W12CJV7NXGF1CZZw6vkGAIQeplEBAAAAMAUjGwAAAHA0VqMyDyMbAAAAAExBswEAAADAFEyjAgAAgLMZstdqVHaqpZwY2QAAAABgCpoNAAAAAKZgGhUAAAAczvXfzS7sVEv5MLIBAAAAwBQ0GwAAAABMwTQqAAAAOBurUZmGkQ0AAAAApqDZAAAAAGAKplEBAADA2ZhGZRpGNgAAAACYgmYDAAAAgCmYRgUAAABnM1zHN7uwUy3lxMgGAAAAAFPQbAAAAAAwBdOoAAAA4GiGcXyzCzvVUl6MbAAAAAAwBc0GAAAAAFMwjQoAAADOxk39TMPIBgAAAABT0GwAAAAAMAXTqM5Rr0EHdPPdOYpPKFHG5hi99Eg9pa+Ptbos05Gb3KGS+9Op9bV2YU1l74hRZLRfjdrn6aYxPymx0dHAMcXHXJr3WIpWfZSgkqIwtexySP0f2yF3QrGFlZsnlM/3mZCb3OQGN/UzDyMb56DL9Yc0ZPwezXo2UUN7NFHG5mhNnp0hT83Q/AXkBHKTO5Ryb/3Wo6sG7tWY+Rt0/6xN8pW49NxtLVV45Nd/Fuc+mqoNi+P152k/atS8DTq8L1IvDWluYdXmCfXzfTrkJje5AXPZptl44okn5HK5NHz4cKtLOasbhxzQwtnx+nxuvDK3Rev5h+qr8KhLPfodtLo0U5Gb3KGUe/jbm9Spb47qNT2i5BYFuv2ZrTr4c7R2bawmSTriDdeKuXV0y9idat4pVw1bF2jQ09u0Y41bO9bGWVx9xQv183065CY3uQFz2aLZWLVqlV5++WW1bt3a6lLOKqKKXxe2PqK1y3/9ZcMwXFq3PE4t2h+xsDJzkZvcoZ77aN7xWaVVq5dIknZtrCZfcZiadz4cOKZu46OKr3dMGSHWbDjxfEvkJje5Qzl3WbkM+22hwvJmIz8/X/3799err76qGjVqWF3OWbnjfQqPkA7vD77c5dCBCNVIKLGoKvORm9xS6Ob2+6U5E1LV+JJc1Wt6/D++3v2Rioj0K9bjCzrWXatYuTmRVpRpGqed7xPITW6J3IDZSnWB+EcffVTqN7z++uvLVMDQoUN13XXXqVu3bnrsscfOeGxhYaEKCwsDj71eb5k+CwBOZfYjjbRna6wefG+D1aUAABBSStVs9OnTp1Rv5nK55PP5zn7gf82ZM0dr167VqlWrSnV8WlqaJk6cWOr3N4P3YLh8JVL1330bUKNWiQ7tD93FvchNbik0c88em6oNS+I16p8bFF+3KLDfnVCkkqIwHckNDxrd8B6oIk/tolO9VaXlpPP9W+Qmt0Ru/Bc39TNNqaZR+f3+Um1laTSysrJ03333adasWYqOji7Va8aMGaPc3NzAlpWVVerPqyglxWHatiFW7TrnBfa5XIbads7X5jWhu4QcuckdarkN43ijsW5hTT0wZ6MSGhQGPd+wVb7Cq/i15T/VA/uyd8To4M/RSr04T6HECef7VMhNbnKHbm7YR7la2mPHjpW6Ufi9NWvWKCcnRxdffHFgn8/n01dffaWpU6eqsLBQ4eHhQa+JiopSVFRUeUquEO+/Uksjp2Rp6/exSl8XqxsG71d0rF+fz4m3ujRTkZvcoZR79iON9O2HCRr62mZFV/UpN6eKJCnG7VNktF+xbp8637pP8yalqGr1EsVUK9G74xupUXuvGoVYsyGF/vk+HXKTm9yAucrcbPh8Pj3++OOaPn269u3bp61btyo1NVVjx47VBRdcoDvvvLNU73P11Vdr48aNQftuv/12NWvWTA899NBJjYadLPuohjw1fRowKls1EkqUsSlGD/dP0eEDVawuzVTkJnco5V76dl1J0tO3BK+CN+iZrerUN0eSdOu4DLnCUjTtz82CbuoXikL9fJ8OuclNbkjipn4mchmGUaZZYY8++qjefPNNPfrooxo8eLB++OEHpaamau7cuZoyZYpWrlx5zsV07dpVbdu21ZQpU0p1vNfrlcfjUVf1VoSLvzBAqHk1c4XVJVhicIPOVpcAABWmxCjWUn2o3Nxcud1uq8sJcuJ3yeTnJiks5txm65jBf/SYsu4fa8ufWVmVeenbt956S6+88or69+8fNPrQpk0b/fjjjxVaHAAAAIDKq8zTqH7++Wc1btz4pP1+v1/FxeW77f3SpUvL9XoAAACgzFiNyjRlHtlo0aKFli9fftL+f/3rX2rXrl2FFAUAAACg8ivzyMa4ceM0cOBA/fzzz/L7/Xr//feVnp6ut956SwsWLDCjRgAAAACVUJlHNnr37q2PP/5YixcvVtWqVTVu3Dht2bJFH3/8sa655hozagQAAADMY9hwCxHndJ+NK664QosWLaroWgAAAACEkHO+qd/q1au1ZcsWScev42jfvn2FFQUAAACg8itzs7F7927169dP//nPf1S9enVJ0uHDh3X55Zdrzpw5ql+/fkXXCAAAAJjHblOX7FRLOZX5mo277rpLxcXF2rJliw4ePKiDBw9qy5Yt8vv9uuuuu8yoEQAAAEAlVOaRjWXLlunrr79W06ZNA/uaNm2qF154QVdccUWFFgcAAACg8ipzs5GcnHzKm/f5fD4lJSVVSFEAAADAeWO4jm92YadayqnM06j+/ve/695779Xq1asD+1avXq377rtPTz/9dIUWBwAAAKDyKtXIRo0aNeRy/dphFRQUqEOHDoqIOP7ykpISRURE6I477lCfPn1MKRQAAABA5VKqZmPKlCkmlwEAAABYw2Uc3+zCTrWUV6majYEDB5pdBwAAAIAQc8439ZOkY8eOqaioKGif2+0uV0EAAAAAQkOZLxAvKCjQsGHDVLt2bVWtWlU1atQI2gAAAIBKxbDhFiLK3Gw8+OCD+uKLLzRt2jRFRUXptdde08SJE5WUlKS33nrLjBoBAAAAVEJlnkb18ccf66233lLXrl11++2364orrlDjxo3VsGFDzZo1S/379zejTgAAAACVTJlHNg4ePKjU1FRJx6/POHjwoCSpc+fO+uqrryq2OgAAAACVVpmbjdTUVO3cuVOS1KxZM82bN0/S8RGP6tWrV2hxAAAAACqvMjcbt99+u77//ntJ0ujRo/Xiiy8qOjpa999/v0aNGlXhBQIAAAConMp8zcb9998f+P/dunXTjz/+qDVr1qhx48Zq3bp1hRYHAAAAmM0le91Iz2V1ARWoXPfZkKSGDRuqYcOGFVELAAAAgBBSqmbj+eefL/Ub/vWvfz3nYgAAAACEjlI1G88991yp3szlctFsAKgwgxt0troES7yaucLqEizh1PMNAKGsVM3GidWnAAAAgJBjuI5vdmGnWsqpzKtRAQAAAEBp0GwAAAAAMEW5V6MCAAAAKjXjv5td2KmWcmJkAwAAAIApaDYAAAAAmOKcmo3ly5frtttuU8eOHfXzzz9Lkt5++22tWOHM5RoBAABQiRk23EJEmZuN9957Tz169FBMTIzWrVunwsJCSVJubq4ef/zxCi8QAAAAQOVU5mbjscce0/Tp0/Xqq6+qSpUqgf2dOnXS2rVrK7Q4AAAAAJVXmVejSk9P15VXXnnSfo/Ho8OHD1dETQAAAMB54zKOb3Zhp1rKq8wjG4mJidq+fftJ+1esWKHU1NQKKQoAAABA5VfmZmPw4MG677779O2338rlcmnPnj2aNWuWRo4cqbvvvtuMGgEAAABUQmWeRjV69Gj5/X5dffXVOnLkiK688kpFRUVp5MiRuvfee82oEQAAADCP3VaAslMt5VTmZsPlcunhhx/WqFGjtH37duXn56tFixaqVq2aGfUBAAAAqKTO+aZ+kZGRatGihS677DIaDQAAAMBCX331lXr16qWkpCS5XC7Nnz8/6HnDMDRu3DjVrVtXMTEx6tatm7Zt23bW933xxRd1wQUXKDo6Wh06dNB3331XprrKPLJx1VVXyeVynfb5L774oqxvCQAAAFgnBKZRFRQUqE2bNrrjjjt04403nvT8U089peeff15vvvmmUlJSNHbsWPXo0UObN29WdHT0Kd9z7ty5GjFihKZPn64OHTpoypQp6tGjh9LT01W7du1S1VXmZqNt27ZBj4uLi7V+/Xr98MMPGjhwYFnfDgAAAEA59ezZUz179jzlc4ZhaMqUKXrkkUfUu3dvSdJbb72lOnXqaP78+frTn/50ytc9++yzGjx4sG6//XZJ0vTp0/XJJ5/ojTfe0OjRo0tVV5mbjeeee+6U+ydMmKD8/Pyyvh0AAACAU/B6vUGPo6KiFBUVVeb32blzp7Kzs9WtW7fAPo/How4dOmjlypWnbDaKioq0Zs0ajRkzJrAvLCxM3bp108qVK0v92ed8zcbv3XbbbXrjjTcq6u0AAACA8+LETf3stElScnKyPB5PYEtLSzunfNnZ2ZKkOnXqBO2vU6dO4LnfO3DggHw+X5lecyplHtk4nZUrV552vhcAAACAssnKypLb7Q48PpdRDauVudn4/QUnhmFo7969Wr16tcaOHVthhQEAAABO5na7g5qNc5WYmChJ2rdvn+rWrRvYv2/fvpOuxz6hVq1aCg8P1759+4L279u3L/B+pVHmaVS/HcrxeDyKj49X165d9emnn2r8+PFlfTsAAADAWobLflsFSklJUWJiopYsWRLY5/V69e2336pjx46nfE1kZKTat28f9Bq/368lS5ac9jWnUqaRDZ/Pp9tvv12tWrVSjRo1yvJSAAAAACbJz8/X9u3bA4937typ9evXKz4+Xg0aNNDw4cP12GOP6cILLwwsfZuUlKQ+ffoEXnP11Vfrhhtu0LBhwyRJI0aM0MCBA3XJJZfosssu05QpU1RQUBBYnao0ytRshIeHq3v37tqyZQvNBgAAAGATq1ev1lVXXRV4PGLECEnSwIEDNXPmTD344IMqKCjQkCFDdPjwYXXu3FkLFy4MuuZ6x44dOnDgQODxrbfeqv3792vcuHHKzs5W27ZttXDhwpMuGj+TMl+zcdFFFykjI0MpKSllfSkAAABgPyFwU7+uXbvKME7/QpfLpUcffVSPPvroaY/56aefTto3bNiwwEjHuShzs/HYY49p5MiRmjRpktq3b6+qVasGPV8RF7FUBr0GHdDNd+coPqFEGZtj9NIj9ZS+PtbqskxHbnKTu3L7dGp9rV1YU9k7YhQZ7Vej9nm6acxPSmx0NHBM8TGX5j2WolUfJaikKEwtuxxS/8d2yJ1QbGHl5gnl830m5Ca3E3LDeqW+QPzRRx9VQUGB/vd//1fff/+9rr/+etWvX181atRQjRo1VL16dcdMrepy/SENGb9Hs55N1NAeTZSxOVqTZ2fIUzM0/0N8ArnJTe7Kb+u3Hl01cK/GzN+g+2dtkq/Epedua6nCI7/+52Duo6nasDhef572o0bN26DD+yL10pDmFlZtnlA/36dDbnI7ITfsodTNxsSJE1VQUKAvv/wysH3xxReB7cTjspgwYYJcLlfQ1qxZszKHON9uHHJAC2fH6/O58crcFq3nH6qvwqMu9eh30OrSTEVucpO78hv+9iZ16pujek2PKLlFgW5/ZqsO/hytXRurSZKOeMO1Ym4d3TJ2p5p3ylXD1gUa9PQ27Vjj1o61cRZXX/FC/XyfDrnJ7YTcZWH1DfxOd1O/UFDqaVQn5oB16dKlQgto2bKlFi9e/GtBERV2n0FTRFTx68LWRzRnau3APsNwad3yOLVof8TCysxFbnKTOzRzH807/m9u1eolkqRdG6vJVxym5p0PB46p2/io4usdU8baODW6OM+KMk3hxPMtkZvczsgN+yjTfTZcropd81c63lwkJiYGtlq1alX4Z1Qkd7xP4RHS4f3BTdGhAxGqkVBiUVXmIze5JXKHGr9fmjMhVY0vyVW9psd/6fDuj1REpF+xHl/Qse5axcrNibSiTNM47XyfQG5yS6GfG/ZRpmGEJk2anLXhOHiwbENy27ZtU1JSkqKjo9WxY0elpaWpQYMGpzy2sLBQhYWFgcder7dMnwUA+NXsRxppz9ZYPfjeBqtLAQBrhcBqVHZVpmZj4sSJ8ng8FfbhHTp00MyZM9W0aVPt3btXEydO1BVXXKEffvhBcXEnzw1OS0vTxIkTK+zzz4X3YLh8JVL1330bUKNWiQ7tt/cUsPIgN7klcoeS2WNTtWFJvEb9c4Pi6xYF9rsTilRSFKYjueFBoxveA1XkqV10qreqtJx0vn+L3OSWQj837KNM06j+9Kc/aeDAgWfcyqJnz57q27evWrdurR49eujTTz/V4cOHNW/evFMeP2bMGOXm5ga2rKysMn1eRSgpDtO2DbFq1/nXecsul6G2nfO1eU3oLiFHbnKTOzRyG8bxRmPdwpp6YM5GJTQoDHq+Yat8hVfxa8t/qgf2Ze+I0cGfo5UaQtdrSM4436dCbnI7ITfso9QtrRnXa/xe9erV1aRJk6Bbrf9WVFSUoqKiTK/jbN5/pZZGTsnS1u9jlb4uVjcM3q/oWL8+nxNvdWmmIje5yV35zX6kkb79MEFDX9us6Ko+5eZUkSTFuH2KjPYr1u1T51v3ad6kFFWtXqKYaiV6d3wjNWrvDamLw08I9fN9OuQmtxNyl4ndVoCyUy3lVObVqMyUn5+vHTt26P/+7/9M/6zyWPZRDXlq+jRgVLZqJJQoY1OMHu6fosMHqlhdmqnITW5yV35L364rSXr6ltZB+wc9s1Wd+uZIkm4dlyFXWIqm/blZ0E39QlGon+/TITe5nZAb9uAyzkcXcRojR45Ur1691LBhQ+3Zs0fjx4/X+vXrtXnzZiUkJJz19V6vVx6PR13VWxEu/sIACA2vZq6wugRLDG7Q2eoSAJigxCjWUn2o3Nxcud1uq8sJcuJ3ydSxjys8OtrqcgJ8x44pY9LfbPkzKytLrwzavXu3+vXrp19++UUJCQnq3Lmzvvnmm1I1GgAAAECFYDUq01jabMyZM8fKjwcAAABgojKtRgUAAAAApcUCywAAAHA2plGZhpENAAAAAKag2QAAAABgCqZRAQAAwNFcNrupn51qKS9GNgAAAACYgmYDAAAAgCloNgAAAACYgmYDAAAAgCloNgAAAACYgtWoAAAA4Gzc1M80jGwAAAAAMAXNBgAAAABTMI0KAAAAjsZN/czDyAYAAAAAU9BsAAAAADAF06gAAACAEJq6ZCeMbAAAAAAwBc0GAAAAAFMwjQoAAADOxk39TMPIBgAAAABT0GwAAAAAMAXTqAAAAOBo3NTPPDQbAGAzf2nTy+oSLPFq5sdWl2CJwQ06W10CAJiGaVQAAAAATMHIBgAAAJyN1ahMw8gGAAAAAFPQbAAAAAAwBdOoAAAA4GisRmUeRjYAAAAAmIJmAwAAAIApmEYFAAAAZ2M1KtMwsgEAAADAFDQbAAAAAEzBNCoAAAA4G9OoTMPIBgAAAABT0GwAAAAAMAXTqAAAAOBo3NTPPIxsAAAAADAFzQYAAAAAUzCNCgAAAM7GalSmYWQDAAAAgCloNgAAAACYgmlUAAAAcDamUZmGkQ0AAAAApqDZAAAAAGAKplEBAADA0bipn3kY2QAAAABgCpoNAAAAAKZgGtU56jXogG6+O0fxCSXK2Byjlx6pp/T1sVaXZTpyk5vcoeei9od10x1ZatwiTzVrF2nSvS218osEq8uqUJ9Ora+1C2sqe0eMIqP9atQ+TzeN+UmJjY4Gjik+5tK8x1K06qMElRSFqWWXQ+r/2A65E4otrNw8TvtzfgK5nZW71FiNyjSMbJyDLtcf0pDxezTr2UQN7dFEGZujNXl2hjw1Q/M/SCeQm9zkDk3RMT7tTK+qlx670OpSTLP1W4+uGrhXY+Zv0P2zNslX4tJzt7VU4ZFf/zM499FUbVgcrz9P+1Gj5m3Q4X2RemlIcwurNo8T/5xL5HZabtiD5c3Gzz//rNtuu001a9ZUTEyMWrVqpdWrV1td1hndOOSAFs6O1+dz45W5LVrPP1RfhUdd6tHvoNWlmYrc5CZ3aFq9oqbeej5VK5eE1mjGbw1/e5M69c1RvaZHlNyiQLc/s1UHf47Wro3VJElHvOFaMbeObhm7U8075aph6wINenqbdqxxa8faOIurr3hO/HMukdtpuWEPljYbhw4dUqdOnVSlShX9+9//1ubNm/XMM8+oRo0aVpZ1RhFV/Lqw9RGtXf7rf3wMw6V1y+PUov0RCyszF7nJTe7Qze1ER/OOzyKuWr1EkrRrYzX5isPUvPPhwDF1Gx9VfL1jygixZsOpf87J7azcZXViNSo7baHC0ms2nnzySSUnJ2vGjBmBfSkpKRZWdHbueJ/CI6TD+4N/dIcORCi5caFFVZmP3OSWyI3Q4PdLcyakqvEluarX9PgvW979kYqI9CvW4ws61l2rWLk5kVaUaRqn/jknt7Nywz4sHdn46KOPdMkll6hv376qXbu22rVrp1dfffW0xxcWFsrr9QZtAACUxexHGmnP1lgNfjHd6lIAIORZ2mxkZGRo2rRpuvDCC/XZZ5/p7rvv1l//+le9+eabpzw+LS1NHo8nsCUnJ5/niiXvwXD5SqTqCSVB+2vUKtGh/aG7uBe5yS2RG5Xf7LGp2rAkXg/M2aj4ukWB/e6EIpUUhelIbnjQ8d4DVeSpXfT7t6nUnPrnnNzOyl1mhg23EGFps+H3+3XxxRfr8ccfV7t27TRkyBANHjxY06dPP+XxY8aMUW5ubmDLyso6zxVLJcVh2rYhVu065wX2uVyG2nbO1+Y1obuEHLnJTe7Qze0EhnG80Vi3sKYemLNRCQ2Cp480bJWv8Cp+bflP9cC+7B0xOvhztFIvzlMoceqfc3I7Kzfsw9KWtm7dumrRokXQvubNm+u999475fFRUVGKioo6H6Wd0fuv1NLIKVna+n2s0tfF6obB+xUd69fnc+KtLs1U5CY3uUNTdGyJkhr8er+JOvWPKbVZnvJyq2j/3mgLK6s4sx9ppG8/TNDQ1zYruqpPuTlVJEkxbp8io/2KdfvU+dZ9mjcpRVWrlyimWoneHd9Ijdp71SjEmg3JmX/OJXI7LTfswdJmo1OnTkpPD54zu3XrVjVs2NCiikpn2Uc15Knp04BR2aqRUKKMTTF6uH+KDh+oYnVppiI3uckdmi5smacnZ34feDzkoR2SpEXz6+i5h0PjPhNL364rSXr6ltZB+wc9s1Wd+uZIkm4dlyFXWIqm/blZ0E39QpET/5xL5HZa7jKx29QlO9VSTi7DMCyLs2rVKl1++eWaOHGibrnlFn333XcaPHiwXnnlFfXv3/+sr/d6vfJ4POqq3opw8RcGQGgIt/Hy32aa/v3HVpdgicENOltdAmCqEqNYS/WhcnNz5Xa7rS4nyInfJZvf87jCo+wzkusrPKYtL/3Nlj+zsrL0mo1LL71UH3zwgd59911ddNFFmjRpkqZMmVKqRgMAAACAvVm+DMEf//hH/fGPf7S6DAAAADiU67+bXdiplvKydGQDAAAAQOii2QAAAABgCsunUQEAAACWYjUq0zCyAQAAAMAUNBsAAAAATEGzAQAAAEdzGfbbyuKCCy6Qy+U6aRs6dOgpj585c+ZJx0ZHm3OfEa7ZAAAAACqxVatWyefzBR7/8MMPuuaaa9S3b9/Tvsbtdis9PT3w2OUyZ8Fdmg0AAACgEktISAh6/MQTT6hRo0bq0qXLaV/jcrmUmJhodmlMowIAAIDDGTbczlFRUZHeeecd3XHHHWccrcjPz1fDhg2VnJys3r17a9OmTef+oWdAswEAAADYkNfrDdoKCwvP+pr58+fr8OHDGjRo0GmPadq0qd544w19+OGHeuedd+T3+3X55Zdr9+7dFVj9cTQbAAAAgA0lJyfL4/EEtrS0tLO+5vXXX1fPnj2VlJR02mM6duyoAQMGqG3bturSpYvef/99JSQk6OWXX67I8iVxzQYAAABgyxvpZWVlye12Bx5HRUWd8fhdu3Zp8eLFev/998v0OVWqVFG7du20ffv2c6rzTBjZAAAAAGzI7XYHbWdrNmbMmKHatWvruuuuK9Pn+Hw+bdy4UXXr1i1PuadEswEAAABUcn6/XzNmzNDAgQMVERE8eWnAgAEaM2ZM4PGjjz6qzz//XBkZGVq7dq1uu+027dq1S3fddVeF18U0KgAAADjaudxIz0znUsvixYuVmZmpO+6446TnMjMzFRb26xjDoUOHNHjwYGVnZ6tGjRpq3769vv76a7Vo0aI8ZZ8SzQYAAABQyXXv3l2GceouZenSpUGPn3vuOT333HPnoSqmUQEAAAAwCSMbAAAAcLZy3kivwtmplnJiZAMAAACAKWg2AAAAAJiCaVQAAABwtFBYjcquGNkAAAAAYAqaDQAAAACmYBoVANiM79Ahq0uwxOAGna0uwRKvZq6wugRLOPV8w6ZYjco0jGwAAAAAMAXNBgAAAABTMI0KAAAAjsZqVOZhZAMAAACAKWg2AAAAAJiCaVQAAABwNlajMg0jGwAAAABMQbMBAAAAwBRMowIAAICzMY3KNIxsAAAAADAFzQYAAAAAUzCNCgAAAI7GTf3Mw8gGAAAAAFPQbAAAAAAwBdOoAAAA4GysRmUaRjYAAAAAmIJmAwAAAIApmEYFAAAAR3MZhlyGfeYu2amW8mJkAwAAAIApaDYAAAAAmIJpVAAAAHA2VqMyDSMbAAAAAExBswEAAADAFEyjAgAAgKO5jOObXdiplvJiZAMAAACAKRjZOEe9Bh3QzXfnKD6hRBmbY/TSI/WUvj7W6rJMR25ykzt0kTv0cn86tb7WLqyp7B0xioz2q1H7PN005iclNjoaOKb4mEvzHkvRqo8SVFIUppZdDqn/YzvkTii2sHLzhPL5PhOn5ob1GNk4B12uP6Qh4/do1rOJGtqjiTI2R2vy7Ax5aobmP8wnkJvc5A5d5A7N3Fu/9eiqgXs1Zv4G3T9rk3wlLj13W0sVHvn1P/9zH03VhsXx+vO0HzVq3gYd3hepl4Y0t7Bq84T6+T4dp+YuE8OGW4iwtNm44IIL5HK5TtqGDh1qZVlndeOQA1o4O16fz41X5rZoPf9QfRUedalHv4NWl2YqcpOb3KGL3KGZe/jbm9Spb47qNT2i5BYFuv2ZrTr4c7R2bawmSTriDdeKuXV0y9idat4pVw1bF2jQ09u0Y41bO9bGWVx9xQv18306Ts0Ne7C02Vi1apX27t0b2BYtWiRJ6tu3r5VlnVFEFb8ubH1Ea5f/+o+wYbi0bnmcWrQ/YmFl5iI3uclN7lDjxNxH847Pnq5avUSStGtjNfmKw9S88+HAMXUbH1V8vWPKCLFmw4nnW3JubtiHpc1GQkKCEhMTA9uCBQvUqFEjdenSxcqyzsgd71N4hHR4f/DlLocORKhGQolFVZmP3OSWyB2qyO2M3H6/NGdCqhpfkqt6TY//kundH6mISL9iPb6gY921ipWbE2lFmaZx2vk+wam5y+rEalR22kKFbS4QLyoq0jvvvKMRI0bI5XKd8pjCwkIVFhYGHnu93vNVHgAAldrsRxppz9ZYPfjeBqtLAeAgtrlAfP78+Tp8+LAGDRp02mPS0tLk8XgCW3Jy8vkr8L+8B8PlK5Gq/+7bgBq1SnRov216twpHbnJL5A5V5A793LPHpmrDkng9MGej4usWBfa7E4pUUhSmI7nhQcd7D1SRp3bR79+mUnPS+f4tp+aGfdim2Xj99dfVs2dPJSUlnfaYMWPGKDc3N7BlZWWdxwqPKykO07YNsWrXOS+wz+Uy1LZzvjavCd0l5MhNbnKTO9Q4IbdhHG801i2sqQfmbFRCg8Kg5xu2yld4Fb+2/Kd6YF/2jhgd/DlaqRfnKZQ44XyfilNzl5nVK0+F8GpUtmhpd+3apcWLF+v9998/43FRUVGKioo6T1Wd3vuv1NLIKVna+n2s0tfF6obB+xUd69fnc+KtLs1U5CY3uUMXuUMz9+xHGunbDxM09LXNiq7qU25OFUlSjNunyGi/Yt0+db51n+ZNSlHV6iWKqVaid8c3UqP2XjUKsWZDCv3zfTpOzQ17sEWzMWPGDNWuXVvXXXed1aWUyrKPashT06cBo7JVI6FEGZti9HD/FB0+UMXq0kxFbnKTO3SROzRzL327riTp6VtaB+0f9MxWdeqbI0m6dVyGXGEpmvbnZkE39QtFoX6+T8epuWEPLsMwLB2o8fv9SklJUb9+/fTEE0+U6bVer1cej0dd1VsRLv7CAAAqn1czV1hdgiUGN+hsdQk4T0qMYi3Vh8rNzZXb7ba6nCAnfpdsf+tkhUdGW11OgK/omNbMfdiWP7OysvyajcWLFyszM1N33HGH1aUAAAAAqECWT6Pq3r27LB5cAQAAAGACy5sNAAAAwFJ2WwHKTrWUk+XTqAAAAACEJpoNAAAAAKZgGhUAAAAczxVCU5fshJENAAAAAKag2QAAAABgCqZRAQAAwNkM4/hmF3aqpZwY2QAAAABgCpoNAAAAAKZgGhUAAAAczWXYazUqO9VSXoxsAAAAADAFzQYAAAAAUzCNCgAAAM5m/HezCzvVUk6MbAAAAAAwBc0GAAAAAFMwjQoAAACO5vIf3+zCTrWUFyMbAAAAAExBswEAAADAFEyjAgAAgLOxGpVpGNkAAAAAYAqaDQAAAACmYBoVAAAAHM1lHN/swk61lBcjGwAAAABMwcgGKpXwGjWsLsESvkOHrC4BgEkGN+hsdQmWeDhjvdUlWGJyalurSwDOK5oNAAAAOJthHN/swk61lBPTqAAAAACYgmYDAAAAgCmYRgUAAABHYzUq8zCyAQAAAMAUNBsAAAAATME0KgAAADib8d/NLuxUSzkxsgEAAADAFDQbAAAAAEzBNCoAAAA4GqtRmYeRDQAAAACmoNkAAAAAKrEJEybI5XIFbc2aNTvja/75z3+qWbNmio6OVqtWrfTpp5+aUhvNBgAAAJzNMOy3lVHLli21d+/ewLZixYrTHvv111+rX79+uvPOO7Vu3Tr16dNHffr00Q8//FCen+Ip0WwAAAAAlVxERIQSExMDW61atU577D/+8Q9de+21GjVqlJo3b65Jkybp4osv1tSpUyu8LpoNAAAAwIa8Xm/QVlhYeNpjt23bpqSkJKWmpqp///7KzMw87bErV65Ut27dgvb16NFDK1eurLDaT6DZAAAAgKOdWI3KTpskJScny+PxBLa0tLRT1t+hQwfNnDlTCxcu1LRp07Rz505dccUVysvLO+Xx2dnZqlOnTtC+OnXqKDs7u0J/rhJL3wIAAAC2lJWVJbfbHXgcFRV1yuN69uwZ+P+tW7dWhw4d1LBhQ82bN0933nmn6XWeCc0GAAAAYENutzuo2Sit6tWrq0mTJtq+ffspn09MTNS+ffuC9u3bt0+JiYnnVOeZMI0KAAAAzmbYcCuH/Px87dixQ3Xr1j3l8x07dtSSJUuC9i1atEgdO3Ys3wefAs0GAAAAUImNHDlSy5Yt008//aSvv/5aN9xwg8LDw9WvXz9J0oABAzRmzJjA8ffdd58WLlyoZ555Rj/++KMmTJig1atXa9iwYRVeG9OoAAAAgEps9+7d6tevn3755RclJCSoc+fO+uabb5SQkCBJyszMVFjYr2MMl19+uWbPnq1HHnlEf/vb33ThhRdq/vz5uuiiiyq8NpoNAAAAONpvV4Cyg7LWMmfOnDM+v3Tp0pP29e3bV3379i3bB50DplEBAAAAMAXNBgAAAABTMI0KAAAAzuY3jm92Yadayolm4xz1GnRAN9+do/iEEmVsjtFLj9RT+vpYq8syndNyX9T+sG66I0uNW+SpZu0iTbq3pVZ+kWB1WeeN0873CeQmN7krv8zvqmrlK7WV/UOs8nOq6ObpO9W0e27g+fz9EfryqSRlLI/TMW+4GlyWrx7jdys+pcjCqs0T6ucb9sU0qnPQ5fpDGjJ+j2Y9m6ihPZooY3O0Js/OkKdmsdWlmcqJuaNjfNqZXlUvPXah1aWcd0483xK5yU3uUFF0JEx1mh9Vj4m7T3rOMKR//SVFhzIj1fflDN21IF2eekWa9X+NVXQk9H41csL5hn1Z+jfK5/Np7NixSklJUUxMjBo1aqRJkybJMOw9dHTjkANaODten8+NV+a2aD3/UH0VHnWpR7+DVpdmKifmXr2ipt56PlUrlzhnNOMEJ55vidzkJneoaNw1T10fyFazHrknPXdwZ5R+XldVPSftVlKbo6qZWqiek3arpNClTR9XP//FmswJ57vcrL6BXwXf1M9OLG02nnzySU2bNk1Tp07Vli1b9OSTT+qpp57SCy+8YGVZZxRRxa8LWx/R2uVxgX2G4dK65XFq0f6IhZWZy6m5ncqp55vc5CZ36Ob+LV+RS5IUEeUP7HOFSeGRhnavrmZVWabgfMNqljYbX3/9tXr37q3rrrtOF1xwgW6++WZ1795d3333nZVlnZE73qfwCOnw/uDLXQ4diFCNhBKLqjKfU3M7lVPPN7nJLZHbCWo2OiZ3UpG+/HtdHc0Nl6/Ipa+n11be3kjl54TW5aycb1jN0mbj8ssv15IlS7R161ZJ0vfff68VK1aoZ8+epzy+sLBQXq83aAMAACiL8CrSzdN26ped0Xq2XSs92bK1dn1TTY26eLma1aFc+vXGfrbYrP6BVCBL2/fRo0fL6/WqWbNmCg8Pl8/n0+TJk9W/f/9THp+WlqaJEyee5yqDeQ+Gy1ciVf/dtwE1apXo0P7Q+jbkt5ya26mcer7JTW6J3E5Rt9VRDf4kXce8YfIVu1S1pk8zbrhQdVuF1tQizjesZmn/Pm/ePM2aNUuzZ8/W2rVr9eabb+rpp5/Wm2++ecrjx4wZo9zc3MCWlZV1niuWSorDtG1DrNp1zgvsc7kMte2cr81rQncJOafmdiqnnm9yk5vcoZv7dKLdflWt6dPBnZHauzFWTa4JrVkTnG9YzdKWdtSoURo9erT+9Kc/SZJatWqlXbt2KS0tTQMHDjzp+KioKEVFRZ3vMk/y/iu1NHJKlrZ+H6v0dbG6YfB+Rcf69fmceKtLM5UTc0fHliipwdHA4zr1jym1WZ7ycqto/95oCysznxPPt0RucpM7VBQVhOngrl9/ZzicFanszTGK8ZTIU69YWz71KDbeJ3dSkXLSo7Xo0fpqck2uUq/IO8O7Vk5OON/lZhjHN7uwUy3lZGmzceTIEYWFBQ+uhIeHy+/3n+YV9rDsoxry1PRpwKhs1UgoUcamGD3cP0WHD1SxujRTOTH3hS3z9OTM7wOPhzy0Q5K0aH4dPfdwc6vKOi+ceL4lcpOb3KFi78ZYvfP/GgceL55cT5LU+qaD6vX3TOXnVNGiyfVUcCBC1RJK1OrGg7pi2D6ryjWVE8437MtlWHhTi0GDBmnx4sV6+eWX1bJlS61bt05DhgzRHXfcoSeffPKsr/d6vfJ4POqq3opw8RfGCcJr1LC6BEv4Dh2yugQAqFAPZ6y3ugRLTE5ta3UJ512JUayl+lC5ublyu91WlxPkxO+Sna6eoIgI+8xYKCk5pv8smWDLn1lZWTqy8cILL2js2LG65557lJOTo6SkJP35z3/WuHHjrCwLAAAADnJiFSi7sFMt5WVpsxEXF6cpU6ZoypQpVpYBAAAAwASsJg0AAADAFCywDAAAAGcz/rvZhZ1qKSdGNgAAAACYgmYDAAAAgCmYRgUAAABHcxmGXDa6kZ6daikvRjYAAAAAmIJmAwAAAIApmEYFAAAAZ/P/d7MLO9VSToxsAAAAADAFzQYAAAAAUzCNCgAAAI7GalTmYWQDAAAAgCloNgAAAACYgmlUAAAAcDbjv5td2KmWcmJkAwAAAIApaDYAAAAAmIJpVAAAAHA2wzi+2YWdaiknRjYAAAAAmIJmAwAAAIApmEYFAAAAR3MZxze7sFMt5cXIBgAAAABT0GwAAAAAMAXTqAAAAOBsrEZlGpoNVCq+Q4esLgEAUAEmp7a1ugRLPJyx3uoSzruCPL+Wtra6CliFaVQAAAAATMHIBgAAABzN5T++2YWdaikvRjYAAAAAmIJmAwAAAIApmEYFAAAAZ2M1KtMwsgEAAADAFDQbAAAAAEzBNCoAAAA4m/HfzS7sVEs5MbIBAAAAwBQ0GwAAAABMwTQqAAAAOJrLMOSy0QpQdqqlvBjZAAAAAGAKmg0AAAAApmAaFQAAAJyNm/qZhpENAAAAAKag2QAAAABgCqZRAQAAwNkMSX6ri/iN0JlFxcgGAAAAAHPQbAAAAAAwBdOoAAAA4Gjc1M88jGwAAAAAMAXNBgAAAABTMI0KAAAAzmbIXjfSs1Ep5cXIBgAAAABT0GwAAAAAMAXTqM5Rr0EHdPPdOYpPKFHG5hi99Eg9pa+Ptbos05Gb3OQOXeQmN7krv8zvqmrlK7WV/UOs8nOq6ObpO9W0e27g+fz9EfryqSRlLI/TMW+4GlyWrx7jdys+pcjCqm3AMGw2jcpGtZQTIxvnoMv1hzRk/B7NejZRQ3s0UcbmaE2enSFPzWKrSzMVuclN7tBFbnKTOzQUHQlTneZH1WPi7pOeMwzpX39J0aHMSPV9OUN3LUiXp16RZv1fYxUd4VdCmMPSP1l5eXkaPny4GjZsqJiYGF1++eVatWqVlSWVyo1DDmjh7Hh9Pjdemdui9fxD9VV41KUe/Q5aXZqpyE1ucocucpOb3KGhcdc8dX0gW8165J703MGdUfp5XVX1nLRbSW2OqmZqoXpO2q2SQpc2fVz9/BcLR7C02bjrrru0aNEivf3229q4caO6d++ubt266eeff7ayrDOKqOLXha2PaO3yuMA+w3Bp3fI4tWh/xMLKzEVucpOb3KGG3OR2Qu7f8hW5JEkRUf7APleYFB5paPfqalaVZQ9+G24hwrJm4+jRo3rvvff01FNP6corr1Tjxo01YcIENW7cWNOmTbOqrLNyx/sUHiEd3h98ucuhAxGqkVBiUVXmIze5JXKHKnKTWyK3E9RsdEzupCJ9+fe6OpobLl+RS19Pr628vZHKz+EyXpjDsj9ZJSUl8vl8io6ODtofExOjFStWnPI1hYWFKiwsDDz2er2m1ggAABAqwqtIN0/bqQWjG+jZdq3kCjeU0ilPjbp4Q+m2DrAZy5qNuLg4dezYUZMmTVLz5s1Vp04dvfvuu1q5cqUaN258ytekpaVp4sSJ57nSYN6D4fKVSNV/9y1IjVolOrQ/dL8VIDe5JXKHKnKTWyK3U9RtdVSDP0nXMW+YfMUuVa3p04wbLlTdVs6YSnY6LsOQy0YrQNmplvKy9JqNt99+W4ZhqF69eoqKitLzzz+vfv36KSzs1GWNGTNGubm5gS0rK+s8VyyVFIdp24ZYteucF9jnchlq2zlfm9eEztJ5v0ducpOb3KGG3OR2Qu7TiXb7VbWmTwd3Rmrvxlg1uYbZIjCHpa18o0aNtGzZMhUUFMjr9apu3bq69dZblZqaesrjo6KiFBUVdZ6rPNn7r9TSyClZ2vp9rNLXxeqGwfsVHevX53PirS7NVOQmN7lDF7nJTe7QUFQQpoO7fv1d6XBWpLI3xyjGUyJPvWJt+dSj2Hif3ElFykmP1qJH66vJNblKvSLvDO8KnDtbjBtWrVpVVatW1aFDh/TZZ5/pqaeesrqkM1r2UQ15avo0YFS2aiSUKGNTjB7un6LDB6pYXZqpyE1ucocucpOb3KFh78ZYvfP/fp2OvnhyPUlS65sOqtffM5WfU0WLJtdTwYEIVUsoUasbD+qKYfusKtc+uKmfaVyGYV2azz77TIZhqGnTptq+fbtGjRql6OhoLV++XFWqnP0vvtfrlcfjUVf1VoQrdP6hAAAAoenhjPVWl3DeFeT59cfWGcrNzZXb7ba6nCAnfpe8uuUoRYRbP3vmhBJfoZZs+rstf2ZlZek1G7m5uRo6dKiaNWumAQMGqHPnzvrss89K1WgAAAAAsDdLp1HdcsstuuWWW6wsAQAAAE7HNCrTWDqyAQAAACB00WwAAAAAMIUtVqMCAAAALMM0KtMwsgEAAABUYmlpabr00ksVFxen2rVrq0+fPkpPTz/ja2bOnCmXyxW0RUdHV3htNBsAAABAJbZs2TINHTpU33zzjRYtWqTi4mJ1795dBQUFZ3yd2+3W3r17A9uuXbsqvDamUQEAAMDZ/JJcVhfxG/6yHb5w4cKgxzNnzlTt2rW1Zs0aXXnllad9ncvlUmJi4rlUWGqMbAAAAAA25PV6g7bCwsJSvS43N1eSFB8ff8bj8vPz1bBhQyUnJ6t3797atGlTuWv+PZoNAAAAwIaSk5Pl8XgCW1pa2llf4/f7NXz4cHXq1EkXXXTRaY9r2rSp3njjDX344Yd655135Pf7dfnll2v37t0VGYFpVAAAAHA2l2HIZaMVoE7UkpWVJbfbHdgfFRV11tcOHTpUP/zwg1asWHHG4zp27KiOHTsGHl9++eVq3ry5Xn75ZU2aNOkcKz8ZzQYAAABgQ263O6jZOJthw4ZpwYIF+uqrr1S/fv0yfVaVKlXUrl07bd++vaxlnhHTqAAAAIBKzDAMDRs2TB988IG++OILpaSklPk9fD6fNm7cqLp161ZobYxsAAAAwNkq+U39hg4dqtmzZ+vDDz9UXFycsrOzJUkej0cxMTGSpAEDBqhevXqB6z4effRR/eEPf1Djxo11+PBh/f3vf9euXbt01113VWgUmg0AAACgEps2bZokqWvXrkH7Z8yYoUGDBkmSMjMzFRb266SmQ4cOafDgwcrOzlaNGjXUvn17ff3112rRokWF1kazAQAAAFRiRilGQpYuXRr0+LnnntNzzz1nUkW/otkAAACAs/kNyWWjaVR+G9VSTlwgDgAAAMAUNBsAAAAATME0KgAAADhbJV+Nys4Y2QAAAABgCpoNAAAAAKZgGhUAAAAczmbTqGSnWsqHkQ0AAAAApqDZAAAAAGCKSj2N6sTdEt/Omiq3221xNQAAAPg9b4RXUnKp7nJtGVajMk2lbjby8vIkScnJyRZXAgAAgDPJy8uTx+OxugycZ5W62UhKSlJWVpbi4uLkcrnO62d7vV4lJycrKyvLUaMq5Ca3E5Cb3E5AbnKfL4ZhKC8vT0lJSef1c2EPlbrZCAsLU/369S2twe12O+ofqxPI7SzkdhZyOwu5ncWq3LYf0fAbstUKUH4b1VJOXCAOAAAAwBQ0GwAAAABMUamnUVkpKipK48ePV1RUlNWlnFfkJrcTkJvcTkBucuM3DP/xzS7sVEs5uQxbr0MGAAAAmMPr9crj8ahbg3sUEWafRqzEX6jFmS8pNze30l9bxDQqAAAAAKZgGhUAAACcjZv6mYaRDQAAAACmoNkAAAAAYAqajXP04osv6oILLlB0dLQ6dOig7777zuqSTPXVV1+pV69eSkpKksvl0vz5860u6bxIS0vTpZdeqri4ONWuXVt9+vRRenq61WWZbtq0aWrdunXg5k8dO3bUv//9b6vLOq+eeOIJuVwuDR8+3OpSTDdhwgS5XK6grVmzZlaXdV78/PPPuu2221SzZk3FxMSoVatWWr16tdVlmeqCCy446Xy7XC4NHTrU6tJM5fP5NHbsWKWkpCgmJkaNGjXSpEmT5IR1cvLy8jR8+HA1bNhQMTExuvzyy7Vq1Sqry7IXv2G/LUTQbJyDuXPnasSIERo/frzWrl2rNm3aqEePHsrJybG6NNMUFBSoTZs2evHFF60u5bxatmyZhg4dqm+++UaLFi1ScXGxunfvroKCAqtLM1X9+vX1xBNPaM2aNVq9erX+53/+R71799amTZusLu28WLVqlV5++WW1bt3a6lLOm5YtW2rv3r2BbcWKFVaXZLpDhw6pU6dOqlKliv79739r8+bNeuaZZ1SjRg2rSzPVqlWrgs71okWLJEl9+/a1uDJzPfnkk5o2bZqmTp2qLVu26Mknn9RTTz2lF154werSTHfXXXdp0aJFevvtt7Vx40Z1795d3bp1088//2x1aXAAlr49Bx06dNCll16qqVOnSpL8fr+Sk5N17733avTo0RZXZz6Xy6UPPvhAffr0sbqU827//v2qXbu2li1bpiuvvNLqcs6r+Ph4/f3vf9edd95pdSmmys/P18UXX6yXXnpJjz32mNq2baspU6ZYXZapJkyYoPnz52v9+vVWl3JejR49Wv/5z3+0fPlyq0ux1PDhw7VgwQJt27ZNLpfL6nJM88c//lF16tTR66+/Hth30003KSYmRu+8846FlZnr6NGjiouL04cffqjrrrsusL99+/bq2bOnHnvsMQurs15g6dt6f7Hf0rc/T2fpWycqKirSmjVr1K1bt8C+sLAwdevWTStXrrSwMpwPubm5ko7/4u0UPp9Pc+bMUUFBgTp27Gh1OaYbOnSorrvuuqC/406wbds2JSUlKTU1Vf3791dmZqbVJZnuo48+0iWXXKK+ffuqdu3aateunV599VWryzqvioqK9M477+iOO+4I6UZDki6//HItWbJEW7dulSR9//33WrFihXr27GlxZeYqKSmRz+dTdHR00P6YmBhHjGCW2onVqOy0hQiWvi2jAwcOyOfzqU6dOkH769Spox9//NGiqnA++P1+DR8+XJ06ddJFF11kdTmm27hxozp27Khjx46pWrVq+uCDD9SiRQuryzLVnDlztHbtWsfNZe7QoYNmzpyppk2bau/evZo4caKuuOIK/fDDD4qLi7O6PNNkZGRo2rRpGjFihP72t79p1apV+utf/6rIyEgNHDjQ6vLOi/nz5+vw4cMaNGiQ1aWYbvTo0fJ6vWrWrJnCw8Pl8/k0efJk9e/f3+rSTBUXF6eOHTtq0qRJat68uerUqaN3331XK1euVOPGja0uDw5AswGU0tChQ/XDDz845pugpk2bav369crNzdW//vUvDRw4UMuWLQvZhiMrK0v33XefFi1adNI3gKHut9/stm7dWh06dFDDhg01b968kJ425/f7dckll+jxxx+XJLVr104//PCDpk+f7phm4/XXX1fPnj2VlJRkdSmmmzdvnmbNmqXZs2erZcuWWr9+vYYPH66kpKSQP99vv/227rjjDtWrV0/h4eG6+OKL1a9fP61Zs8bq0uAANBtlVKtWLYWHh2vfvn1B+/ft26fExESLqoLZhg0bpgULFuirr75S/fr1rS7nvIiMjAx869W+fXutWrVK//jHP/Tyyy9bXJk51qxZo5ycHF188cWBfT6fT1999ZWmTp2qwsJChYeHW1jh+VO9enU1adJE27dvt7oUU9WtW/ek5rl58+Z67733LKro/Nq1a5cWL16s999/3+pSzotRo0Zp9OjR+tOf/iRJatWqlXbt2qW0tLSQbzYaNWqkZcuWqaCgQF6vV3Xr1tWtt96q1NRUq0uzD0P2mrpko1LKi2s2yigyMlLt27fXkiVLAvv8fr+WLFniiPnsTmMYhoYNG6YPPvhAX3zxhVJSUqwuyTJ+v1+FhYVWl2Gaq6++Whs3btT69esD2yWXXKL+/ftr/fr1jmk0pOMXye/YsUN169a1uhRTderU6aSlrLdu3aqGDRtaVNH5NWPGDNWuXTvoouFQduTIEYWFBf/aEx4eLr/fb1FF51/VqlVVt25dHTp0SJ999pl69+5tdUlwAEY2zsGIESM0cOBAXXLJJbrssss0ZcoUFRQU6Pbbb7e6NNPk5+cHfcu5c+dOrV+/XvHx8WrQoIGFlZlr6NChmj17tj788EPFxcUpOztbkuTxeBQTE2NxdeYZM2aMevbsqQYNGigvL0+zZ8/W0qVL9dlnn1ldmmni4uJOuhanatWqqlmzZshfozNy5Ej16tVLDRs21J49ezR+/HiFh4erX79+Vpdmqvvvv1+XX365Hn/8cd1yyy367rvv9Morr+iVV16xujTT+f1+zZgxQwMHDlREhDN+FejVq5cmT56sBg0aqGXLllq3bp2effZZ3XHHHVaXZrrPPvtMhmGoadOm2r59u0aNGqVmzZqF9O8tsA9n/AtTwW699Vbt379f48aNU3Z2ttq2bauFCxeedNF4KFm9erWuuuqqwOMRI0ZIkgYOHKiZM2daVJX5pk2bJknq2rVr0P4ZM2aE9AWVOTk5GjBggPbu3SuPx6PWrVvrs88+0zXXXGN1aTDB7t271a9fP/3yyy9KSEhQ586d9c033yghIcHq0kx16aWX6oMPPtCYMWP06KOPKiUlRVOmTAn5C4YlafHixcrMzHTEL9onvPDCCxo7dqzuuece5eTkKCkpSX/+8581btw4q0szXW5ursaMGaPdu3crPj5eN910kyZPnqwqVapYXZp92G0FKDvVUk7cZwMAAACOFLjPRuIQRYRFWl1OQIm/SIuzX+E+GwAAAABwOkyjAgAAgLP5/ZJstFhACC1cwMgGAAAAAFPQbAAAAAAwBdOoAAAA4GysRmUaRjYAAAAAmIJmAwAAAIApaDYAoIwGDRqkPn36BB537dpVw4cPP+91LF26VC6XS4cPHz7tMS6XS/Pnzy/1e06YMEFt27YtV10//fSTXC6X1q9fX673AYDz5sQ0KjttIYJmA0BIGDRokFwul1wulyIjI9W4cWM9+uijKikpMf2z33//fU2aNKlUx5amQQAAIFRwgTiAkHHttddqxowZKiws1KeffqqhQ4eqSpUqGjNmzEnHFhUVKTKyYu4WGx8fXyHvAwBAqGFkA0DIiIqKUmJioho2bKi7775b3bp100cffSTp16lPkydPVlJSkpo2bSpJysrK0i233KLq1asrPj5evXv31k8//RR4T5/PpxEjRqh69eqqWbOmHnzwQRm/G97+/TSqwsJCPfTQQ0pOTlZUVJQaN26s119/XT/99JOuuuoqSVKNGjXkcrk0aNAgSZLf71daWppSUlIUExOjNm3a6F//+lfQ53z66adq0qSJYmJidNVVVwXVWVoPPfSQmjRpotjYWKWmpmrs2LEqLi4+6biXX35ZycnJio2N1S233KLc3Nyg51977TU1b95c0dHRatasmV566aUy1wIAtuE37LeFCJoNACErJiZGRUVFgcdLlixRenq6Fi1apAULFqi4uFg9evRQXFycli9frv/85z+qVq2arr322sDrnnnmGc2cOVNvvPGGVqxYoYMHD+qDDz444+cOGDBA7777rp5//nlt2bJFL7/8sqpVq6bk5GS99957kqT09HTt3btX//jHPyRJaWlpeuuttzR9+nRt2rRJ999/v2677TYtW7ZM0vGm6MYbb1SvXr20fv163XXXXRo9enSZfyZxcXGaOXOmNm/erH/84x969dVX9dxzzwUds337ds2bN08ff/yxFi5cqHXr1umee+4JPD9r1iyNGzdOkydP1pYtW/T4449r7NixevPNN8tcDwAgtDGNCkDIMQxDS5Ys0WeffaZ77703sL9q1ap67bXXAtOn3nnnHfn9fr322mtyuVySpBkzZqh69epaunSpunfvrilTpmjMmDG68cYbJUnTp0/XZ599dtrP3rp1q+bNm6dFixapW7dukqTU1NTA8yemXNWuXVvVq1eXdHwk5PHHH9fixYvVsWPHwGtWrFihl19+WV26dNG0adPUqFEjPfPMM5Kkpk2bauPGjXryySfL9LN55JFHAv//ggsu0MiRIzVnzhw9+OCDgf3Hjh3TW2+9pXr16kmSXnjhBV133XV65plnlJiYqPHjx+uZZ54J/ExSUlK0efNmvfzyyxo4cGCZ6gEAhDaaDQAhY8GCBapWrZqKi4vl9/v1//7f/9OECRMCz7dq1SroOo3vv/9e27dvV1xcXND7HDt2TDt27FBubq727t2rDh06BJ6LiIjQJZdcctJUqhPWr1+v8PBwdenSpdR1b9++XUeOHNE111wTtL+oqEjt2rWTJG3ZsiWoDkmBxqQs5s6dq+eff147duxQfn6+SkpK5Ha7g45p0KBBoNE48Tl+v1/p6emKi4vTjh07dOedd2rw4MGBY0pKSuTxeMpcDwDYgWH4ZRh+q8sIsFMt5UWzASBkXHXVVZo2bZoiIyOVlJSkiIjgf+KqVq0a9Dg/P1/t27fXrFmzTnqvhISEc6ohJiamzK/Jz8+XJH3yySdBv+RLx69DqSgrV65U//79NXHiRPXo0UMej0dz5swJjJaUpdZXX331pOYnPDy8wmoFAIQGmg0AIaNq1apq3LhxqY+/+OKLNXfuXNWuXfukb/dPqFu3rr799ltdeeWVko5/g79mzRpdfPHFpzy+VatW8vv9WrZsWWAa1W+dGFnx+XyBfS1atFBUVJQyMzNPOyLSvHnzwMXuJ3zzzTdnD/kbX3/9tRo2bKiHH344sG/Xrl0nHZeZmak9e/YoKSkp8DlhYWFq2rSp6tSpo6SkJGVkZKh///5l+nwAgPNwgTgAx+rfv79q1aql3r17a/ny5dq5c6eWLl2qv/71r9q9e7ck6b777tMTTzyh+fPn68cff9Q999xzxntkXHDBBRo4cKDuuOMOzZ8/P/Ce8+bNkyQ1bNhQLpdLCxYs0P79+5Wfn6+4uDiNHDlS999/v958803t2LFDa9eu1QsvvBC46Povf/mLtm3bplGjRik9PV2zZ8/WzJkzy5T3wgsvVGZmpubMmaMdO3bo+eefP+XF7tHR0Ro4cKC+//57LV++XH/96191yy23KDExUZI0ceJEpaWl6fnnn9fWrVu1ceNGzZgxQ88++2yZ6gEA2zBssPrUbzdu6gcAlV9sbKy++uorNWjQQDfeeKOaN2+uO++8U8eOHQuMdDzwwAP6v//7Pw0cOFAdO3ZUXFycbrjhhjO+77Rp03TzzTfrnnvuUbNmzTR48GAVFBRIkurVq6eJEydq9OjRqlOnjoYNGyZJmjRpksaOHau0tDQ1b95c1157rT755BOlpKRIOn4dxXvvvaf58+erTZs2mj59uh5//PEy5b3++ut1//33a9iwYWrbtq2+/vprjR079qTjGjdurBtvvFH/+7//q+7du6t169ZBS9veddddeu211zRjxgy1atVKXbp00cyZMwO1AgBwgss43VWOAAAAQAjzer3yeDy6uvoARbgq5kavFaHEKNKSw28pNzf3tNN8Kwuu2QAAAICzGYYkG33/HkJjAUyjAgAAAGAKmg0AAAAApmAaFQAAAJzN75dcNrqRXgjd1I+RDQAAAACmoNkAAAAAYAqmUQEAAMDZWI3KNIxsAAAAADAFzQYAAAAAUzCNCgAAAI5m+P0ybLQalcFqVAAAAABwZjQbAAAAAEzBNCoAAAA4G6tRmYaRDQAAAACmoNkAAAAAYAqmUQEAAMDZ/IbkstHUJaZRAQAAAMCZ0WwAAAAAMAXTqAAAAOBshiHJRjfSYxoVAAAAAJwZzQYAAAAAUzCNCgAAAI5m+A0ZNlqNymAaFQAAAACcGc0GAAAAAFMwjQoAAADOZvhlr9WobFRLOTGyAQAAAMAUNBsAAAAATME0KgAAADgaq1GZh5ENAAAAAKag2QAAAABgCpoNAAAAOJvht992Dl588UVdcMEFio6OVocOHfTdd9+d8fh//vOfatasmaKjo9WqVSt9+umn5/S5Z0KzAQAAAFRyc+fO1YgRIzR+/HitXbtWbdq0UY8ePZSTk3PK47/++mv169dPd955p9atW6c+ffqoT58++uGHHyq0LpcRSlegAAAAAKXk9Xrl8XjUVb0V4apidTkBJUaxlupD5ebmyu12l+o1HTp00KWXXqqpU6dKkvx+v5KTk3Xvvfdq9OjRJx1/6623qqCgQAsWLAjs+8Mf/qC2bdtq+vTpFRNErEYFAAAAhytRsWSjr99LVCzpeDP0W1FRUYqKijrp+KKiIq1Zs0ZjxowJ7AsLC1O3bt20cuXKU37GypUrNWLEiKB9PXr00Pz588tZfTCaDQAAADhSZGSkEhMTtSK74q9VKK9q1aopOTk5aN/48eM1YcKEk449cOCAfD6f6tSpE7S/Tp06+vHHH0/5/tnZ2ac8Pjs7u3yF/w7NBgAAABwpOjpaO3fuVFFRkdWlnMQwDLlcrqB9pxrVsDuaDQAAADhWdHS0oqOjrS6jXGrVqqXw8HDt27cvaP++ffuUmJh4ytckJiaW6fhzxWpUAAAAQCUWGRmp9u3ba8mSJYF9fr9fS5YsUceOHU/5mo4dOwYdL0mLFi067fHnipENAAAAoJIbMWKEBg4cqEsuuUSXXXaZpkyZooKCAt1+++2SpAEDBqhevXpKS0uTJN13333q0qWLnnnmGV133XWaM2eOVq9erVdeeaVC66LZAAAAACq5W2+9Vfv379e4ceOUnZ2ttm3bauHChYGLwDMzMxUW9uukpssvv1yzZ8/WI488or/97W+68MILNX/+fF100UUVWhf32QAAAABgCq7ZAAAAAGAKmg0AAAAApqDZAAAAAGAKmg0AAAAApqDZAAAAAGAKmg0AAAAApqDZAAAAAGAKmg0AAAAApqDZAAAAAGAKmg0AAAAApqDZAAAAAGCK/w9aJNwxLT4O1wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "ConfusionMatrixDisplay.from_estimator(clf, scaler.transform(x_test), y_test, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(clf, scaled, y_train, cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95      , 0.975     , 0.975     , 0.975     , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.975     , 0.95      ,\n",
       "       0.95      , 1.        , 0.975     , 0.9       , 1.        ,\n",
       "       0.975     , 0.975     , 1.        , 0.97435897, 1.        ])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9774679487179487"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  a little better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's look at mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_examples = y_test != clf.predict(scaler.transform(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_images = np.array(x_test)[bad_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = np.array(y_test)[bad_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = clf.predict(scaler.transform(bad_images))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try small convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2545628e3f0>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 300\n",
    "batch_size_train = 10\n",
    "batch_size_test = 10\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor, Compose, Normalize, Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([ToTensor(), Resize((16, 25)), Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchvision.datasets.ImageFolder(root=dir, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset, val_subset = torch.utils.data.random_split(\n",
    "        data, [int(len(data) * 0.8), len(data) - (int(len(data) * 0.8))], generator=torch.Generator().manual_seed(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(60, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(x.size(0), 60)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return nn.LogSoftmax(dim=1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "network  = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=60, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, network, optimizer, train_loader):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data.cuda())\n",
    "    loss = F.nll_loss(output, target.cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "\n",
    "def test(network, test_loader):\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data.cuda()).cpu()\n",
    "      test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n",
    "  return 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "def training_experiment(n_epochs,network, optimizer, train_loader, test_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train(epoch, network, optimizer, train_loader)\n",
    "        test(network, test_loader)\n",
    "    return test(network, test_loader), network\n",
    "\n",
    "def get_dataloaders_splits(data):\n",
    "  train_subset, val_subset = torch.utils.data.random_split(\n",
    "            data, [int(len(data) * 0.8), len(data) - (int(len(data) * 0.8))], generator=torch.Generator())\n",
    "  train_loader = torch.utils.data.DataLoader(train_subset, batch_size=batch_size_train, shuffle=True)\n",
    "  test_loader = torch.utils.data.DataLoader(val_subset, batch_size=batch_size_train, shuffle=True)\n",
    "  return train_loader, test_loader\n",
    "\n",
    "def get_model():\n",
    "  network  = Net()\n",
    "  optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                        momentum=momentum)\n",
    "  network.cuda()\n",
    "  return network, optimizer\n",
    "\n",
    "def bootstrap_experiment(n_epochs, n):\n",
    "    results = []\n",
    "    for i in range(n):\n",
    "        print(\"Running bootstrap experiment: \" + str(i))\n",
    "        network, optimizer = get_model()\n",
    "        train_loader, test_loader = get_dataloaders_splits(data)\n",
    "        result, model = training_experiment(n_epochs, network, optimizer, train_loader, test_loader)\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running bootstrap experiment: 0\n",
      "Train Epoch: 1 [0/798 (0%)]\tLoss: 2.358800\n",
      "Train Epoch: 1 [100/798 (12%)]\tLoss: 2.245432\n",
      "Train Epoch: 1 [200/798 (25%)]\tLoss: 2.272980\n",
      "Train Epoch: 1 [300/798 (38%)]\tLoss: 2.369586\n",
      "Train Epoch: 1 [400/798 (50%)]\tLoss: 2.324393\n",
      "Train Epoch: 1 [500/798 (62%)]\tLoss: 2.311904\n",
      "Train Epoch: 1 [600/798 (75%)]\tLoss: 2.321509\n",
      "Train Epoch: 1 [700/798 (88%)]\tLoss: 2.377161\n",
      "\n",
      "Test set: Avg. loss: 2.2761, Accuracy: 43/200 (22%)\n",
      "\n",
      "Train Epoch: 2 [0/798 (0%)]\tLoss: 2.290271\n",
      "Train Epoch: 2 [100/798 (12%)]\tLoss: 2.313030\n",
      "Train Epoch: 2 [200/798 (25%)]\tLoss: 2.268588\n",
      "Train Epoch: 2 [300/798 (38%)]\tLoss: 2.305645\n",
      "Train Epoch: 2 [400/798 (50%)]\tLoss: 2.284916\n",
      "Train Epoch: 2 [500/798 (62%)]\tLoss: 2.327997\n",
      "Train Epoch: 2 [600/798 (75%)]\tLoss: 2.219756\n",
      "Train Epoch: 2 [700/798 (88%)]\tLoss: 2.293387\n",
      "\n",
      "Test set: Avg. loss: 2.2334, Accuracy: 48/200 (24%)\n",
      "\n",
      "Train Epoch: 3 [0/798 (0%)]\tLoss: 2.253511\n",
      "Train Epoch: 3 [100/798 (12%)]\tLoss: 2.197968\n",
      "Train Epoch: 3 [200/798 (25%)]\tLoss: 2.079638\n",
      "Train Epoch: 3 [300/798 (38%)]\tLoss: 2.292723\n",
      "Train Epoch: 3 [400/798 (50%)]\tLoss: 2.193038\n",
      "Train Epoch: 3 [500/798 (62%)]\tLoss: 2.154116\n",
      "Train Epoch: 3 [600/798 (75%)]\tLoss: 2.219502\n",
      "Train Epoch: 3 [700/798 (88%)]\tLoss: 2.136830\n",
      "\n",
      "Test set: Avg. loss: 2.1121, Accuracy: 60/200 (30%)\n",
      "\n",
      "Train Epoch: 4 [0/798 (0%)]\tLoss: 2.011954\n",
      "Train Epoch: 4 [100/798 (12%)]\tLoss: 2.041710\n",
      "Train Epoch: 4 [200/798 (25%)]\tLoss: 2.014598\n",
      "Train Epoch: 4 [300/798 (38%)]\tLoss: 2.284703\n",
      "Train Epoch: 4 [400/798 (50%)]\tLoss: 2.087803\n",
      "Train Epoch: 4 [500/798 (62%)]\tLoss: 2.013853\n",
      "Train Epoch: 4 [600/798 (75%)]\tLoss: 2.221358\n",
      "Train Epoch: 4 [700/798 (88%)]\tLoss: 2.136705\n",
      "\n",
      "Test set: Avg. loss: 1.8648, Accuracy: 97/200 (48%)\n",
      "\n",
      "Train Epoch: 5 [0/798 (0%)]\tLoss: 1.947695\n",
      "Train Epoch: 5 [100/798 (12%)]\tLoss: 1.869165\n",
      "Train Epoch: 5 [200/798 (25%)]\tLoss: 2.000158\n",
      "Train Epoch: 5 [300/798 (38%)]\tLoss: 1.698134\n",
      "Train Epoch: 5 [400/798 (50%)]\tLoss: 1.560045\n",
      "Train Epoch: 5 [500/798 (62%)]\tLoss: 1.777748\n",
      "Train Epoch: 5 [600/798 (75%)]\tLoss: 2.000569\n",
      "Train Epoch: 5 [700/798 (88%)]\tLoss: 2.100642\n",
      "\n",
      "Test set: Avg. loss: 1.4321, Accuracy: 143/200 (72%)\n",
      "\n",
      "Train Epoch: 6 [0/798 (0%)]\tLoss: 1.671878\n",
      "Train Epoch: 6 [100/798 (12%)]\tLoss: 1.865198\n",
      "Train Epoch: 6 [200/798 (25%)]\tLoss: 1.542541\n",
      "Train Epoch: 6 [300/798 (38%)]\tLoss: 1.887673\n",
      "Train Epoch: 6 [400/798 (50%)]\tLoss: 1.702160\n",
      "Train Epoch: 6 [500/798 (62%)]\tLoss: 1.560858\n",
      "Train Epoch: 6 [600/798 (75%)]\tLoss: 1.544604\n",
      "Train Epoch: 6 [700/798 (88%)]\tLoss: 1.377461\n",
      "\n",
      "Test set: Avg. loss: 1.0691, Accuracy: 159/200 (80%)\n",
      "\n",
      "Train Epoch: 7 [0/798 (0%)]\tLoss: 1.817978\n",
      "Train Epoch: 7 [100/798 (12%)]\tLoss: 1.290968\n",
      "Train Epoch: 7 [200/798 (25%)]\tLoss: 1.394336\n",
      "Train Epoch: 7 [300/798 (38%)]\tLoss: 1.002268\n",
      "Train Epoch: 7 [400/798 (50%)]\tLoss: 1.189847\n",
      "Train Epoch: 7 [500/798 (62%)]\tLoss: 1.744905\n",
      "Train Epoch: 7 [600/798 (75%)]\tLoss: 1.380629\n",
      "Train Epoch: 7 [700/798 (88%)]\tLoss: 1.333804\n",
      "\n",
      "Test set: Avg. loss: 0.7997, Accuracy: 172/200 (86%)\n",
      "\n",
      "Train Epoch: 8 [0/798 (0%)]\tLoss: 1.352427\n",
      "Train Epoch: 8 [100/798 (12%)]\tLoss: 1.387591\n",
      "Train Epoch: 8 [200/798 (25%)]\tLoss: 1.294746\n",
      "Train Epoch: 8 [300/798 (38%)]\tLoss: 1.138077\n",
      "Train Epoch: 8 [400/798 (50%)]\tLoss: 1.570467\n",
      "Train Epoch: 8 [500/798 (62%)]\tLoss: 1.443994\n",
      "Train Epoch: 8 [600/798 (75%)]\tLoss: 1.129857\n",
      "Train Epoch: 8 [700/798 (88%)]\tLoss: 1.327264\n",
      "\n",
      "Test set: Avg. loss: 0.6728, Accuracy: 163/200 (82%)\n",
      "\n",
      "Train Epoch: 9 [0/798 (0%)]\tLoss: 0.844733\n",
      "Train Epoch: 9 [100/798 (12%)]\tLoss: 1.145197\n",
      "Train Epoch: 9 [200/798 (25%)]\tLoss: 1.047990\n",
      "Train Epoch: 9 [300/798 (38%)]\tLoss: 0.756642\n",
      "Train Epoch: 9 [400/798 (50%)]\tLoss: 1.173158\n",
      "Train Epoch: 9 [500/798 (62%)]\tLoss: 1.159212\n",
      "Train Epoch: 9 [600/798 (75%)]\tLoss: 1.561805\n",
      "Train Epoch: 9 [700/798 (88%)]\tLoss: 1.013585\n",
      "\n",
      "Test set: Avg. loss: 0.5579, Accuracy: 171/200 (86%)\n",
      "\n",
      "Train Epoch: 10 [0/798 (0%)]\tLoss: 1.016669\n",
      "Train Epoch: 10 [100/798 (12%)]\tLoss: 0.662454\n",
      "Train Epoch: 10 [200/798 (25%)]\tLoss: 0.555864\n",
      "Train Epoch: 10 [300/798 (38%)]\tLoss: 0.418864\n",
      "Train Epoch: 10 [400/798 (50%)]\tLoss: 0.841242\n",
      "Train Epoch: 10 [500/798 (62%)]\tLoss: 0.957027\n",
      "Train Epoch: 10 [600/798 (75%)]\tLoss: 0.765947\n",
      "Train Epoch: 10 [700/798 (88%)]\tLoss: 1.209612\n",
      "\n",
      "Test set: Avg. loss: 0.4337, Accuracy: 176/200 (88%)\n",
      "\n",
      "Train Epoch: 11 [0/798 (0%)]\tLoss: 1.566659\n",
      "Train Epoch: 11 [100/798 (12%)]\tLoss: 1.214439\n",
      "Train Epoch: 11 [200/798 (25%)]\tLoss: 0.914096\n",
      "Train Epoch: 11 [300/798 (38%)]\tLoss: 1.110502\n",
      "Train Epoch: 11 [400/798 (50%)]\tLoss: 0.773906\n",
      "Train Epoch: 11 [500/798 (62%)]\tLoss: 0.666644\n",
      "Train Epoch: 11 [600/798 (75%)]\tLoss: 0.685997\n",
      "Train Epoch: 11 [700/798 (88%)]\tLoss: 1.004154\n",
      "\n",
      "Test set: Avg. loss: 0.3321, Accuracy: 186/200 (93%)\n",
      "\n",
      "Train Epoch: 12 [0/798 (0%)]\tLoss: 0.664771\n",
      "Train Epoch: 12 [100/798 (12%)]\tLoss: 0.587204\n",
      "Train Epoch: 12 [200/798 (25%)]\tLoss: 0.830882\n",
      "Train Epoch: 12 [300/798 (38%)]\tLoss: 1.038634\n",
      "Train Epoch: 12 [400/798 (50%)]\tLoss: 0.910701\n",
      "Train Epoch: 12 [500/798 (62%)]\tLoss: 1.546598\n",
      "Train Epoch: 12 [600/798 (75%)]\tLoss: 0.382455\n",
      "Train Epoch: 12 [700/798 (88%)]\tLoss: 0.845499\n",
      "\n",
      "Test set: Avg. loss: 0.3218, Accuracy: 193/200 (96%)\n",
      "\n",
      "Train Epoch: 13 [0/798 (0%)]\tLoss: 0.404806\n",
      "Train Epoch: 13 [100/798 (12%)]\tLoss: 0.796481\n",
      "Train Epoch: 13 [200/798 (25%)]\tLoss: 0.724560\n",
      "Train Epoch: 13 [300/798 (38%)]\tLoss: 0.652506\n",
      "Train Epoch: 13 [400/798 (50%)]\tLoss: 1.164815\n",
      "Train Epoch: 13 [500/798 (62%)]\tLoss: 0.768866\n",
      "Train Epoch: 13 [600/798 (75%)]\tLoss: 0.609697\n",
      "Train Epoch: 13 [700/798 (88%)]\tLoss: 0.827801\n",
      "\n",
      "Test set: Avg. loss: 0.2603, Accuracy: 190/200 (95%)\n",
      "\n",
      "Train Epoch: 14 [0/798 (0%)]\tLoss: 0.743288\n",
      "Train Epoch: 14 [100/798 (12%)]\tLoss: 0.600051\n",
      "Train Epoch: 14 [200/798 (25%)]\tLoss: 0.866341\n",
      "Train Epoch: 14 [300/798 (38%)]\tLoss: 0.660648\n",
      "Train Epoch: 14 [400/798 (50%)]\tLoss: 0.165735\n",
      "Train Epoch: 14 [500/798 (62%)]\tLoss: 0.189364\n",
      "Train Epoch: 14 [600/798 (75%)]\tLoss: 0.683001\n",
      "Train Epoch: 14 [700/798 (88%)]\tLoss: 0.987684\n",
      "\n",
      "Test set: Avg. loss: 0.1962, Accuracy: 193/200 (96%)\n",
      "\n",
      "Train Epoch: 15 [0/798 (0%)]\tLoss: 0.712118\n",
      "Train Epoch: 15 [100/798 (12%)]\tLoss: 0.270740\n",
      "Train Epoch: 15 [200/798 (25%)]\tLoss: 0.438785\n",
      "Train Epoch: 15 [300/798 (38%)]\tLoss: 0.713747\n",
      "Train Epoch: 15 [400/798 (50%)]\tLoss: 1.104679\n",
      "Train Epoch: 15 [500/798 (62%)]\tLoss: 0.731602\n",
      "Train Epoch: 15 [600/798 (75%)]\tLoss: 0.167081\n",
      "Train Epoch: 15 [700/798 (88%)]\tLoss: 0.896885\n",
      "\n",
      "Test set: Avg. loss: 0.2016, Accuracy: 190/200 (95%)\n",
      "\n",
      "Train Epoch: 16 [0/798 (0%)]\tLoss: 0.404253\n",
      "Train Epoch: 16 [100/798 (12%)]\tLoss: 0.581225\n",
      "Train Epoch: 16 [200/798 (25%)]\tLoss: 0.289291\n",
      "Train Epoch: 16 [300/798 (38%)]\tLoss: 0.601018\n",
      "Train Epoch: 16 [400/798 (50%)]\tLoss: 1.037247\n",
      "Train Epoch: 16 [500/798 (62%)]\tLoss: 1.072894\n",
      "Train Epoch: 16 [600/798 (75%)]\tLoss: 0.357035\n",
      "Train Epoch: 16 [700/798 (88%)]\tLoss: 0.492960\n",
      "\n",
      "Test set: Avg. loss: 0.1990, Accuracy: 192/200 (96%)\n",
      "\n",
      "Train Epoch: 17 [0/798 (0%)]\tLoss: 0.419082\n",
      "Train Epoch: 17 [100/798 (12%)]\tLoss: 0.357506\n",
      "Train Epoch: 17 [200/798 (25%)]\tLoss: 0.489048\n",
      "Train Epoch: 17 [300/798 (38%)]\tLoss: 0.211111\n",
      "Train Epoch: 17 [400/798 (50%)]\tLoss: 0.532054\n",
      "Train Epoch: 17 [500/798 (62%)]\tLoss: 0.156134\n",
      "Train Epoch: 17 [600/798 (75%)]\tLoss: 0.624591\n",
      "Train Epoch: 17 [700/798 (88%)]\tLoss: 1.029766\n",
      "\n",
      "Test set: Avg. loss: 0.1592, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 18 [0/798 (0%)]\tLoss: 0.396407\n",
      "Train Epoch: 18 [100/798 (12%)]\tLoss: 0.489648\n",
      "Train Epoch: 18 [200/798 (25%)]\tLoss: 0.840158\n",
      "Train Epoch: 18 [300/798 (38%)]\tLoss: 0.856751\n",
      "Train Epoch: 18 [400/798 (50%)]\tLoss: 0.514015\n",
      "Train Epoch: 18 [500/798 (62%)]\tLoss: 0.318651\n",
      "Train Epoch: 18 [600/798 (75%)]\tLoss: 0.521121\n",
      "Train Epoch: 18 [700/798 (88%)]\tLoss: 0.373278\n",
      "\n",
      "Test set: Avg. loss: 0.1155, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 19 [0/798 (0%)]\tLoss: 0.532911\n",
      "Train Epoch: 19 [100/798 (12%)]\tLoss: 0.204310\n",
      "Train Epoch: 19 [200/798 (25%)]\tLoss: 0.612813\n",
      "Train Epoch: 19 [300/798 (38%)]\tLoss: 0.428361\n",
      "Train Epoch: 19 [400/798 (50%)]\tLoss: 0.350299\n",
      "Train Epoch: 19 [500/798 (62%)]\tLoss: 0.283100\n",
      "Train Epoch: 19 [600/798 (75%)]\tLoss: 0.516179\n",
      "Train Epoch: 19 [700/798 (88%)]\tLoss: 0.467494\n",
      "\n",
      "Test set: Avg. loss: 0.0985, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/798 (0%)]\tLoss: 0.061831\n",
      "Train Epoch: 20 [100/798 (12%)]\tLoss: 0.539261\n",
      "Train Epoch: 20 [200/798 (25%)]\tLoss: 0.489368\n",
      "Train Epoch: 20 [300/798 (38%)]\tLoss: 0.276847\n",
      "Train Epoch: 20 [400/798 (50%)]\tLoss: 0.280594\n",
      "Train Epoch: 20 [500/798 (62%)]\tLoss: 0.624786\n",
      "Train Epoch: 20 [600/798 (75%)]\tLoss: 0.153114\n",
      "Train Epoch: 20 [700/798 (88%)]\tLoss: 0.605861\n",
      "\n",
      "Test set: Avg. loss: 0.1068, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/798 (0%)]\tLoss: 0.495933\n",
      "Train Epoch: 21 [100/798 (12%)]\tLoss: 0.243353\n",
      "Train Epoch: 21 [200/798 (25%)]\tLoss: 0.295502\n",
      "Train Epoch: 21 [300/798 (38%)]\tLoss: 0.533783\n",
      "Train Epoch: 21 [400/798 (50%)]\tLoss: 0.414049\n",
      "Train Epoch: 21 [500/798 (62%)]\tLoss: 0.786070\n",
      "Train Epoch: 21 [600/798 (75%)]\tLoss: 0.452179\n",
      "Train Epoch: 21 [700/798 (88%)]\tLoss: 0.692067\n",
      "\n",
      "Test set: Avg. loss: 0.1171, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/798 (0%)]\tLoss: 0.425006\n",
      "Train Epoch: 22 [100/798 (12%)]\tLoss: 1.198424\n",
      "Train Epoch: 22 [200/798 (25%)]\tLoss: 0.791186\n",
      "Train Epoch: 22 [300/798 (38%)]\tLoss: 0.375773\n",
      "Train Epoch: 22 [400/798 (50%)]\tLoss: 0.332320\n",
      "Train Epoch: 22 [500/798 (62%)]\tLoss: 0.436267\n",
      "Train Epoch: 22 [600/798 (75%)]\tLoss: 0.636787\n",
      "Train Epoch: 22 [700/798 (88%)]\tLoss: 0.824889\n",
      "\n",
      "Test set: Avg. loss: 0.0981, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/798 (0%)]\tLoss: 0.485082\n",
      "Train Epoch: 23 [100/798 (12%)]\tLoss: 0.339305\n",
      "Train Epoch: 23 [200/798 (25%)]\tLoss: 0.377069\n",
      "Train Epoch: 23 [300/798 (38%)]\tLoss: 0.262668\n",
      "Train Epoch: 23 [400/798 (50%)]\tLoss: 0.681296\n",
      "Train Epoch: 23 [500/798 (62%)]\tLoss: 0.413841\n",
      "Train Epoch: 23 [600/798 (75%)]\tLoss: 0.515410\n",
      "Train Epoch: 23 [700/798 (88%)]\tLoss: 0.206921\n",
      "\n",
      "Test set: Avg. loss: 0.0980, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/798 (0%)]\tLoss: 0.106312\n",
      "Train Epoch: 24 [100/798 (12%)]\tLoss: 0.465838\n",
      "Train Epoch: 24 [200/798 (25%)]\tLoss: 0.566903\n",
      "Train Epoch: 24 [300/798 (38%)]\tLoss: 0.305155\n",
      "Train Epoch: 24 [400/798 (50%)]\tLoss: 0.812277\n",
      "Train Epoch: 24 [500/798 (62%)]\tLoss: 0.207333\n",
      "Train Epoch: 24 [600/798 (75%)]\tLoss: 0.613801\n",
      "Train Epoch: 24 [700/798 (88%)]\tLoss: 0.381175\n",
      "\n",
      "Test set: Avg. loss: 0.0749, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/798 (0%)]\tLoss: 0.061864\n",
      "Train Epoch: 25 [100/798 (12%)]\tLoss: 0.458386\n",
      "Train Epoch: 25 [200/798 (25%)]\tLoss: 0.210816\n",
      "Train Epoch: 25 [300/798 (38%)]\tLoss: 0.211159\n",
      "Train Epoch: 25 [400/798 (50%)]\tLoss: 0.601757\n",
      "Train Epoch: 25 [500/798 (62%)]\tLoss: 0.526262\n",
      "Train Epoch: 25 [600/798 (75%)]\tLoss: 0.416126\n",
      "Train Epoch: 25 [700/798 (88%)]\tLoss: 0.057705\n",
      "\n",
      "Test set: Avg. loss: 0.0666, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/798 (0%)]\tLoss: 0.332432\n",
      "Train Epoch: 26 [100/798 (12%)]\tLoss: 0.669533\n",
      "Train Epoch: 26 [200/798 (25%)]\tLoss: 0.442560\n",
      "Train Epoch: 26 [300/798 (38%)]\tLoss: 0.037842\n",
      "Train Epoch: 26 [400/798 (50%)]\tLoss: 0.689023\n",
      "Train Epoch: 26 [500/798 (62%)]\tLoss: 0.058181\n",
      "Train Epoch: 26 [600/798 (75%)]\tLoss: 0.251364\n",
      "Train Epoch: 26 [700/798 (88%)]\tLoss: 0.109290\n",
      "\n",
      "Test set: Avg. loss: 0.1018, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/798 (0%)]\tLoss: 0.138257\n",
      "Train Epoch: 27 [100/798 (12%)]\tLoss: 0.275359\n",
      "Train Epoch: 27 [200/798 (25%)]\tLoss: 0.250706\n",
      "Train Epoch: 27 [300/798 (38%)]\tLoss: 0.289310\n",
      "Train Epoch: 27 [400/798 (50%)]\tLoss: 0.012369\n",
      "Train Epoch: 27 [500/798 (62%)]\tLoss: 0.453094\n",
      "Train Epoch: 27 [600/798 (75%)]\tLoss: 0.579269\n",
      "Train Epoch: 27 [700/798 (88%)]\tLoss: 0.250324\n",
      "\n",
      "Test set: Avg. loss: 0.0797, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/798 (0%)]\tLoss: 0.220149\n",
      "Train Epoch: 28 [100/798 (12%)]\tLoss: 0.681076\n",
      "Train Epoch: 28 [200/798 (25%)]\tLoss: 0.277636\n",
      "Train Epoch: 28 [300/798 (38%)]\tLoss: 0.260089\n",
      "Train Epoch: 28 [400/798 (50%)]\tLoss: 1.173841\n",
      "Train Epoch: 28 [500/798 (62%)]\tLoss: 0.367328\n",
      "Train Epoch: 28 [600/798 (75%)]\tLoss: 0.664064\n",
      "Train Epoch: 28 [700/798 (88%)]\tLoss: 0.352434\n",
      "\n",
      "Test set: Avg. loss: 0.0790, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/798 (0%)]\tLoss: 0.138174\n",
      "Train Epoch: 29 [100/798 (12%)]\tLoss: 0.232121\n",
      "Train Epoch: 29 [200/798 (25%)]\tLoss: 0.360598\n",
      "Train Epoch: 29 [300/798 (38%)]\tLoss: 0.029458\n",
      "Train Epoch: 29 [400/798 (50%)]\tLoss: 0.203639\n",
      "Train Epoch: 29 [500/798 (62%)]\tLoss: 0.873328\n",
      "Train Epoch: 29 [600/798 (75%)]\tLoss: 0.051369\n",
      "Train Epoch: 29 [700/798 (88%)]\tLoss: 0.100602\n",
      "\n",
      "Test set: Avg. loss: 0.0622, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 30 [0/798 (0%)]\tLoss: 0.310446\n",
      "Train Epoch: 30 [100/798 (12%)]\tLoss: 0.395281\n",
      "Train Epoch: 30 [200/798 (25%)]\tLoss: 0.313590\n",
      "Train Epoch: 30 [300/798 (38%)]\tLoss: 0.124587\n",
      "Train Epoch: 30 [400/798 (50%)]\tLoss: 0.293873\n",
      "Train Epoch: 30 [500/798 (62%)]\tLoss: 0.368823\n",
      "Train Epoch: 30 [600/798 (75%)]\tLoss: 0.298560\n",
      "Train Epoch: 30 [700/798 (88%)]\tLoss: 0.227348\n",
      "\n",
      "Test set: Avg. loss: 0.0870, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/798 (0%)]\tLoss: 0.343060\n",
      "Train Epoch: 31 [100/798 (12%)]\tLoss: 0.308515\n",
      "Train Epoch: 31 [200/798 (25%)]\tLoss: 0.760147\n",
      "Train Epoch: 31 [300/798 (38%)]\tLoss: 0.425183\n",
      "Train Epoch: 31 [400/798 (50%)]\tLoss: 0.652646\n",
      "Train Epoch: 31 [500/798 (62%)]\tLoss: 0.059582\n",
      "Train Epoch: 31 [600/798 (75%)]\tLoss: 0.453352\n",
      "Train Epoch: 31 [700/798 (88%)]\tLoss: 0.317375\n",
      "\n",
      "Test set: Avg. loss: 0.0715, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 32 [0/798 (0%)]\tLoss: 0.326122\n",
      "Train Epoch: 32 [100/798 (12%)]\tLoss: 0.434339\n",
      "Train Epoch: 32 [200/798 (25%)]\tLoss: 0.114694\n",
      "Train Epoch: 32 [300/798 (38%)]\tLoss: 0.131682\n",
      "Train Epoch: 32 [400/798 (50%)]\tLoss: 0.074499\n",
      "Train Epoch: 32 [500/798 (62%)]\tLoss: 0.048352\n",
      "Train Epoch: 32 [600/798 (75%)]\tLoss: 0.031634\n",
      "Train Epoch: 32 [700/798 (88%)]\tLoss: 0.413438\n",
      "\n",
      "Test set: Avg. loss: 0.0735, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 33 [0/798 (0%)]\tLoss: 0.337054\n",
      "Train Epoch: 33 [100/798 (12%)]\tLoss: 0.008613\n",
      "Train Epoch: 33 [200/798 (25%)]\tLoss: 0.333560\n",
      "Train Epoch: 33 [300/798 (38%)]\tLoss: 0.049009\n",
      "Train Epoch: 33 [400/798 (50%)]\tLoss: 1.176446\n",
      "Train Epoch: 33 [500/798 (62%)]\tLoss: 0.347016\n",
      "Train Epoch: 33 [600/798 (75%)]\tLoss: 0.408919\n",
      "Train Epoch: 33 [700/798 (88%)]\tLoss: 0.101721\n",
      "\n",
      "Test set: Avg. loss: 0.0787, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/798 (0%)]\tLoss: 0.224255\n",
      "Train Epoch: 34 [100/798 (12%)]\tLoss: 0.463669\n",
      "Train Epoch: 34 [200/798 (25%)]\tLoss: 0.531586\n",
      "Train Epoch: 34 [300/798 (38%)]\tLoss: 0.047282\n",
      "Train Epoch: 34 [400/798 (50%)]\tLoss: 0.539757\n",
      "Train Epoch: 34 [500/798 (62%)]\tLoss: 0.058386\n",
      "Train Epoch: 34 [600/798 (75%)]\tLoss: 0.609890\n",
      "Train Epoch: 34 [700/798 (88%)]\tLoss: 0.134814\n",
      "\n",
      "Test set: Avg. loss: 0.0564, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 35 [0/798 (0%)]\tLoss: 0.158369\n",
      "Train Epoch: 35 [100/798 (12%)]\tLoss: 0.319438\n",
      "Train Epoch: 35 [200/798 (25%)]\tLoss: 0.047450\n",
      "Train Epoch: 35 [300/798 (38%)]\tLoss: 0.156846\n",
      "Train Epoch: 35 [400/798 (50%)]\tLoss: 0.017860\n",
      "Train Epoch: 35 [500/798 (62%)]\tLoss: 0.432527\n",
      "Train Epoch: 35 [600/798 (75%)]\tLoss: 0.017672\n",
      "Train Epoch: 35 [700/798 (88%)]\tLoss: 0.753634\n",
      "\n",
      "Test set: Avg. loss: 0.0541, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 36 [0/798 (0%)]\tLoss: 0.030866\n",
      "Train Epoch: 36 [100/798 (12%)]\tLoss: 0.000600\n",
      "Train Epoch: 36 [200/798 (25%)]\tLoss: 0.285947\n",
      "Train Epoch: 36 [300/798 (38%)]\tLoss: 0.930750\n",
      "Train Epoch: 36 [400/798 (50%)]\tLoss: 0.267629\n",
      "Train Epoch: 36 [500/798 (62%)]\tLoss: 0.042604\n",
      "Train Epoch: 36 [600/798 (75%)]\tLoss: 0.384498\n",
      "Train Epoch: 36 [700/798 (88%)]\tLoss: 0.042898\n",
      "\n",
      "Test set: Avg. loss: 0.0534, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 37 [0/798 (0%)]\tLoss: 0.109569\n",
      "Train Epoch: 37 [100/798 (12%)]\tLoss: 0.266200\n",
      "Train Epoch: 37 [200/798 (25%)]\tLoss: 0.034669\n",
      "Train Epoch: 37 [300/798 (38%)]\tLoss: 0.042176\n",
      "Train Epoch: 37 [400/798 (50%)]\tLoss: 0.079444\n",
      "Train Epoch: 37 [500/798 (62%)]\tLoss: 0.313255\n",
      "Train Epoch: 37 [600/798 (75%)]\tLoss: 0.168235\n",
      "Train Epoch: 37 [700/798 (88%)]\tLoss: 0.398574\n",
      "\n",
      "Test set: Avg. loss: 0.0701, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 38 [0/798 (0%)]\tLoss: 0.017645\n",
      "Train Epoch: 38 [100/798 (12%)]\tLoss: 0.134265\n",
      "Train Epoch: 38 [200/798 (25%)]\tLoss: 0.078207\n",
      "Train Epoch: 38 [300/798 (38%)]\tLoss: 0.312392\n",
      "Train Epoch: 38 [400/798 (50%)]\tLoss: 0.670947\n",
      "Train Epoch: 38 [500/798 (62%)]\tLoss: 0.101070\n",
      "Train Epoch: 38 [600/798 (75%)]\tLoss: 0.145132\n",
      "Train Epoch: 38 [700/798 (88%)]\tLoss: 0.229838\n",
      "\n",
      "Test set: Avg. loss: 0.0510, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 39 [0/798 (0%)]\tLoss: 0.283843\n",
      "Train Epoch: 39 [100/798 (12%)]\tLoss: 0.168997\n",
      "Train Epoch: 39 [200/798 (25%)]\tLoss: 0.230104\n",
      "Train Epoch: 39 [300/798 (38%)]\tLoss: 0.526510\n",
      "Train Epoch: 39 [400/798 (50%)]\tLoss: 0.014049\n",
      "Train Epoch: 39 [500/798 (62%)]\tLoss: 0.100819\n",
      "Train Epoch: 39 [600/798 (75%)]\tLoss: 0.439817\n",
      "Train Epoch: 39 [700/798 (88%)]\tLoss: 0.328823\n",
      "\n",
      "Test set: Avg. loss: 0.0620, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 40 [0/798 (0%)]\tLoss: 0.140002\n",
      "Train Epoch: 40 [100/798 (12%)]\tLoss: 0.115245\n",
      "Train Epoch: 40 [200/798 (25%)]\tLoss: 0.248346\n",
      "Train Epoch: 40 [300/798 (38%)]\tLoss: 0.442799\n",
      "Train Epoch: 40 [400/798 (50%)]\tLoss: 0.470848\n",
      "Train Epoch: 40 [500/798 (62%)]\tLoss: 0.052561\n",
      "Train Epoch: 40 [600/798 (75%)]\tLoss: 0.244571\n",
      "Train Epoch: 40 [700/798 (88%)]\tLoss: 0.153052\n",
      "\n",
      "Test set: Avg. loss: 0.0838, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 41 [0/798 (0%)]\tLoss: 0.310583\n",
      "Train Epoch: 41 [100/798 (12%)]\tLoss: 0.645080\n",
      "Train Epoch: 41 [200/798 (25%)]\tLoss: 0.414796\n",
      "Train Epoch: 41 [300/798 (38%)]\tLoss: 0.131771\n",
      "Train Epoch: 41 [400/798 (50%)]\tLoss: 0.115310\n",
      "Train Epoch: 41 [500/798 (62%)]\tLoss: 0.103232\n",
      "Train Epoch: 41 [600/798 (75%)]\tLoss: 0.035607\n",
      "Train Epoch: 41 [700/798 (88%)]\tLoss: 0.320360\n",
      "\n",
      "Test set: Avg. loss: 0.1146, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 42 [0/798 (0%)]\tLoss: 0.172047\n",
      "Train Epoch: 42 [100/798 (12%)]\tLoss: 0.291173\n",
      "Train Epoch: 42 [200/798 (25%)]\tLoss: 0.148027\n",
      "Train Epoch: 42 [300/798 (38%)]\tLoss: 0.204422\n",
      "Train Epoch: 42 [400/798 (50%)]\tLoss: 0.178890\n",
      "Train Epoch: 42 [500/798 (62%)]\tLoss: 0.059585\n",
      "Train Epoch: 42 [600/798 (75%)]\tLoss: 0.300814\n",
      "Train Epoch: 42 [700/798 (88%)]\tLoss: 0.643117\n",
      "\n",
      "Test set: Avg. loss: 0.0446, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 43 [0/798 (0%)]\tLoss: 0.040494\n",
      "Train Epoch: 43 [100/798 (12%)]\tLoss: 0.281086\n",
      "Train Epoch: 43 [200/798 (25%)]\tLoss: 0.006219\n",
      "Train Epoch: 43 [300/798 (38%)]\tLoss: 0.081850\n",
      "Train Epoch: 43 [400/798 (50%)]\tLoss: 0.079228\n",
      "Train Epoch: 43 [500/798 (62%)]\tLoss: 0.002366\n",
      "Train Epoch: 43 [600/798 (75%)]\tLoss: 0.594880\n",
      "Train Epoch: 43 [700/798 (88%)]\tLoss: 0.199454\n",
      "\n",
      "Test set: Avg. loss: 0.0681, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 44 [0/798 (0%)]\tLoss: 0.127134\n",
      "Train Epoch: 44 [100/798 (12%)]\tLoss: 0.099661\n",
      "Train Epoch: 44 [200/798 (25%)]\tLoss: 0.210942\n",
      "Train Epoch: 44 [300/798 (38%)]\tLoss: 0.051624\n",
      "Train Epoch: 44 [400/798 (50%)]\tLoss: 0.074660\n",
      "Train Epoch: 44 [500/798 (62%)]\tLoss: 0.271981\n",
      "Train Epoch: 44 [600/798 (75%)]\tLoss: 0.681621\n",
      "Train Epoch: 44 [700/798 (88%)]\tLoss: 0.000456\n",
      "\n",
      "Test set: Avg. loss: 0.0570, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 45 [0/798 (0%)]\tLoss: 0.147773\n",
      "Train Epoch: 45 [100/798 (12%)]\tLoss: 0.028729\n",
      "Train Epoch: 45 [200/798 (25%)]\tLoss: 0.000001\n",
      "Train Epoch: 45 [300/798 (38%)]\tLoss: 0.053412\n",
      "Train Epoch: 45 [400/798 (50%)]\tLoss: 0.000110\n",
      "Train Epoch: 45 [500/798 (62%)]\tLoss: 0.104428\n",
      "Train Epoch: 45 [600/798 (75%)]\tLoss: 0.326142\n",
      "Train Epoch: 45 [700/798 (88%)]\tLoss: 0.021617\n",
      "\n",
      "Test set: Avg. loss: 0.0622, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 46 [0/798 (0%)]\tLoss: 0.305177\n",
      "Train Epoch: 46 [100/798 (12%)]\tLoss: 0.029137\n",
      "Train Epoch: 46 [200/798 (25%)]\tLoss: 0.528585\n",
      "Train Epoch: 46 [300/798 (38%)]\tLoss: 0.148869\n",
      "Train Epoch: 46 [400/798 (50%)]\tLoss: 0.179911\n",
      "Train Epoch: 46 [500/798 (62%)]\tLoss: 0.012676\n",
      "Train Epoch: 46 [600/798 (75%)]\tLoss: 0.079576\n",
      "Train Epoch: 46 [700/798 (88%)]\tLoss: 0.252720\n",
      "\n",
      "Test set: Avg. loss: 0.0568, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 47 [0/798 (0%)]\tLoss: 0.409384\n",
      "Train Epoch: 47 [100/798 (12%)]\tLoss: 0.084412\n",
      "Train Epoch: 47 [200/798 (25%)]\tLoss: 0.341407\n",
      "Train Epoch: 47 [300/798 (38%)]\tLoss: 0.192032\n",
      "Train Epoch: 47 [400/798 (50%)]\tLoss: 0.160496\n",
      "Train Epoch: 47 [500/798 (62%)]\tLoss: 0.142154\n",
      "Train Epoch: 47 [600/798 (75%)]\tLoss: 0.225326\n",
      "Train Epoch: 47 [700/798 (88%)]\tLoss: 0.323970\n",
      "\n",
      "Test set: Avg. loss: 0.0442, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 48 [0/798 (0%)]\tLoss: 0.046014\n",
      "Train Epoch: 48 [100/798 (12%)]\tLoss: 0.017818\n",
      "Train Epoch: 48 [200/798 (25%)]\tLoss: 0.217740\n",
      "Train Epoch: 48 [300/798 (38%)]\tLoss: 0.044905\n",
      "Train Epoch: 48 [400/798 (50%)]\tLoss: 0.324272\n",
      "Train Epoch: 48 [500/798 (62%)]\tLoss: 0.049191\n",
      "Train Epoch: 48 [600/798 (75%)]\tLoss: 0.004108\n",
      "Train Epoch: 48 [700/798 (88%)]\tLoss: 0.173837\n",
      "\n",
      "Test set: Avg. loss: 0.0800, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 49 [0/798 (0%)]\tLoss: 0.020508\n",
      "Train Epoch: 49 [100/798 (12%)]\tLoss: 1.115460\n",
      "Train Epoch: 49 [200/798 (25%)]\tLoss: 0.019905\n",
      "Train Epoch: 49 [300/798 (38%)]\tLoss: 0.507747\n",
      "Train Epoch: 49 [400/798 (50%)]\tLoss: 0.286084\n",
      "Train Epoch: 49 [500/798 (62%)]\tLoss: 0.026485\n",
      "Train Epoch: 49 [600/798 (75%)]\tLoss: 0.122788\n",
      "Train Epoch: 49 [700/798 (88%)]\tLoss: 0.165841\n",
      "\n",
      "Test set: Avg. loss: 0.0467, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 50 [0/798 (0%)]\tLoss: 0.126141\n",
      "Train Epoch: 50 [100/798 (12%)]\tLoss: 0.091783\n",
      "Train Epoch: 50 [200/798 (25%)]\tLoss: 0.003715\n",
      "Train Epoch: 50 [300/798 (38%)]\tLoss: 0.000127\n",
      "Train Epoch: 50 [400/798 (50%)]\tLoss: 0.239818\n",
      "Train Epoch: 50 [500/798 (62%)]\tLoss: 0.756035\n",
      "Train Epoch: 50 [600/798 (75%)]\tLoss: 0.155884\n",
      "Train Epoch: 50 [700/798 (88%)]\tLoss: 0.598150\n",
      "\n",
      "Test set: Avg. loss: 0.0480, Accuracy: 198/200 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0480, Accuracy: 198/200 (99%)\n",
      "\n",
      "Running bootstrap experiment: 1\n",
      "Train Epoch: 1 [0/798 (0%)]\tLoss: 2.258202\n",
      "Train Epoch: 1 [100/798 (12%)]\tLoss: 2.352448\n",
      "Train Epoch: 1 [200/798 (25%)]\tLoss: 2.284398\n",
      "Train Epoch: 1 [300/798 (38%)]\tLoss: 2.256279\n",
      "Train Epoch: 1 [400/798 (50%)]\tLoss: 2.218643\n",
      "Train Epoch: 1 [500/798 (62%)]\tLoss: 2.363968\n",
      "Train Epoch: 1 [600/798 (75%)]\tLoss: 2.295012\n",
      "Train Epoch: 1 [700/798 (88%)]\tLoss: 2.250307\n",
      "\n",
      "Test set: Avg. loss: 2.2942, Accuracy: 22/200 (11%)\n",
      "\n",
      "Train Epoch: 2 [0/798 (0%)]\tLoss: 2.255431\n",
      "Train Epoch: 2 [100/798 (12%)]\tLoss: 2.237346\n",
      "Train Epoch: 2 [200/798 (25%)]\tLoss: 2.257915\n",
      "Train Epoch: 2 [300/798 (38%)]\tLoss: 2.263314\n",
      "Train Epoch: 2 [400/798 (50%)]\tLoss: 2.264472\n",
      "Train Epoch: 2 [500/798 (62%)]\tLoss: 2.264946\n",
      "Train Epoch: 2 [600/798 (75%)]\tLoss: 2.338931\n",
      "Train Epoch: 2 [700/798 (88%)]\tLoss: 2.298356\n",
      "\n",
      "Test set: Avg. loss: 2.2725, Accuracy: 49/200 (24%)\n",
      "\n",
      "Train Epoch: 3 [0/798 (0%)]\tLoss: 2.202080\n",
      "Train Epoch: 3 [100/798 (12%)]\tLoss: 2.325009\n",
      "Train Epoch: 3 [200/798 (25%)]\tLoss: 2.233696\n",
      "Train Epoch: 3 [300/798 (38%)]\tLoss: 2.281831\n",
      "Train Epoch: 3 [400/798 (50%)]\tLoss: 2.217644\n",
      "Train Epoch: 3 [500/798 (62%)]\tLoss: 2.207986\n",
      "Train Epoch: 3 [600/798 (75%)]\tLoss: 2.201330\n",
      "Train Epoch: 3 [700/798 (88%)]\tLoss: 2.094812\n",
      "\n",
      "Test set: Avg. loss: 2.2082, Accuracy: 61/200 (30%)\n",
      "\n",
      "Train Epoch: 4 [0/798 (0%)]\tLoss: 2.155767\n",
      "Train Epoch: 4 [100/798 (12%)]\tLoss: 2.070116\n",
      "Train Epoch: 4 [200/798 (25%)]\tLoss: 2.028146\n",
      "Train Epoch: 4 [300/798 (38%)]\tLoss: 2.096518\n",
      "Train Epoch: 4 [400/798 (50%)]\tLoss: 2.178502\n",
      "Train Epoch: 4 [500/798 (62%)]\tLoss: 2.023440\n",
      "Train Epoch: 4 [600/798 (75%)]\tLoss: 1.958126\n",
      "Train Epoch: 4 [700/798 (88%)]\tLoss: 1.978106\n",
      "\n",
      "Test set: Avg. loss: 2.0338, Accuracy: 53/200 (26%)\n",
      "\n",
      "Train Epoch: 5 [0/798 (0%)]\tLoss: 2.139089\n",
      "Train Epoch: 5 [100/798 (12%)]\tLoss: 2.181652\n",
      "Train Epoch: 5 [200/798 (25%)]\tLoss: 2.086514\n",
      "Train Epoch: 5 [300/798 (38%)]\tLoss: 2.153571\n",
      "Train Epoch: 5 [400/798 (50%)]\tLoss: 1.673469\n",
      "Train Epoch: 5 [500/798 (62%)]\tLoss: 1.659328\n",
      "Train Epoch: 5 [600/798 (75%)]\tLoss: 1.913879\n",
      "Train Epoch: 5 [700/798 (88%)]\tLoss: 1.912211\n",
      "\n",
      "Test set: Avg. loss: 1.6837, Accuracy: 88/200 (44%)\n",
      "\n",
      "Train Epoch: 6 [0/798 (0%)]\tLoss: 1.823083\n",
      "Train Epoch: 6 [100/798 (12%)]\tLoss: 1.976215\n",
      "Train Epoch: 6 [200/798 (25%)]\tLoss: 1.785422\n",
      "Train Epoch: 6 [300/798 (38%)]\tLoss: 1.419254\n",
      "Train Epoch: 6 [400/798 (50%)]\tLoss: 1.605786\n",
      "Train Epoch: 6 [500/798 (62%)]\tLoss: 1.810725\n",
      "Train Epoch: 6 [600/798 (75%)]\tLoss: 1.218651\n",
      "Train Epoch: 6 [700/798 (88%)]\tLoss: 1.428471\n",
      "\n",
      "Test set: Avg. loss: 1.4271, Accuracy: 127/200 (64%)\n",
      "\n",
      "Train Epoch: 7 [0/798 (0%)]\tLoss: 1.639105\n",
      "Train Epoch: 7 [100/798 (12%)]\tLoss: 1.845842\n",
      "Train Epoch: 7 [200/798 (25%)]\tLoss: 1.813161\n",
      "Train Epoch: 7 [300/798 (38%)]\tLoss: 1.265119\n",
      "Train Epoch: 7 [400/798 (50%)]\tLoss: 1.346260\n",
      "Train Epoch: 7 [500/798 (62%)]\tLoss: 1.389787\n",
      "Train Epoch: 7 [600/798 (75%)]\tLoss: 1.863784\n",
      "Train Epoch: 7 [700/798 (88%)]\tLoss: 1.383190\n",
      "\n",
      "Test set: Avg. loss: 1.1927, Accuracy: 151/200 (76%)\n",
      "\n",
      "Train Epoch: 8 [0/798 (0%)]\tLoss: 1.271260\n",
      "Train Epoch: 8 [100/798 (12%)]\tLoss: 1.623564\n",
      "Train Epoch: 8 [200/798 (25%)]\tLoss: 1.269751\n",
      "Train Epoch: 8 [300/798 (38%)]\tLoss: 1.256065\n",
      "Train Epoch: 8 [400/798 (50%)]\tLoss: 1.126168\n",
      "Train Epoch: 8 [500/798 (62%)]\tLoss: 1.117635\n",
      "Train Epoch: 8 [600/798 (75%)]\tLoss: 1.511197\n",
      "Train Epoch: 8 [700/798 (88%)]\tLoss: 1.552047\n",
      "\n",
      "Test set: Avg. loss: 0.8534, Accuracy: 167/200 (84%)\n",
      "\n",
      "Train Epoch: 9 [0/798 (0%)]\tLoss: 1.098391\n",
      "Train Epoch: 9 [100/798 (12%)]\tLoss: 1.327585\n",
      "Train Epoch: 9 [200/798 (25%)]\tLoss: 1.736243\n",
      "Train Epoch: 9 [300/798 (38%)]\tLoss: 1.182647\n",
      "Train Epoch: 9 [400/798 (50%)]\tLoss: 0.896904\n",
      "Train Epoch: 9 [500/798 (62%)]\tLoss: 1.370477\n",
      "Train Epoch: 9 [600/798 (75%)]\tLoss: 0.942582\n",
      "Train Epoch: 9 [700/798 (88%)]\tLoss: 1.057842\n",
      "\n",
      "Test set: Avg. loss: 0.6279, Accuracy: 185/200 (92%)\n",
      "\n",
      "Train Epoch: 10 [0/798 (0%)]\tLoss: 0.723596\n",
      "Train Epoch: 10 [100/798 (12%)]\tLoss: 1.029935\n",
      "Train Epoch: 10 [200/798 (25%)]\tLoss: 0.856297\n",
      "Train Epoch: 10 [300/798 (38%)]\tLoss: 1.250688\n",
      "Train Epoch: 10 [400/798 (50%)]\tLoss: 1.400265\n",
      "Train Epoch: 10 [500/798 (62%)]\tLoss: 0.686236\n",
      "Train Epoch: 10 [600/798 (75%)]\tLoss: 1.331017\n",
      "Train Epoch: 10 [700/798 (88%)]\tLoss: 0.990920\n",
      "\n",
      "Test set: Avg. loss: 0.5677, Accuracy: 181/200 (90%)\n",
      "\n",
      "Train Epoch: 11 [0/798 (0%)]\tLoss: 1.218626\n",
      "Train Epoch: 11 [100/798 (12%)]\tLoss: 0.789981\n",
      "Train Epoch: 11 [200/798 (25%)]\tLoss: 1.265113\n",
      "Train Epoch: 11 [300/798 (38%)]\tLoss: 1.061535\n",
      "Train Epoch: 11 [400/798 (50%)]\tLoss: 0.783412\n",
      "Train Epoch: 11 [500/798 (62%)]\tLoss: 0.410219\n",
      "Train Epoch: 11 [600/798 (75%)]\tLoss: 1.017093\n",
      "Train Epoch: 11 [700/798 (88%)]\tLoss: 1.377798\n",
      "\n",
      "Test set: Avg. loss: 0.3513, Accuracy: 184/200 (92%)\n",
      "\n",
      "Train Epoch: 12 [0/798 (0%)]\tLoss: 1.152415\n",
      "Train Epoch: 12 [100/798 (12%)]\tLoss: 0.882375\n",
      "Train Epoch: 12 [200/798 (25%)]\tLoss: 1.246769\n",
      "Train Epoch: 12 [300/798 (38%)]\tLoss: 0.452232\n",
      "Train Epoch: 12 [400/798 (50%)]\tLoss: 0.856562\n",
      "Train Epoch: 12 [500/798 (62%)]\tLoss: 0.656270\n",
      "Train Epoch: 12 [600/798 (75%)]\tLoss: 0.589430\n",
      "Train Epoch: 12 [700/798 (88%)]\tLoss: 0.738851\n",
      "\n",
      "Test set: Avg. loss: 0.3233, Accuracy: 191/200 (96%)\n",
      "\n",
      "Train Epoch: 13 [0/798 (0%)]\tLoss: 0.677994\n",
      "Train Epoch: 13 [100/798 (12%)]\tLoss: 0.411375\n",
      "Train Epoch: 13 [200/798 (25%)]\tLoss: 0.669474\n",
      "Train Epoch: 13 [300/798 (38%)]\tLoss: 0.637911\n",
      "Train Epoch: 13 [400/798 (50%)]\tLoss: 0.737876\n",
      "Train Epoch: 13 [500/798 (62%)]\tLoss: 0.827540\n",
      "Train Epoch: 13 [600/798 (75%)]\tLoss: 1.077085\n",
      "Train Epoch: 13 [700/798 (88%)]\tLoss: 0.486052\n",
      "\n",
      "Test set: Avg. loss: 0.2853, Accuracy: 193/200 (96%)\n",
      "\n",
      "Train Epoch: 14 [0/798 (0%)]\tLoss: 0.617733\n",
      "Train Epoch: 14 [100/798 (12%)]\tLoss: 0.308088\n",
      "Train Epoch: 14 [200/798 (25%)]\tLoss: 0.480971\n",
      "Train Epoch: 14 [300/798 (38%)]\tLoss: 0.945248\n",
      "Train Epoch: 14 [400/798 (50%)]\tLoss: 0.660605\n",
      "Train Epoch: 14 [500/798 (62%)]\tLoss: 0.981618\n",
      "Train Epoch: 14 [600/798 (75%)]\tLoss: 1.079306\n",
      "Train Epoch: 14 [700/798 (88%)]\tLoss: 0.218054\n",
      "\n",
      "Test set: Avg. loss: 0.2508, Accuracy: 193/200 (96%)\n",
      "\n",
      "Train Epoch: 15 [0/798 (0%)]\tLoss: 0.448091\n",
      "Train Epoch: 15 [100/798 (12%)]\tLoss: 0.382198\n",
      "Train Epoch: 15 [200/798 (25%)]\tLoss: 0.582399\n",
      "Train Epoch: 15 [300/798 (38%)]\tLoss: 0.727040\n",
      "Train Epoch: 15 [400/798 (50%)]\tLoss: 0.802309\n",
      "Train Epoch: 15 [500/798 (62%)]\tLoss: 0.948822\n",
      "Train Epoch: 15 [600/798 (75%)]\tLoss: 0.736566\n",
      "Train Epoch: 15 [700/798 (88%)]\tLoss: 0.426722\n",
      "\n",
      "Test set: Avg. loss: 0.2503, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 16 [0/798 (0%)]\tLoss: 0.531820\n",
      "Train Epoch: 16 [100/798 (12%)]\tLoss: 0.626751\n",
      "Train Epoch: 16 [200/798 (25%)]\tLoss: 1.190538\n",
      "Train Epoch: 16 [300/798 (38%)]\tLoss: 0.671963\n",
      "Train Epoch: 16 [400/798 (50%)]\tLoss: 1.439233\n",
      "Train Epoch: 16 [500/798 (62%)]\tLoss: 0.663546\n",
      "Train Epoch: 16 [600/798 (75%)]\tLoss: 0.542165\n",
      "Train Epoch: 16 [700/798 (88%)]\tLoss: 0.831625\n",
      "\n",
      "Test set: Avg. loss: 0.2192, Accuracy: 191/200 (96%)\n",
      "\n",
      "Train Epoch: 17 [0/798 (0%)]\tLoss: 0.409397\n",
      "Train Epoch: 17 [100/798 (12%)]\tLoss: 0.595469\n",
      "Train Epoch: 17 [200/798 (25%)]\tLoss: 1.025163\n",
      "Train Epoch: 17 [300/798 (38%)]\tLoss: 0.696123\n",
      "Train Epoch: 17 [400/798 (50%)]\tLoss: 0.690524\n",
      "Train Epoch: 17 [500/798 (62%)]\tLoss: 0.211884\n",
      "Train Epoch: 17 [600/798 (75%)]\tLoss: 0.420477\n",
      "Train Epoch: 17 [700/798 (88%)]\tLoss: 0.464972\n",
      "\n",
      "Test set: Avg. loss: 0.3088, Accuracy: 190/200 (95%)\n",
      "\n",
      "Train Epoch: 18 [0/798 (0%)]\tLoss: 0.441819\n",
      "Train Epoch: 18 [100/798 (12%)]\tLoss: 0.702937\n",
      "Train Epoch: 18 [200/798 (25%)]\tLoss: 0.976052\n",
      "Train Epoch: 18 [300/798 (38%)]\tLoss: 0.526716\n",
      "Train Epoch: 18 [400/798 (50%)]\tLoss: 0.559119\n",
      "Train Epoch: 18 [500/798 (62%)]\tLoss: 0.316827\n",
      "Train Epoch: 18 [600/798 (75%)]\tLoss: 0.345908\n",
      "Train Epoch: 18 [700/798 (88%)]\tLoss: 0.411794\n",
      "\n",
      "Test set: Avg. loss: 0.1433, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 19 [0/798 (0%)]\tLoss: 0.403742\n",
      "Train Epoch: 19 [100/798 (12%)]\tLoss: 0.337201\n",
      "Train Epoch: 19 [200/798 (25%)]\tLoss: 0.604107\n",
      "Train Epoch: 19 [300/798 (38%)]\tLoss: 0.137891\n",
      "Train Epoch: 19 [400/798 (50%)]\tLoss: 0.207096\n",
      "Train Epoch: 19 [500/798 (62%)]\tLoss: 0.825865\n",
      "Train Epoch: 19 [600/798 (75%)]\tLoss: 0.967326\n",
      "Train Epoch: 19 [700/798 (88%)]\tLoss: 0.323159\n",
      "\n",
      "Test set: Avg. loss: 0.1207, Accuracy: 193/200 (96%)\n",
      "\n",
      "Train Epoch: 20 [0/798 (0%)]\tLoss: 0.479215\n",
      "Train Epoch: 20 [100/798 (12%)]\tLoss: 0.603978\n",
      "Train Epoch: 20 [200/798 (25%)]\tLoss: 0.104322\n",
      "Train Epoch: 20 [300/798 (38%)]\tLoss: 0.346023\n",
      "Train Epoch: 20 [400/798 (50%)]\tLoss: 0.541338\n",
      "Train Epoch: 20 [500/798 (62%)]\tLoss: 0.375908\n",
      "Train Epoch: 20 [600/798 (75%)]\tLoss: 0.353621\n",
      "Train Epoch: 20 [700/798 (88%)]\tLoss: 0.810673\n",
      "\n",
      "Test set: Avg. loss: 0.1105, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 21 [0/798 (0%)]\tLoss: 0.085251\n",
      "Train Epoch: 21 [100/798 (12%)]\tLoss: 0.327289\n",
      "Train Epoch: 21 [200/798 (25%)]\tLoss: 0.284124\n",
      "Train Epoch: 21 [300/798 (38%)]\tLoss: 0.447868\n",
      "Train Epoch: 21 [400/798 (50%)]\tLoss: 0.404112\n",
      "Train Epoch: 21 [500/798 (62%)]\tLoss: 0.330125\n",
      "Train Epoch: 21 [600/798 (75%)]\tLoss: 0.756442\n",
      "Train Epoch: 21 [700/798 (88%)]\tLoss: 0.570508\n",
      "\n",
      "Test set: Avg. loss: 0.1007, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 22 [0/798 (0%)]\tLoss: 0.693683\n",
      "Train Epoch: 22 [100/798 (12%)]\tLoss: 0.584908\n",
      "Train Epoch: 22 [200/798 (25%)]\tLoss: 0.951692\n",
      "Train Epoch: 22 [300/798 (38%)]\tLoss: 0.698787\n",
      "Train Epoch: 22 [400/798 (50%)]\tLoss: 0.743529\n",
      "Train Epoch: 22 [500/798 (62%)]\tLoss: 0.489311\n",
      "Train Epoch: 22 [600/798 (75%)]\tLoss: 0.789231\n",
      "Train Epoch: 22 [700/798 (88%)]\tLoss: 0.337765\n",
      "\n",
      "Test set: Avg. loss: 0.1113, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 23 [0/798 (0%)]\tLoss: 0.216273\n",
      "Train Epoch: 23 [100/798 (12%)]\tLoss: 0.690324\n",
      "Train Epoch: 23 [200/798 (25%)]\tLoss: 0.594151\n",
      "Train Epoch: 23 [300/798 (38%)]\tLoss: 0.507571\n",
      "Train Epoch: 23 [400/798 (50%)]\tLoss: 0.350066\n",
      "Train Epoch: 23 [500/798 (62%)]\tLoss: 0.335110\n",
      "Train Epoch: 23 [600/798 (75%)]\tLoss: 0.117050\n",
      "Train Epoch: 23 [700/798 (88%)]\tLoss: 0.525337\n",
      "\n",
      "Test set: Avg. loss: 0.1225, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/798 (0%)]\tLoss: 0.075140\n",
      "Train Epoch: 24 [100/798 (12%)]\tLoss: 0.256320\n",
      "Train Epoch: 24 [200/798 (25%)]\tLoss: 0.558365\n",
      "Train Epoch: 24 [300/798 (38%)]\tLoss: 0.643964\n",
      "Train Epoch: 24 [400/798 (50%)]\tLoss: 0.058644\n",
      "Train Epoch: 24 [500/798 (62%)]\tLoss: 0.484578\n",
      "Train Epoch: 24 [600/798 (75%)]\tLoss: 0.733926\n",
      "Train Epoch: 24 [700/798 (88%)]\tLoss: 0.073607\n",
      "\n",
      "Test set: Avg. loss: 0.0807, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/798 (0%)]\tLoss: 0.756687\n",
      "Train Epoch: 25 [100/798 (12%)]\tLoss: 0.469930\n",
      "Train Epoch: 25 [200/798 (25%)]\tLoss: 0.053879\n",
      "Train Epoch: 25 [300/798 (38%)]\tLoss: 0.237098\n",
      "Train Epoch: 25 [400/798 (50%)]\tLoss: 0.087370\n",
      "Train Epoch: 25 [500/798 (62%)]\tLoss: 0.678977\n",
      "Train Epoch: 25 [600/798 (75%)]\tLoss: 0.284111\n",
      "Train Epoch: 25 [700/798 (88%)]\tLoss: 0.147810\n",
      "\n",
      "Test set: Avg. loss: 0.0943, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/798 (0%)]\tLoss: 0.383434\n",
      "Train Epoch: 26 [100/798 (12%)]\tLoss: 0.287289\n",
      "Train Epoch: 26 [200/798 (25%)]\tLoss: 0.267294\n",
      "Train Epoch: 26 [300/798 (38%)]\tLoss: 0.493073\n",
      "Train Epoch: 26 [400/798 (50%)]\tLoss: 0.171689\n",
      "Train Epoch: 26 [500/798 (62%)]\tLoss: 0.158596\n",
      "Train Epoch: 26 [600/798 (75%)]\tLoss: 0.038887\n",
      "Train Epoch: 26 [700/798 (88%)]\tLoss: 0.843764\n",
      "\n",
      "Test set: Avg. loss: 0.0859, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/798 (0%)]\tLoss: 0.260579\n",
      "Train Epoch: 27 [100/798 (12%)]\tLoss: 0.147921\n",
      "Train Epoch: 27 [200/798 (25%)]\tLoss: 0.429868\n",
      "Train Epoch: 27 [300/798 (38%)]\tLoss: 0.436976\n",
      "Train Epoch: 27 [400/798 (50%)]\tLoss: 0.143565\n",
      "Train Epoch: 27 [500/798 (62%)]\tLoss: 0.351051\n",
      "Train Epoch: 27 [600/798 (75%)]\tLoss: 0.373109\n",
      "Train Epoch: 27 [700/798 (88%)]\tLoss: 0.751659\n",
      "\n",
      "Test set: Avg. loss: 0.0882, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/798 (0%)]\tLoss: 0.493509\n",
      "Train Epoch: 28 [100/798 (12%)]\tLoss: 0.068675\n",
      "Train Epoch: 28 [200/798 (25%)]\tLoss: 0.133246\n",
      "Train Epoch: 28 [300/798 (38%)]\tLoss: 0.358856\n",
      "Train Epoch: 28 [400/798 (50%)]\tLoss: 0.643525\n",
      "Train Epoch: 28 [500/798 (62%)]\tLoss: 0.599808\n",
      "Train Epoch: 28 [600/798 (75%)]\tLoss: 0.725135\n",
      "Train Epoch: 28 [700/798 (88%)]\tLoss: 0.204248\n",
      "\n",
      "Test set: Avg. loss: 0.0889, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/798 (0%)]\tLoss: 0.638950\n",
      "Train Epoch: 29 [100/798 (12%)]\tLoss: 0.277561\n",
      "Train Epoch: 29 [200/798 (25%)]\tLoss: 0.308018\n",
      "Train Epoch: 29 [300/798 (38%)]\tLoss: 0.331711\n",
      "Train Epoch: 29 [400/798 (50%)]\tLoss: 0.254394\n",
      "Train Epoch: 29 [500/798 (62%)]\tLoss: 0.094993\n",
      "Train Epoch: 29 [600/798 (75%)]\tLoss: 0.753552\n",
      "Train Epoch: 29 [700/798 (88%)]\tLoss: 0.396158\n",
      "\n",
      "Test set: Avg. loss: 0.0932, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 30 [0/798 (0%)]\tLoss: 0.595112\n",
      "Train Epoch: 30 [100/798 (12%)]\tLoss: 0.500590\n",
      "Train Epoch: 30 [200/798 (25%)]\tLoss: 0.453500\n",
      "Train Epoch: 30 [300/798 (38%)]\tLoss: 0.253189\n",
      "Train Epoch: 30 [400/798 (50%)]\tLoss: 1.032195\n",
      "Train Epoch: 30 [500/798 (62%)]\tLoss: 0.538631\n",
      "Train Epoch: 30 [600/798 (75%)]\tLoss: 0.628512\n",
      "Train Epoch: 30 [700/798 (88%)]\tLoss: 0.574121\n",
      "\n",
      "Test set: Avg. loss: 0.0867, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/798 (0%)]\tLoss: 0.102691\n",
      "Train Epoch: 31 [100/798 (12%)]\tLoss: 0.512095\n",
      "Train Epoch: 31 [200/798 (25%)]\tLoss: 0.141721\n",
      "Train Epoch: 31 [300/798 (38%)]\tLoss: 0.143100\n",
      "Train Epoch: 31 [400/798 (50%)]\tLoss: 0.039094\n",
      "Train Epoch: 31 [500/798 (62%)]\tLoss: 0.219108\n",
      "Train Epoch: 31 [600/798 (75%)]\tLoss: 0.430177\n",
      "Train Epoch: 31 [700/798 (88%)]\tLoss: 0.681179\n",
      "\n",
      "Test set: Avg. loss: 0.0893, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 32 [0/798 (0%)]\tLoss: 0.359550\n",
      "Train Epoch: 32 [100/798 (12%)]\tLoss: 0.246041\n",
      "Train Epoch: 32 [200/798 (25%)]\tLoss: 0.225014\n",
      "Train Epoch: 32 [300/798 (38%)]\tLoss: 0.410160\n",
      "Train Epoch: 32 [400/798 (50%)]\tLoss: 0.115294\n",
      "Train Epoch: 32 [500/798 (62%)]\tLoss: 0.315368\n",
      "Train Epoch: 32 [600/798 (75%)]\tLoss: 0.416825\n",
      "Train Epoch: 32 [700/798 (88%)]\tLoss: 0.466990\n",
      "\n",
      "Test set: Avg. loss: 0.0843, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 33 [0/798 (0%)]\tLoss: 0.067449\n",
      "Train Epoch: 33 [100/798 (12%)]\tLoss: 0.108982\n",
      "Train Epoch: 33 [200/798 (25%)]\tLoss: 0.748968\n",
      "Train Epoch: 33 [300/798 (38%)]\tLoss: 0.008761\n",
      "Train Epoch: 33 [400/798 (50%)]\tLoss: 0.314131\n",
      "Train Epoch: 33 [500/798 (62%)]\tLoss: 0.436650\n",
      "Train Epoch: 33 [600/798 (75%)]\tLoss: 0.327181\n",
      "Train Epoch: 33 [700/798 (88%)]\tLoss: 0.064472\n",
      "\n",
      "Test set: Avg. loss: 0.0759, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/798 (0%)]\tLoss: 0.130128\n",
      "Train Epoch: 34 [100/798 (12%)]\tLoss: 0.285310\n",
      "Train Epoch: 34 [200/798 (25%)]\tLoss: 0.617835\n",
      "Train Epoch: 34 [300/798 (38%)]\tLoss: 0.457550\n",
      "Train Epoch: 34 [400/798 (50%)]\tLoss: 0.206045\n",
      "Train Epoch: 34 [500/798 (62%)]\tLoss: 0.667824\n",
      "Train Epoch: 34 [600/798 (75%)]\tLoss: 0.459254\n",
      "Train Epoch: 34 [700/798 (88%)]\tLoss: 0.162307\n",
      "\n",
      "Test set: Avg. loss: 0.0843, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 35 [0/798 (0%)]\tLoss: 0.127300\n",
      "Train Epoch: 35 [100/798 (12%)]\tLoss: 0.216993\n",
      "Train Epoch: 35 [200/798 (25%)]\tLoss: 0.140252\n",
      "Train Epoch: 35 [300/798 (38%)]\tLoss: 0.041687\n",
      "Train Epoch: 35 [400/798 (50%)]\tLoss: 0.378311\n",
      "Train Epoch: 35 [500/798 (62%)]\tLoss: 0.373766\n",
      "Train Epoch: 35 [600/798 (75%)]\tLoss: 0.328463\n",
      "Train Epoch: 35 [700/798 (88%)]\tLoss: 0.005336\n",
      "\n",
      "Test set: Avg. loss: 0.0850, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 36 [0/798 (0%)]\tLoss: 0.322839\n",
      "Train Epoch: 36 [100/798 (12%)]\tLoss: 0.251359\n",
      "Train Epoch: 36 [200/798 (25%)]\tLoss: 0.550301\n",
      "Train Epoch: 36 [300/798 (38%)]\tLoss: 0.640882\n",
      "Train Epoch: 36 [400/798 (50%)]\tLoss: 0.562706\n",
      "Train Epoch: 36 [500/798 (62%)]\tLoss: 0.059256\n",
      "Train Epoch: 36 [600/798 (75%)]\tLoss: 0.033811\n",
      "Train Epoch: 36 [700/798 (88%)]\tLoss: 0.338444\n",
      "\n",
      "Test set: Avg. loss: 0.0709, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 37 [0/798 (0%)]\tLoss: 0.026918\n",
      "Train Epoch: 37 [100/798 (12%)]\tLoss: 1.118119\n",
      "Train Epoch: 37 [200/798 (25%)]\tLoss: 0.268077\n",
      "Train Epoch: 37 [300/798 (38%)]\tLoss: 0.363945\n",
      "Train Epoch: 37 [400/798 (50%)]\tLoss: 0.661725\n",
      "Train Epoch: 37 [500/798 (62%)]\tLoss: 0.106696\n",
      "Train Epoch: 37 [600/798 (75%)]\tLoss: 0.153612\n",
      "Train Epoch: 37 [700/798 (88%)]\tLoss: 0.178019\n",
      "\n",
      "Test set: Avg. loss: 0.0782, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 38 [0/798 (0%)]\tLoss: 0.805809\n",
      "Train Epoch: 38 [100/798 (12%)]\tLoss: 0.314490\n",
      "Train Epoch: 38 [200/798 (25%)]\tLoss: 0.619389\n",
      "Train Epoch: 38 [300/798 (38%)]\tLoss: 0.426275\n",
      "Train Epoch: 38 [400/798 (50%)]\tLoss: 0.047898\n",
      "Train Epoch: 38 [500/798 (62%)]\tLoss: 0.130610\n",
      "Train Epoch: 38 [600/798 (75%)]\tLoss: 0.030300\n",
      "Train Epoch: 38 [700/798 (88%)]\tLoss: 0.048393\n",
      "\n",
      "Test set: Avg. loss: 0.0663, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 39 [0/798 (0%)]\tLoss: 0.079912\n",
      "Train Epoch: 39 [100/798 (12%)]\tLoss: 0.028683\n",
      "Train Epoch: 39 [200/798 (25%)]\tLoss: 0.509754\n",
      "Train Epoch: 39 [300/798 (38%)]\tLoss: 0.191979\n",
      "Train Epoch: 39 [400/798 (50%)]\tLoss: 0.244046\n",
      "Train Epoch: 39 [500/798 (62%)]\tLoss: 0.232965\n",
      "Train Epoch: 39 [600/798 (75%)]\tLoss: 0.628834\n",
      "Train Epoch: 39 [700/798 (88%)]\tLoss: 0.798799\n",
      "\n",
      "Test set: Avg. loss: 0.0682, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 40 [0/798 (0%)]\tLoss: 0.138771\n",
      "Train Epoch: 40 [100/798 (12%)]\tLoss: 0.172751\n",
      "Train Epoch: 40 [200/798 (25%)]\tLoss: 0.001026\n",
      "Train Epoch: 40 [300/798 (38%)]\tLoss: 0.746060\n",
      "Train Epoch: 40 [400/798 (50%)]\tLoss: 0.329885\n",
      "Train Epoch: 40 [500/798 (62%)]\tLoss: 0.051009\n",
      "Train Epoch: 40 [600/798 (75%)]\tLoss: 0.013907\n",
      "Train Epoch: 40 [700/798 (88%)]\tLoss: 0.387941\n",
      "\n",
      "Test set: Avg. loss: 0.0619, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 41 [0/798 (0%)]\tLoss: 0.229715\n",
      "Train Epoch: 41 [100/798 (12%)]\tLoss: 0.163178\n",
      "Train Epoch: 41 [200/798 (25%)]\tLoss: 0.625748\n",
      "Train Epoch: 41 [300/798 (38%)]\tLoss: 0.080206\n",
      "Train Epoch: 41 [400/798 (50%)]\tLoss: 0.224296\n",
      "Train Epoch: 41 [500/798 (62%)]\tLoss: 0.365584\n",
      "Train Epoch: 41 [600/798 (75%)]\tLoss: 0.740352\n",
      "Train Epoch: 41 [700/798 (88%)]\tLoss: 0.110039\n",
      "\n",
      "Test set: Avg. loss: 0.0718, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 42 [0/798 (0%)]\tLoss: 0.253701\n",
      "Train Epoch: 42 [100/798 (12%)]\tLoss: 0.391947\n",
      "Train Epoch: 42 [200/798 (25%)]\tLoss: 0.133455\n",
      "Train Epoch: 42 [300/798 (38%)]\tLoss: 0.429589\n",
      "Train Epoch: 42 [400/798 (50%)]\tLoss: 0.052366\n",
      "Train Epoch: 42 [500/798 (62%)]\tLoss: 0.224438\n",
      "Train Epoch: 42 [600/798 (75%)]\tLoss: 0.017817\n",
      "Train Epoch: 42 [700/798 (88%)]\tLoss: 0.390595\n",
      "\n",
      "Test set: Avg. loss: 0.0534, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 43 [0/798 (0%)]\tLoss: 0.091487\n",
      "Train Epoch: 43 [100/798 (12%)]\tLoss: 0.240409\n",
      "Train Epoch: 43 [200/798 (25%)]\tLoss: 0.309424\n",
      "Train Epoch: 43 [300/798 (38%)]\tLoss: 0.153717\n",
      "Train Epoch: 43 [400/798 (50%)]\tLoss: 0.079434\n",
      "Train Epoch: 43 [500/798 (62%)]\tLoss: 0.170212\n",
      "Train Epoch: 43 [600/798 (75%)]\tLoss: 0.149592\n",
      "Train Epoch: 43 [700/798 (88%)]\tLoss: 1.232486\n",
      "\n",
      "Test set: Avg. loss: 0.1010, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 44 [0/798 (0%)]\tLoss: 0.063935\n",
      "Train Epoch: 44 [100/798 (12%)]\tLoss: 0.201237\n",
      "Train Epoch: 44 [200/798 (25%)]\tLoss: 0.223214\n",
      "Train Epoch: 44 [300/798 (38%)]\tLoss: 0.228682\n",
      "Train Epoch: 44 [400/798 (50%)]\tLoss: 0.043422\n",
      "Train Epoch: 44 [500/798 (62%)]\tLoss: 0.301010\n",
      "Train Epoch: 44 [600/798 (75%)]\tLoss: 0.234040\n",
      "Train Epoch: 44 [700/798 (88%)]\tLoss: 0.226706\n",
      "\n",
      "Test set: Avg. loss: 0.1124, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 45 [0/798 (0%)]\tLoss: 0.219696\n",
      "Train Epoch: 45 [100/798 (12%)]\tLoss: 0.022915\n",
      "Train Epoch: 45 [200/798 (25%)]\tLoss: 0.444778\n",
      "Train Epoch: 45 [300/798 (38%)]\tLoss: 0.404075\n",
      "Train Epoch: 45 [400/798 (50%)]\tLoss: 0.060764\n",
      "Train Epoch: 45 [500/798 (62%)]\tLoss: 0.012016\n",
      "Train Epoch: 45 [600/798 (75%)]\tLoss: 0.361736\n",
      "Train Epoch: 45 [700/798 (88%)]\tLoss: 0.081763\n",
      "\n",
      "Test set: Avg. loss: 0.0646, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 46 [0/798 (0%)]\tLoss: 0.220381\n",
      "Train Epoch: 46 [100/798 (12%)]\tLoss: 0.332398\n",
      "Train Epoch: 46 [200/798 (25%)]\tLoss: 0.131033\n",
      "Train Epoch: 46 [300/798 (38%)]\tLoss: 0.121954\n",
      "Train Epoch: 46 [400/798 (50%)]\tLoss: 0.200097\n",
      "Train Epoch: 46 [500/798 (62%)]\tLoss: 0.089295\n",
      "Train Epoch: 46 [600/798 (75%)]\tLoss: 0.297049\n",
      "Train Epoch: 46 [700/798 (88%)]\tLoss: 0.763773\n",
      "\n",
      "Test set: Avg. loss: 0.0851, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 47 [0/798 (0%)]\tLoss: 0.447209\n",
      "Train Epoch: 47 [100/798 (12%)]\tLoss: 0.489393\n",
      "Train Epoch: 47 [200/798 (25%)]\tLoss: 0.152241\n",
      "Train Epoch: 47 [300/798 (38%)]\tLoss: 0.133074\n",
      "Train Epoch: 47 [400/798 (50%)]\tLoss: 0.146551\n",
      "Train Epoch: 47 [500/798 (62%)]\tLoss: 0.120757\n",
      "Train Epoch: 47 [600/798 (75%)]\tLoss: 0.327731\n",
      "Train Epoch: 47 [700/798 (88%)]\tLoss: 0.187022\n",
      "\n",
      "Test set: Avg. loss: 0.0948, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 48 [0/798 (0%)]\tLoss: 0.085020\n",
      "Train Epoch: 48 [100/798 (12%)]\tLoss: 0.064025\n",
      "Train Epoch: 48 [200/798 (25%)]\tLoss: 0.564347\n",
      "Train Epoch: 48 [300/798 (38%)]\tLoss: 0.304705\n",
      "Train Epoch: 48 [400/798 (50%)]\tLoss: 0.900802\n",
      "Train Epoch: 48 [500/798 (62%)]\tLoss: 0.082040\n",
      "Train Epoch: 48 [600/798 (75%)]\tLoss: 0.671172\n",
      "Train Epoch: 48 [700/798 (88%)]\tLoss: 0.503344\n",
      "\n",
      "Test set: Avg. loss: 0.0796, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 49 [0/798 (0%)]\tLoss: 0.312908\n",
      "Train Epoch: 49 [100/798 (12%)]\tLoss: 0.072111\n",
      "Train Epoch: 49 [200/798 (25%)]\tLoss: 0.219787\n",
      "Train Epoch: 49 [300/798 (38%)]\tLoss: 0.369014\n",
      "Train Epoch: 49 [400/798 (50%)]\tLoss: 1.060897\n",
      "Train Epoch: 49 [500/798 (62%)]\tLoss: 0.081417\n",
      "Train Epoch: 49 [600/798 (75%)]\tLoss: 0.049505\n",
      "Train Epoch: 49 [700/798 (88%)]\tLoss: 0.024426\n",
      "\n",
      "Test set: Avg. loss: 0.0700, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 50 [0/798 (0%)]\tLoss: 0.065791\n",
      "Train Epoch: 50 [100/798 (12%)]\tLoss: 0.172273\n",
      "Train Epoch: 50 [200/798 (25%)]\tLoss: 0.311856\n",
      "Train Epoch: 50 [300/798 (38%)]\tLoss: 0.410504\n",
      "Train Epoch: 50 [400/798 (50%)]\tLoss: 0.033429\n",
      "Train Epoch: 50 [500/798 (62%)]\tLoss: 0.160944\n",
      "Train Epoch: 50 [600/798 (75%)]\tLoss: 0.314838\n",
      "Train Epoch: 50 [700/798 (88%)]\tLoss: 0.214686\n",
      "\n",
      "Test set: Avg. loss: 0.0622, Accuracy: 196/200 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0622, Accuracy: 196/200 (98%)\n",
      "\n",
      "Running bootstrap experiment: 2\n",
      "Train Epoch: 1 [0/798 (0%)]\tLoss: 2.311156\n",
      "Train Epoch: 1 [100/798 (12%)]\tLoss: 2.322956\n",
      "Train Epoch: 1 [200/798 (25%)]\tLoss: 2.320656\n",
      "Train Epoch: 1 [300/798 (38%)]\tLoss: 2.375037\n",
      "Train Epoch: 1 [400/798 (50%)]\tLoss: 2.321434\n",
      "Train Epoch: 1 [500/798 (62%)]\tLoss: 2.320297\n",
      "Train Epoch: 1 [600/798 (75%)]\tLoss: 2.291804\n",
      "Train Epoch: 1 [700/798 (88%)]\tLoss: 2.271300\n",
      "\n",
      "Test set: Avg. loss: 2.3000, Accuracy: 34/200 (17%)\n",
      "\n",
      "Train Epoch: 2 [0/798 (0%)]\tLoss: 2.325213\n",
      "Train Epoch: 2 [100/798 (12%)]\tLoss: 2.293961\n",
      "Train Epoch: 2 [200/798 (25%)]\tLoss: 2.323835\n",
      "Train Epoch: 2 [300/798 (38%)]\tLoss: 2.294611\n",
      "Train Epoch: 2 [400/798 (50%)]\tLoss: 2.278728\n",
      "Train Epoch: 2 [500/798 (62%)]\tLoss: 2.296174\n",
      "Train Epoch: 2 [600/798 (75%)]\tLoss: 2.325195\n",
      "Train Epoch: 2 [700/798 (88%)]\tLoss: 2.301190\n",
      "\n",
      "Test set: Avg. loss: 2.2900, Accuracy: 30/200 (15%)\n",
      "\n",
      "Train Epoch: 3 [0/798 (0%)]\tLoss: 2.254672\n",
      "Train Epoch: 3 [100/798 (12%)]\tLoss: 2.280704\n",
      "Train Epoch: 3 [200/798 (25%)]\tLoss: 2.234687\n",
      "Train Epoch: 3 [300/798 (38%)]\tLoss: 2.298190\n",
      "Train Epoch: 3 [400/798 (50%)]\tLoss: 2.274275\n",
      "Train Epoch: 3 [500/798 (62%)]\tLoss: 2.208046\n",
      "Train Epoch: 3 [600/798 (75%)]\tLoss: 2.293903\n",
      "Train Epoch: 3 [700/798 (88%)]\tLoss: 2.263360\n",
      "\n",
      "Test set: Avg. loss: 2.2729, Accuracy: 31/200 (16%)\n",
      "\n",
      "Train Epoch: 4 [0/798 (0%)]\tLoss: 2.297328\n",
      "Train Epoch: 4 [100/798 (12%)]\tLoss: 2.275525\n",
      "Train Epoch: 4 [200/798 (25%)]\tLoss: 2.257119\n",
      "Train Epoch: 4 [300/798 (38%)]\tLoss: 2.369716\n",
      "Train Epoch: 4 [400/798 (50%)]\tLoss: 2.268212\n",
      "Train Epoch: 4 [500/798 (62%)]\tLoss: 2.279790\n",
      "Train Epoch: 4 [600/798 (75%)]\tLoss: 2.161442\n",
      "Train Epoch: 4 [700/798 (88%)]\tLoss: 2.080980\n",
      "\n",
      "Test set: Avg. loss: 2.1766, Accuracy: 50/200 (25%)\n",
      "\n",
      "Train Epoch: 5 [0/798 (0%)]\tLoss: 2.200555\n",
      "Train Epoch: 5 [100/798 (12%)]\tLoss: 2.150315\n",
      "Train Epoch: 5 [200/798 (25%)]\tLoss: 2.291835\n",
      "Train Epoch: 5 [300/798 (38%)]\tLoss: 2.385968\n",
      "Train Epoch: 5 [400/798 (50%)]\tLoss: 1.909551\n",
      "Train Epoch: 5 [500/798 (62%)]\tLoss: 2.040155\n",
      "Train Epoch: 5 [600/798 (75%)]\tLoss: 2.187138\n",
      "Train Epoch: 5 [700/798 (88%)]\tLoss: 2.022492\n",
      "\n",
      "Test set: Avg. loss: 2.0031, Accuracy: 61/200 (30%)\n",
      "\n",
      "Train Epoch: 6 [0/798 (0%)]\tLoss: 1.983529\n",
      "Train Epoch: 6 [100/798 (12%)]\tLoss: 1.805001\n",
      "Train Epoch: 6 [200/798 (25%)]\tLoss: 1.692683\n",
      "Train Epoch: 6 [300/798 (38%)]\tLoss: 2.041701\n",
      "Train Epoch: 6 [400/798 (50%)]\tLoss: 1.984952\n",
      "Train Epoch: 6 [500/798 (62%)]\tLoss: 1.684044\n",
      "Train Epoch: 6 [600/798 (75%)]\tLoss: 1.713508\n",
      "Train Epoch: 6 [700/798 (88%)]\tLoss: 1.716245\n",
      "\n",
      "Test set: Avg. loss: 1.6976, Accuracy: 78/200 (39%)\n",
      "\n",
      "Train Epoch: 7 [0/798 (0%)]\tLoss: 1.906781\n",
      "Train Epoch: 7 [100/798 (12%)]\tLoss: 1.980957\n",
      "Train Epoch: 7 [200/798 (25%)]\tLoss: 1.698043\n",
      "Train Epoch: 7 [300/798 (38%)]\tLoss: 1.519998\n",
      "Train Epoch: 7 [400/798 (50%)]\tLoss: 1.666123\n",
      "Train Epoch: 7 [500/798 (62%)]\tLoss: 1.729445\n",
      "Train Epoch: 7 [600/798 (75%)]\tLoss: 1.525530\n",
      "Train Epoch: 7 [700/798 (88%)]\tLoss: 1.693996\n",
      "\n",
      "Test set: Avg. loss: 1.3367, Accuracy: 137/200 (68%)\n",
      "\n",
      "Train Epoch: 8 [0/798 (0%)]\tLoss: 1.636775\n",
      "Train Epoch: 8 [100/798 (12%)]\tLoss: 1.535427\n",
      "Train Epoch: 8 [200/798 (25%)]\tLoss: 1.596161\n",
      "Train Epoch: 8 [300/798 (38%)]\tLoss: 1.518973\n",
      "Train Epoch: 8 [400/798 (50%)]\tLoss: 1.421850\n",
      "Train Epoch: 8 [500/798 (62%)]\tLoss: 1.125559\n",
      "Train Epoch: 8 [600/798 (75%)]\tLoss: 1.048671\n",
      "Train Epoch: 8 [700/798 (88%)]\tLoss: 1.119745\n",
      "\n",
      "Test set: Avg. loss: 1.0275, Accuracy: 140/200 (70%)\n",
      "\n",
      "Train Epoch: 9 [0/798 (0%)]\tLoss: 1.354035\n",
      "Train Epoch: 9 [100/798 (12%)]\tLoss: 1.294061\n",
      "Train Epoch: 9 [200/798 (25%)]\tLoss: 0.708488\n",
      "Train Epoch: 9 [300/798 (38%)]\tLoss: 1.182498\n",
      "Train Epoch: 9 [400/798 (50%)]\tLoss: 1.390341\n",
      "Train Epoch: 9 [500/798 (62%)]\tLoss: 1.020278\n",
      "Train Epoch: 9 [600/798 (75%)]\tLoss: 1.064736\n",
      "Train Epoch: 9 [700/798 (88%)]\tLoss: 1.132109\n",
      "\n",
      "Test set: Avg. loss: 0.7565, Accuracy: 163/200 (82%)\n",
      "\n",
      "Train Epoch: 10 [0/798 (0%)]\tLoss: 1.011051\n",
      "Train Epoch: 10 [100/798 (12%)]\tLoss: 1.136396\n",
      "Train Epoch: 10 [200/798 (25%)]\tLoss: 0.695717\n",
      "Train Epoch: 10 [300/798 (38%)]\tLoss: 0.781318\n",
      "Train Epoch: 10 [400/798 (50%)]\tLoss: 1.194046\n",
      "Train Epoch: 10 [500/798 (62%)]\tLoss: 1.089518\n",
      "Train Epoch: 10 [600/798 (75%)]\tLoss: 2.118537\n",
      "Train Epoch: 10 [700/798 (88%)]\tLoss: 1.260077\n",
      "\n",
      "Test set: Avg. loss: 0.6465, Accuracy: 185/200 (92%)\n",
      "\n",
      "Train Epoch: 11 [0/798 (0%)]\tLoss: 1.013551\n",
      "Train Epoch: 11 [100/798 (12%)]\tLoss: 1.219221\n",
      "Train Epoch: 11 [200/798 (25%)]\tLoss: 0.710271\n",
      "Train Epoch: 11 [300/798 (38%)]\tLoss: 1.073972\n",
      "Train Epoch: 11 [400/798 (50%)]\tLoss: 1.000827\n",
      "Train Epoch: 11 [500/798 (62%)]\tLoss: 0.859351\n",
      "Train Epoch: 11 [600/798 (75%)]\tLoss: 1.667050\n",
      "Train Epoch: 11 [700/798 (88%)]\tLoss: 0.506065\n",
      "\n",
      "Test set: Avg. loss: 0.4914, Accuracy: 178/200 (89%)\n",
      "\n",
      "Train Epoch: 12 [0/798 (0%)]\tLoss: 0.865421\n",
      "Train Epoch: 12 [100/798 (12%)]\tLoss: 0.742227\n",
      "Train Epoch: 12 [200/798 (25%)]\tLoss: 0.826453\n",
      "Train Epoch: 12 [300/798 (38%)]\tLoss: 0.811887\n",
      "Train Epoch: 12 [400/798 (50%)]\tLoss: 0.753415\n",
      "Train Epoch: 12 [500/798 (62%)]\tLoss: 0.546513\n",
      "Train Epoch: 12 [600/798 (75%)]\tLoss: 0.851442\n",
      "Train Epoch: 12 [700/798 (88%)]\tLoss: 0.526010\n",
      "\n",
      "Test set: Avg. loss: 0.3727, Accuracy: 188/200 (94%)\n",
      "\n",
      "Train Epoch: 13 [0/798 (0%)]\tLoss: 0.253885\n",
      "Train Epoch: 13 [100/798 (12%)]\tLoss: 0.628927\n",
      "Train Epoch: 13 [200/798 (25%)]\tLoss: 0.852440\n",
      "Train Epoch: 13 [300/798 (38%)]\tLoss: 0.596092\n",
      "Train Epoch: 13 [400/798 (50%)]\tLoss: 0.862944\n",
      "Train Epoch: 13 [500/798 (62%)]\tLoss: 1.644918\n",
      "Train Epoch: 13 [600/798 (75%)]\tLoss: 1.049661\n",
      "Train Epoch: 13 [700/798 (88%)]\tLoss: 0.768934\n",
      "\n",
      "Test set: Avg. loss: 0.2901, Accuracy: 188/200 (94%)\n",
      "\n",
      "Train Epoch: 14 [0/798 (0%)]\tLoss: 0.477875\n",
      "Train Epoch: 14 [100/798 (12%)]\tLoss: 0.708221\n",
      "Train Epoch: 14 [200/798 (25%)]\tLoss: 0.797711\n",
      "Train Epoch: 14 [300/798 (38%)]\tLoss: 1.061286\n",
      "Train Epoch: 14 [400/798 (50%)]\tLoss: 1.118354\n",
      "Train Epoch: 14 [500/798 (62%)]\tLoss: 0.805166\n",
      "Train Epoch: 14 [600/798 (75%)]\tLoss: 0.647463\n",
      "Train Epoch: 14 [700/798 (88%)]\tLoss: 0.950972\n",
      "\n",
      "Test set: Avg. loss: 0.2832, Accuracy: 192/200 (96%)\n",
      "\n",
      "Train Epoch: 15 [0/798 (0%)]\tLoss: 0.921365\n",
      "Train Epoch: 15 [100/798 (12%)]\tLoss: 0.763217\n",
      "Train Epoch: 15 [200/798 (25%)]\tLoss: 0.788519\n",
      "Train Epoch: 15 [300/798 (38%)]\tLoss: 0.743659\n",
      "Train Epoch: 15 [400/798 (50%)]\tLoss: 0.312641\n",
      "Train Epoch: 15 [500/798 (62%)]\tLoss: 0.494128\n",
      "Train Epoch: 15 [600/798 (75%)]\tLoss: 0.637564\n",
      "Train Epoch: 15 [700/798 (88%)]\tLoss: 0.690665\n",
      "\n",
      "Test set: Avg. loss: 0.2434, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 16 [0/798 (0%)]\tLoss: 0.160886\n",
      "Train Epoch: 16 [100/798 (12%)]\tLoss: 0.177013\n",
      "Train Epoch: 16 [200/798 (25%)]\tLoss: 0.725270\n",
      "Train Epoch: 16 [300/798 (38%)]\tLoss: 0.734790\n",
      "Train Epoch: 16 [400/798 (50%)]\tLoss: 0.232758\n",
      "Train Epoch: 16 [500/798 (62%)]\tLoss: 0.703128\n",
      "Train Epoch: 16 [600/798 (75%)]\tLoss: 0.898191\n",
      "Train Epoch: 16 [700/798 (88%)]\tLoss: 0.837720\n",
      "\n",
      "Test set: Avg. loss: 0.1919, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/798 (0%)]\tLoss: 1.170921\n",
      "Train Epoch: 17 [100/798 (12%)]\tLoss: 0.844921\n",
      "Train Epoch: 17 [200/798 (25%)]\tLoss: 0.802394\n",
      "Train Epoch: 17 [300/798 (38%)]\tLoss: 0.091943\n",
      "Train Epoch: 17 [400/798 (50%)]\tLoss: 0.506545\n",
      "Train Epoch: 17 [500/798 (62%)]\tLoss: 0.800125\n",
      "Train Epoch: 17 [600/798 (75%)]\tLoss: 0.930660\n",
      "Train Epoch: 17 [700/798 (88%)]\tLoss: 0.666473\n",
      "\n",
      "Test set: Avg. loss: 0.1846, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 18 [0/798 (0%)]\tLoss: 0.225146\n",
      "Train Epoch: 18 [100/798 (12%)]\tLoss: 0.371906\n",
      "Train Epoch: 18 [200/798 (25%)]\tLoss: 0.508619\n",
      "Train Epoch: 18 [300/798 (38%)]\tLoss: 0.690251\n",
      "Train Epoch: 18 [400/798 (50%)]\tLoss: 0.502505\n",
      "Train Epoch: 18 [500/798 (62%)]\tLoss: 0.336376\n",
      "Train Epoch: 18 [600/798 (75%)]\tLoss: 0.642444\n",
      "Train Epoch: 18 [700/798 (88%)]\tLoss: 0.313169\n",
      "\n",
      "Test set: Avg. loss: 0.1240, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/798 (0%)]\tLoss: 0.457568\n",
      "Train Epoch: 19 [100/798 (12%)]\tLoss: 0.505043\n",
      "Train Epoch: 19 [200/798 (25%)]\tLoss: 0.233980\n",
      "Train Epoch: 19 [300/798 (38%)]\tLoss: 0.479967\n",
      "Train Epoch: 19 [400/798 (50%)]\tLoss: 0.584572\n",
      "Train Epoch: 19 [500/798 (62%)]\tLoss: 0.571921\n",
      "Train Epoch: 19 [600/798 (75%)]\tLoss: 0.353204\n",
      "Train Epoch: 19 [700/798 (88%)]\tLoss: 0.216076\n",
      "\n",
      "Test set: Avg. loss: 0.1204, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/798 (0%)]\tLoss: 0.526460\n",
      "Train Epoch: 20 [100/798 (12%)]\tLoss: 0.541492\n",
      "Train Epoch: 20 [200/798 (25%)]\tLoss: 0.679313\n",
      "Train Epoch: 20 [300/798 (38%)]\tLoss: 0.289536\n",
      "Train Epoch: 20 [400/798 (50%)]\tLoss: 0.757470\n",
      "Train Epoch: 20 [500/798 (62%)]\tLoss: 0.782029\n",
      "Train Epoch: 20 [600/798 (75%)]\tLoss: 0.463351\n",
      "Train Epoch: 20 [700/798 (88%)]\tLoss: 0.404591\n",
      "\n",
      "Test set: Avg. loss: 0.1118, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/798 (0%)]\tLoss: 0.638335\n",
      "Train Epoch: 21 [100/798 (12%)]\tLoss: 0.688878\n",
      "Train Epoch: 21 [200/798 (25%)]\tLoss: 0.336628\n",
      "Train Epoch: 21 [300/798 (38%)]\tLoss: 0.508572\n",
      "Train Epoch: 21 [400/798 (50%)]\tLoss: 0.419470\n",
      "Train Epoch: 21 [500/798 (62%)]\tLoss: 0.294315\n",
      "Train Epoch: 21 [600/798 (75%)]\tLoss: 0.176067\n",
      "Train Epoch: 21 [700/798 (88%)]\tLoss: 0.193400\n",
      "\n",
      "Test set: Avg. loss: 0.1087, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/798 (0%)]\tLoss: 0.257471\n",
      "Train Epoch: 22 [100/798 (12%)]\tLoss: 0.413259\n",
      "Train Epoch: 22 [200/798 (25%)]\tLoss: 0.326166\n",
      "Train Epoch: 22 [300/798 (38%)]\tLoss: 0.164673\n",
      "Train Epoch: 22 [400/798 (50%)]\tLoss: 0.367063\n",
      "Train Epoch: 22 [500/798 (62%)]\tLoss: 0.313461\n",
      "Train Epoch: 22 [600/798 (75%)]\tLoss: 0.501840\n",
      "Train Epoch: 22 [700/798 (88%)]\tLoss: 0.331456\n",
      "\n",
      "Test set: Avg. loss: 0.0877, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/798 (0%)]\tLoss: 0.760372\n",
      "Train Epoch: 23 [100/798 (12%)]\tLoss: 0.146756\n",
      "Train Epoch: 23 [200/798 (25%)]\tLoss: 0.538748\n",
      "Train Epoch: 23 [300/798 (38%)]\tLoss: 0.384113\n",
      "Train Epoch: 23 [400/798 (50%)]\tLoss: 0.768387\n",
      "Train Epoch: 23 [500/798 (62%)]\tLoss: 0.561051\n",
      "Train Epoch: 23 [600/798 (75%)]\tLoss: 0.248342\n",
      "Train Epoch: 23 [700/798 (88%)]\tLoss: 0.333098\n",
      "\n",
      "Test set: Avg. loss: 0.1024, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/798 (0%)]\tLoss: 0.201943\n",
      "Train Epoch: 24 [100/798 (12%)]\tLoss: 0.638478\n",
      "Train Epoch: 24 [200/798 (25%)]\tLoss: 0.459397\n",
      "Train Epoch: 24 [300/798 (38%)]\tLoss: 1.046731\n",
      "Train Epoch: 24 [400/798 (50%)]\tLoss: 0.296728\n",
      "Train Epoch: 24 [500/798 (62%)]\tLoss: 0.482762\n",
      "Train Epoch: 24 [600/798 (75%)]\tLoss: 0.277992\n",
      "Train Epoch: 24 [700/798 (88%)]\tLoss: 0.511188\n",
      "\n",
      "Test set: Avg. loss: 0.0970, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/798 (0%)]\tLoss: 0.159668\n",
      "Train Epoch: 25 [100/798 (12%)]\tLoss: 0.147420\n",
      "Train Epoch: 25 [200/798 (25%)]\tLoss: 0.209185\n",
      "Train Epoch: 25 [300/798 (38%)]\tLoss: 0.472777\n",
      "Train Epoch: 25 [400/798 (50%)]\tLoss: 0.354532\n",
      "Train Epoch: 25 [500/798 (62%)]\tLoss: 0.584005\n",
      "Train Epoch: 25 [600/798 (75%)]\tLoss: 0.259482\n",
      "Train Epoch: 25 [700/798 (88%)]\tLoss: 0.453597\n",
      "\n",
      "Test set: Avg. loss: 0.0829, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/798 (0%)]\tLoss: 0.454302\n",
      "Train Epoch: 26 [100/798 (12%)]\tLoss: 0.343707\n",
      "Train Epoch: 26 [200/798 (25%)]\tLoss: 0.538466\n",
      "Train Epoch: 26 [300/798 (38%)]\tLoss: 0.376875\n",
      "Train Epoch: 26 [400/798 (50%)]\tLoss: 1.277214\n",
      "Train Epoch: 26 [500/798 (62%)]\tLoss: 0.160863\n",
      "Train Epoch: 26 [600/798 (75%)]\tLoss: 0.188093\n",
      "Train Epoch: 26 [700/798 (88%)]\tLoss: 0.351528\n",
      "\n",
      "Test set: Avg. loss: 0.0746, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/798 (0%)]\tLoss: 0.523220\n",
      "Train Epoch: 27 [100/798 (12%)]\tLoss: 0.646165\n",
      "Train Epoch: 27 [200/798 (25%)]\tLoss: 0.325938\n",
      "Train Epoch: 27 [300/798 (38%)]\tLoss: 0.203571\n",
      "Train Epoch: 27 [400/798 (50%)]\tLoss: 0.124781\n",
      "Train Epoch: 27 [500/798 (62%)]\tLoss: 0.618039\n",
      "Train Epoch: 27 [600/798 (75%)]\tLoss: 0.812516\n",
      "Train Epoch: 27 [700/798 (88%)]\tLoss: 0.421908\n",
      "\n",
      "Test set: Avg. loss: 0.0874, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/798 (0%)]\tLoss: 0.265986\n",
      "Train Epoch: 28 [100/798 (12%)]\tLoss: 0.281481\n",
      "Train Epoch: 28 [200/798 (25%)]\tLoss: 0.196160\n",
      "Train Epoch: 28 [300/798 (38%)]\tLoss: 0.251693\n",
      "Train Epoch: 28 [400/798 (50%)]\tLoss: 1.032064\n",
      "Train Epoch: 28 [500/798 (62%)]\tLoss: 0.322004\n",
      "Train Epoch: 28 [600/798 (75%)]\tLoss: 0.162458\n",
      "Train Epoch: 28 [700/798 (88%)]\tLoss: 0.205576\n",
      "\n",
      "Test set: Avg. loss: 0.0701, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/798 (0%)]\tLoss: 0.074949\n",
      "Train Epoch: 29 [100/798 (12%)]\tLoss: 0.363045\n",
      "Train Epoch: 29 [200/798 (25%)]\tLoss: 0.453737\n",
      "Train Epoch: 29 [300/798 (38%)]\tLoss: 0.044288\n",
      "Train Epoch: 29 [400/798 (50%)]\tLoss: 0.127393\n",
      "Train Epoch: 29 [500/798 (62%)]\tLoss: 0.188688\n",
      "Train Epoch: 29 [600/798 (75%)]\tLoss: 0.621695\n",
      "Train Epoch: 29 [700/798 (88%)]\tLoss: 0.168944\n",
      "\n",
      "Test set: Avg. loss: 0.0757, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 30 [0/798 (0%)]\tLoss: 0.105133\n",
      "Train Epoch: 30 [100/798 (12%)]\tLoss: 0.404364\n",
      "Train Epoch: 30 [200/798 (25%)]\tLoss: 0.085372\n",
      "Train Epoch: 30 [300/798 (38%)]\tLoss: 0.354278\n",
      "Train Epoch: 30 [400/798 (50%)]\tLoss: 0.113533\n",
      "Train Epoch: 30 [500/798 (62%)]\tLoss: 0.037397\n",
      "Train Epoch: 30 [600/798 (75%)]\tLoss: 0.183173\n",
      "Train Epoch: 30 [700/798 (88%)]\tLoss: 0.204044\n",
      "\n",
      "Test set: Avg. loss: 0.0708, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/798 (0%)]\tLoss: 0.428927\n",
      "Train Epoch: 31 [100/798 (12%)]\tLoss: 0.540923\n",
      "Train Epoch: 31 [200/798 (25%)]\tLoss: 0.266605\n",
      "Train Epoch: 31 [300/798 (38%)]\tLoss: 0.545818\n",
      "Train Epoch: 31 [400/798 (50%)]\tLoss: 0.220084\n",
      "Train Epoch: 31 [500/798 (62%)]\tLoss: 0.260980\n",
      "Train Epoch: 31 [600/798 (75%)]\tLoss: 0.213040\n",
      "Train Epoch: 31 [700/798 (88%)]\tLoss: 0.616787\n",
      "\n",
      "Test set: Avg. loss: 0.0789, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 32 [0/798 (0%)]\tLoss: 0.356262\n",
      "Train Epoch: 32 [100/798 (12%)]\tLoss: 0.394661\n",
      "Train Epoch: 32 [200/798 (25%)]\tLoss: 0.214306\n",
      "Train Epoch: 32 [300/798 (38%)]\tLoss: 0.500513\n",
      "Train Epoch: 32 [400/798 (50%)]\tLoss: 0.374871\n",
      "Train Epoch: 32 [500/798 (62%)]\tLoss: 0.497221\n",
      "Train Epoch: 32 [600/798 (75%)]\tLoss: 0.341387\n",
      "Train Epoch: 32 [700/798 (88%)]\tLoss: 0.069765\n",
      "\n",
      "Test set: Avg. loss: 0.0603, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 33 [0/798 (0%)]\tLoss: 0.699483\n",
      "Train Epoch: 33 [100/798 (12%)]\tLoss: 0.208244\n",
      "Train Epoch: 33 [200/798 (25%)]\tLoss: 0.250060\n",
      "Train Epoch: 33 [300/798 (38%)]\tLoss: 0.079273\n",
      "Train Epoch: 33 [400/798 (50%)]\tLoss: 0.094031\n",
      "Train Epoch: 33 [500/798 (62%)]\tLoss: 0.366409\n",
      "Train Epoch: 33 [600/798 (75%)]\tLoss: 0.665558\n",
      "Train Epoch: 33 [700/798 (88%)]\tLoss: 0.095240\n",
      "\n",
      "Test set: Avg. loss: 0.0577, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/798 (0%)]\tLoss: 0.144322\n",
      "Train Epoch: 34 [100/798 (12%)]\tLoss: 0.194032\n",
      "Train Epoch: 34 [200/798 (25%)]\tLoss: 0.187301\n",
      "Train Epoch: 34 [300/798 (38%)]\tLoss: 0.123098\n",
      "Train Epoch: 34 [400/798 (50%)]\tLoss: 0.224955\n",
      "Train Epoch: 34 [500/798 (62%)]\tLoss: 0.761437\n",
      "Train Epoch: 34 [600/798 (75%)]\tLoss: 0.148471\n",
      "Train Epoch: 34 [700/798 (88%)]\tLoss: 0.822244\n",
      "\n",
      "Test set: Avg. loss: 0.0487, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 35 [0/798 (0%)]\tLoss: 0.408114\n",
      "Train Epoch: 35 [100/798 (12%)]\tLoss: 0.331845\n",
      "Train Epoch: 35 [200/798 (25%)]\tLoss: 0.250367\n",
      "Train Epoch: 35 [300/798 (38%)]\tLoss: 0.018812\n",
      "Train Epoch: 35 [400/798 (50%)]\tLoss: 0.306827\n",
      "Train Epoch: 35 [500/798 (62%)]\tLoss: 0.321286\n",
      "Train Epoch: 35 [600/798 (75%)]\tLoss: 0.697046\n",
      "Train Epoch: 35 [700/798 (88%)]\tLoss: 0.190692\n",
      "\n",
      "Test set: Avg. loss: 0.0634, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 36 [0/798 (0%)]\tLoss: 0.345276\n",
      "Train Epoch: 36 [100/798 (12%)]\tLoss: 0.626576\n",
      "Train Epoch: 36 [200/798 (25%)]\tLoss: 0.128440\n",
      "Train Epoch: 36 [300/798 (38%)]\tLoss: 0.522730\n",
      "Train Epoch: 36 [400/798 (50%)]\tLoss: 0.302652\n",
      "Train Epoch: 36 [500/798 (62%)]\tLoss: 0.080133\n",
      "Train Epoch: 36 [600/798 (75%)]\tLoss: 0.697546\n",
      "Train Epoch: 36 [700/798 (88%)]\tLoss: 0.048724\n",
      "\n",
      "Test set: Avg. loss: 0.0500, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 37 [0/798 (0%)]\tLoss: 0.407773\n",
      "Train Epoch: 37 [100/798 (12%)]\tLoss: 0.106919\n",
      "Train Epoch: 37 [200/798 (25%)]\tLoss: 0.090021\n",
      "Train Epoch: 37 [300/798 (38%)]\tLoss: 0.026284\n",
      "Train Epoch: 37 [400/798 (50%)]\tLoss: 0.067254\n",
      "Train Epoch: 37 [500/798 (62%)]\tLoss: 0.168015\n",
      "Train Epoch: 37 [600/798 (75%)]\tLoss: 0.171974\n",
      "Train Epoch: 37 [700/798 (88%)]\tLoss: 0.492266\n",
      "\n",
      "Test set: Avg. loss: 0.0471, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 38 [0/798 (0%)]\tLoss: 0.245625\n",
      "Train Epoch: 38 [100/798 (12%)]\tLoss: 0.238074\n",
      "Train Epoch: 38 [200/798 (25%)]\tLoss: 0.168618\n",
      "Train Epoch: 38 [300/798 (38%)]\tLoss: 0.011554\n",
      "Train Epoch: 38 [400/798 (50%)]\tLoss: 0.367730\n",
      "Train Epoch: 38 [500/798 (62%)]\tLoss: 0.158763\n",
      "Train Epoch: 38 [600/798 (75%)]\tLoss: 0.186300\n",
      "Train Epoch: 38 [700/798 (88%)]\tLoss: 0.173636\n",
      "\n",
      "Test set: Avg. loss: 0.0489, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 39 [0/798 (0%)]\tLoss: 0.057426\n",
      "Train Epoch: 39 [100/798 (12%)]\tLoss: 0.517359\n",
      "Train Epoch: 39 [200/798 (25%)]\tLoss: 0.000437\n",
      "Train Epoch: 39 [300/798 (38%)]\tLoss: 0.123592\n",
      "Train Epoch: 39 [400/798 (50%)]\tLoss: 0.243358\n",
      "Train Epoch: 39 [500/798 (62%)]\tLoss: 0.042508\n",
      "Train Epoch: 39 [600/798 (75%)]\tLoss: 0.883548\n",
      "Train Epoch: 39 [700/798 (88%)]\tLoss: 0.309049\n",
      "\n",
      "Test set: Avg. loss: 0.0496, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 40 [0/798 (0%)]\tLoss: 0.182424\n",
      "Train Epoch: 40 [100/798 (12%)]\tLoss: 0.397701\n",
      "Train Epoch: 40 [200/798 (25%)]\tLoss: 0.098886\n",
      "Train Epoch: 40 [300/798 (38%)]\tLoss: 0.007184\n",
      "Train Epoch: 40 [400/798 (50%)]\tLoss: 0.268745\n",
      "Train Epoch: 40 [500/798 (62%)]\tLoss: 0.416744\n",
      "Train Epoch: 40 [600/798 (75%)]\tLoss: 0.013497\n",
      "Train Epoch: 40 [700/798 (88%)]\tLoss: 0.021582\n",
      "\n",
      "Test set: Avg. loss: 0.0457, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 41 [0/798 (0%)]\tLoss: 0.227921\n",
      "Train Epoch: 41 [100/798 (12%)]\tLoss: 0.451309\n",
      "Train Epoch: 41 [200/798 (25%)]\tLoss: 0.339843\n",
      "Train Epoch: 41 [300/798 (38%)]\tLoss: 0.010297\n",
      "Train Epoch: 41 [400/798 (50%)]\tLoss: 0.431874\n",
      "Train Epoch: 41 [500/798 (62%)]\tLoss: 0.187429\n",
      "Train Epoch: 41 [600/798 (75%)]\tLoss: 0.028429\n",
      "Train Epoch: 41 [700/798 (88%)]\tLoss: 0.109442\n",
      "\n",
      "Test set: Avg. loss: 0.0442, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 42 [0/798 (0%)]\tLoss: 0.184956\n",
      "Train Epoch: 42 [100/798 (12%)]\tLoss: 0.068948\n",
      "Train Epoch: 42 [200/798 (25%)]\tLoss: 0.126289\n",
      "Train Epoch: 42 [300/798 (38%)]\tLoss: 0.163926\n",
      "Train Epoch: 42 [400/798 (50%)]\tLoss: 0.095680\n",
      "Train Epoch: 42 [500/798 (62%)]\tLoss: 0.438852\n",
      "Train Epoch: 42 [600/798 (75%)]\tLoss: 0.269565\n",
      "Train Epoch: 42 [700/798 (88%)]\tLoss: 0.311411\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 43 [0/798 (0%)]\tLoss: 0.287732\n",
      "Train Epoch: 43 [100/798 (12%)]\tLoss: 0.428205\n",
      "Train Epoch: 43 [200/798 (25%)]\tLoss: 0.406390\n",
      "Train Epoch: 43 [300/798 (38%)]\tLoss: 0.211988\n",
      "Train Epoch: 43 [400/798 (50%)]\tLoss: 0.081954\n",
      "Train Epoch: 43 [500/798 (62%)]\tLoss: 0.162048\n",
      "Train Epoch: 43 [600/798 (75%)]\tLoss: 0.145598\n",
      "Train Epoch: 43 [700/798 (88%)]\tLoss: 0.078557\n",
      "\n",
      "Test set: Avg. loss: 0.0400, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 44 [0/798 (0%)]\tLoss: 0.133033\n",
      "Train Epoch: 44 [100/798 (12%)]\tLoss: 0.465617\n",
      "Train Epoch: 44 [200/798 (25%)]\tLoss: 0.086021\n",
      "Train Epoch: 44 [300/798 (38%)]\tLoss: 0.509066\n",
      "Train Epoch: 44 [400/798 (50%)]\tLoss: 0.179603\n",
      "Train Epoch: 44 [500/798 (62%)]\tLoss: 0.594723\n",
      "Train Epoch: 44 [600/798 (75%)]\tLoss: 0.188721\n",
      "Train Epoch: 44 [700/798 (88%)]\tLoss: 0.349388\n",
      "\n",
      "Test set: Avg. loss: 0.0325, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 45 [0/798 (0%)]\tLoss: 0.615451\n",
      "Train Epoch: 45 [100/798 (12%)]\tLoss: 0.230535\n",
      "Train Epoch: 45 [200/798 (25%)]\tLoss: 0.155804\n",
      "Train Epoch: 45 [300/798 (38%)]\tLoss: 0.051774\n",
      "Train Epoch: 45 [400/798 (50%)]\tLoss: 0.382658\n",
      "Train Epoch: 45 [500/798 (62%)]\tLoss: 0.078653\n",
      "Train Epoch: 45 [600/798 (75%)]\tLoss: 0.500151\n",
      "Train Epoch: 45 [700/798 (88%)]\tLoss: 0.004668\n",
      "\n",
      "Test set: Avg. loss: 0.0428, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 46 [0/798 (0%)]\tLoss: 0.593796\n",
      "Train Epoch: 46 [100/798 (12%)]\tLoss: 0.494759\n",
      "Train Epoch: 46 [200/798 (25%)]\tLoss: 0.293579\n",
      "Train Epoch: 46 [300/798 (38%)]\tLoss: 0.112545\n",
      "Train Epoch: 46 [400/798 (50%)]\tLoss: 0.065179\n",
      "Train Epoch: 46 [500/798 (62%)]\tLoss: 0.470588\n",
      "Train Epoch: 46 [600/798 (75%)]\tLoss: 0.218689\n",
      "Train Epoch: 46 [700/798 (88%)]\tLoss: 0.344174\n",
      "\n",
      "Test set: Avg. loss: 0.0340, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 47 [0/798 (0%)]\tLoss: 0.215102\n",
      "Train Epoch: 47 [100/798 (12%)]\tLoss: 0.354207\n",
      "Train Epoch: 47 [200/798 (25%)]\tLoss: 0.132404\n",
      "Train Epoch: 47 [300/798 (38%)]\tLoss: 0.193607\n",
      "Train Epoch: 47 [400/798 (50%)]\tLoss: 0.023549\n",
      "Train Epoch: 47 [500/798 (62%)]\tLoss: 0.011087\n",
      "Train Epoch: 47 [600/798 (75%)]\tLoss: 0.273022\n",
      "Train Epoch: 47 [700/798 (88%)]\tLoss: 0.473548\n",
      "\n",
      "Test set: Avg. loss: 0.0341, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 48 [0/798 (0%)]\tLoss: 0.510153\n",
      "Train Epoch: 48 [100/798 (12%)]\tLoss: 0.056934\n",
      "Train Epoch: 48 [200/798 (25%)]\tLoss: 0.038758\n",
      "Train Epoch: 48 [300/798 (38%)]\tLoss: 0.377744\n",
      "Train Epoch: 48 [400/798 (50%)]\tLoss: 0.209346\n",
      "Train Epoch: 48 [500/798 (62%)]\tLoss: 0.454705\n",
      "Train Epoch: 48 [600/798 (75%)]\tLoss: 0.028392\n",
      "Train Epoch: 48 [700/798 (88%)]\tLoss: 0.246417\n",
      "\n",
      "Test set: Avg. loss: 0.0332, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 49 [0/798 (0%)]\tLoss: 0.160539\n",
      "Train Epoch: 49 [100/798 (12%)]\tLoss: 0.099389\n",
      "Train Epoch: 49 [200/798 (25%)]\tLoss: 0.386741\n",
      "Train Epoch: 49 [300/798 (38%)]\tLoss: 0.033508\n",
      "Train Epoch: 49 [400/798 (50%)]\tLoss: 0.177676\n",
      "Train Epoch: 49 [500/798 (62%)]\tLoss: 0.132083\n",
      "Train Epoch: 49 [600/798 (75%)]\tLoss: 0.174777\n",
      "Train Epoch: 49 [700/798 (88%)]\tLoss: 0.444942\n",
      "\n",
      "Test set: Avg. loss: 0.0436, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 50 [0/798 (0%)]\tLoss: 0.073396\n",
      "Train Epoch: 50 [100/798 (12%)]\tLoss: 0.351300\n",
      "Train Epoch: 50 [200/798 (25%)]\tLoss: 0.200107\n",
      "Train Epoch: 50 [300/798 (38%)]\tLoss: 0.359000\n",
      "Train Epoch: 50 [400/798 (50%)]\tLoss: 0.142661\n",
      "Train Epoch: 50 [500/798 (62%)]\tLoss: 0.003593\n",
      "Train Epoch: 50 [600/798 (75%)]\tLoss: 0.322527\n",
      "Train Epoch: 50 [700/798 (88%)]\tLoss: 0.199827\n",
      "\n",
      "Test set: Avg. loss: 0.0466, Accuracy: 198/200 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0466, Accuracy: 198/200 (99%)\n",
      "\n",
      "Running bootstrap experiment: 3\n",
      "Train Epoch: 1 [0/798 (0%)]\tLoss: 2.253135\n",
      "Train Epoch: 1 [100/798 (12%)]\tLoss: 2.309699\n",
      "Train Epoch: 1 [200/798 (25%)]\tLoss: 2.285411\n",
      "Train Epoch: 1 [300/798 (38%)]\tLoss: 2.301748\n",
      "Train Epoch: 1 [400/798 (50%)]\tLoss: 2.291392\n",
      "Train Epoch: 1 [500/798 (62%)]\tLoss: 2.355120\n",
      "Train Epoch: 1 [600/798 (75%)]\tLoss: 2.290066\n",
      "Train Epoch: 1 [700/798 (88%)]\tLoss: 2.316011\n",
      "\n",
      "Test set: Avg. loss: 2.2793, Accuracy: 39/200 (20%)\n",
      "\n",
      "Train Epoch: 2 [0/798 (0%)]\tLoss: 2.312804\n",
      "Train Epoch: 2 [100/798 (12%)]\tLoss: 2.330803\n",
      "Train Epoch: 2 [200/798 (25%)]\tLoss: 2.274218\n",
      "Train Epoch: 2 [300/798 (38%)]\tLoss: 2.233677\n",
      "Train Epoch: 2 [400/798 (50%)]\tLoss: 2.318713\n",
      "Train Epoch: 2 [500/798 (62%)]\tLoss: 2.340435\n",
      "Train Epoch: 2 [600/798 (75%)]\tLoss: 2.222377\n",
      "Train Epoch: 2 [700/798 (88%)]\tLoss: 2.307302\n",
      "\n",
      "Test set: Avg. loss: 2.2618, Accuracy: 47/200 (24%)\n",
      "\n",
      "Train Epoch: 3 [0/798 (0%)]\tLoss: 2.162288\n",
      "Train Epoch: 3 [100/798 (12%)]\tLoss: 2.271053\n",
      "Train Epoch: 3 [200/798 (25%)]\tLoss: 2.284222\n",
      "Train Epoch: 3 [300/798 (38%)]\tLoss: 2.248195\n",
      "Train Epoch: 3 [400/798 (50%)]\tLoss: 2.275743\n",
      "Train Epoch: 3 [500/798 (62%)]\tLoss: 2.340847\n",
      "Train Epoch: 3 [600/798 (75%)]\tLoss: 2.274555\n",
      "Train Epoch: 3 [700/798 (88%)]\tLoss: 2.088774\n",
      "\n",
      "Test set: Avg. loss: 2.1927, Accuracy: 58/200 (29%)\n",
      "\n",
      "Train Epoch: 4 [0/798 (0%)]\tLoss: 2.067019\n",
      "Train Epoch: 4 [100/798 (12%)]\tLoss: 2.089015\n",
      "Train Epoch: 4 [200/798 (25%)]\tLoss: 2.272882\n",
      "Train Epoch: 4 [300/798 (38%)]\tLoss: 2.158779\n",
      "Train Epoch: 4 [400/798 (50%)]\tLoss: 2.186603\n",
      "Train Epoch: 4 [500/798 (62%)]\tLoss: 2.094963\n",
      "Train Epoch: 4 [600/798 (75%)]\tLoss: 2.085455\n",
      "Train Epoch: 4 [700/798 (88%)]\tLoss: 2.253050\n",
      "\n",
      "Test set: Avg. loss: 2.0076, Accuracy: 61/200 (30%)\n",
      "\n",
      "Train Epoch: 5 [0/798 (0%)]\tLoss: 1.777846\n",
      "Train Epoch: 5 [100/798 (12%)]\tLoss: 2.326032\n",
      "Train Epoch: 5 [200/798 (25%)]\tLoss: 2.161601\n",
      "Train Epoch: 5 [300/798 (38%)]\tLoss: 1.979837\n",
      "Train Epoch: 5 [400/798 (50%)]\tLoss: 1.979702\n",
      "Train Epoch: 5 [500/798 (62%)]\tLoss: 2.171681\n",
      "Train Epoch: 5 [600/798 (75%)]\tLoss: 1.693869\n",
      "Train Epoch: 5 [700/798 (88%)]\tLoss: 2.181255\n",
      "\n",
      "Test set: Avg. loss: 1.8299, Accuracy: 77/200 (38%)\n",
      "\n",
      "Train Epoch: 6 [0/798 (0%)]\tLoss: 1.963102\n",
      "Train Epoch: 6 [100/798 (12%)]\tLoss: 2.006154\n",
      "Train Epoch: 6 [200/798 (25%)]\tLoss: 2.163033\n",
      "Train Epoch: 6 [300/798 (38%)]\tLoss: 1.878854\n",
      "Train Epoch: 6 [400/798 (50%)]\tLoss: 2.011900\n",
      "Train Epoch: 6 [500/798 (62%)]\tLoss: 2.007617\n",
      "Train Epoch: 6 [600/798 (75%)]\tLoss: 1.478630\n",
      "Train Epoch: 6 [700/798 (88%)]\tLoss: 1.995027\n",
      "\n",
      "Test set: Avg. loss: 1.5557, Accuracy: 80/200 (40%)\n",
      "\n",
      "Train Epoch: 7 [0/798 (0%)]\tLoss: 1.414885\n",
      "Train Epoch: 7 [100/798 (12%)]\tLoss: 2.007201\n",
      "Train Epoch: 7 [200/798 (25%)]\tLoss: 1.756666\n",
      "Train Epoch: 7 [300/798 (38%)]\tLoss: 1.337678\n",
      "Train Epoch: 7 [400/798 (50%)]\tLoss: 1.473332\n",
      "Train Epoch: 7 [500/798 (62%)]\tLoss: 1.921492\n",
      "Train Epoch: 7 [600/798 (75%)]\tLoss: 1.762616\n",
      "Train Epoch: 7 [700/798 (88%)]\tLoss: 1.494756\n",
      "\n",
      "Test set: Avg. loss: 1.4687, Accuracy: 103/200 (52%)\n",
      "\n",
      "Train Epoch: 8 [0/798 (0%)]\tLoss: 1.478597\n",
      "Train Epoch: 8 [100/798 (12%)]\tLoss: 1.143283\n",
      "Train Epoch: 8 [200/798 (25%)]\tLoss: 1.502952\n",
      "Train Epoch: 8 [300/798 (38%)]\tLoss: 1.656835\n",
      "Train Epoch: 8 [400/798 (50%)]\tLoss: 1.531747\n",
      "Train Epoch: 8 [500/798 (62%)]\tLoss: 1.517357\n",
      "Train Epoch: 8 [600/798 (75%)]\tLoss: 1.598922\n",
      "Train Epoch: 8 [700/798 (88%)]\tLoss: 1.084890\n",
      "\n",
      "Test set: Avg. loss: 1.1945, Accuracy: 143/200 (72%)\n",
      "\n",
      "Train Epoch: 9 [0/798 (0%)]\tLoss: 1.648040\n",
      "Train Epoch: 9 [100/798 (12%)]\tLoss: 1.119792\n",
      "Train Epoch: 9 [200/798 (25%)]\tLoss: 1.633430\n",
      "Train Epoch: 9 [300/798 (38%)]\tLoss: 1.175477\n",
      "Train Epoch: 9 [400/798 (50%)]\tLoss: 1.349589\n",
      "Train Epoch: 9 [500/798 (62%)]\tLoss: 1.276928\n",
      "Train Epoch: 9 [600/798 (75%)]\tLoss: 1.536042\n",
      "Train Epoch: 9 [700/798 (88%)]\tLoss: 1.527237\n",
      "\n",
      "Test set: Avg. loss: 0.9949, Accuracy: 155/200 (78%)\n",
      "\n",
      "Train Epoch: 10 [0/798 (0%)]\tLoss: 1.601538\n",
      "Train Epoch: 10 [100/798 (12%)]\tLoss: 0.865212\n",
      "Train Epoch: 10 [200/798 (25%)]\tLoss: 0.949776\n",
      "Train Epoch: 10 [300/798 (38%)]\tLoss: 1.298470\n",
      "Train Epoch: 10 [400/798 (50%)]\tLoss: 1.870103\n",
      "Train Epoch: 10 [500/798 (62%)]\tLoss: 1.483062\n",
      "Train Epoch: 10 [600/798 (75%)]\tLoss: 0.782055\n",
      "Train Epoch: 10 [700/798 (88%)]\tLoss: 1.651527\n",
      "\n",
      "Test set: Avg. loss: 0.8689, Accuracy: 164/200 (82%)\n",
      "\n",
      "Train Epoch: 11 [0/798 (0%)]\tLoss: 1.085328\n",
      "Train Epoch: 11 [100/798 (12%)]\tLoss: 0.934603\n",
      "Train Epoch: 11 [200/798 (25%)]\tLoss: 1.566714\n",
      "Train Epoch: 11 [300/798 (38%)]\tLoss: 1.187264\n",
      "Train Epoch: 11 [400/798 (50%)]\tLoss: 1.423836\n",
      "Train Epoch: 11 [500/798 (62%)]\tLoss: 1.174073\n",
      "Train Epoch: 11 [600/798 (75%)]\tLoss: 0.673942\n",
      "Train Epoch: 11 [700/798 (88%)]\tLoss: 1.161665\n",
      "\n",
      "Test set: Avg. loss: 0.6689, Accuracy: 173/200 (86%)\n",
      "\n",
      "Train Epoch: 12 [0/798 (0%)]\tLoss: 1.089774\n",
      "Train Epoch: 12 [100/798 (12%)]\tLoss: 1.083441\n",
      "Train Epoch: 12 [200/798 (25%)]\tLoss: 1.568836\n",
      "Train Epoch: 12 [300/798 (38%)]\tLoss: 1.632242\n",
      "Train Epoch: 12 [400/798 (50%)]\tLoss: 1.210532\n",
      "Train Epoch: 12 [500/798 (62%)]\tLoss: 1.255598\n",
      "Train Epoch: 12 [600/798 (75%)]\tLoss: 0.552984\n",
      "Train Epoch: 12 [700/798 (88%)]\tLoss: 1.180744\n",
      "\n",
      "Test set: Avg. loss: 0.7193, Accuracy: 158/200 (79%)\n",
      "\n",
      "Train Epoch: 13 [0/798 (0%)]\tLoss: 1.206320\n",
      "Train Epoch: 13 [100/798 (12%)]\tLoss: 0.986895\n",
      "Train Epoch: 13 [200/798 (25%)]\tLoss: 0.926583\n",
      "Train Epoch: 13 [300/798 (38%)]\tLoss: 0.647431\n",
      "Train Epoch: 13 [400/798 (50%)]\tLoss: 0.723182\n",
      "Train Epoch: 13 [500/798 (62%)]\tLoss: 1.144104\n",
      "Train Epoch: 13 [600/798 (75%)]\tLoss: 0.726473\n",
      "Train Epoch: 13 [700/798 (88%)]\tLoss: 0.716057\n",
      "\n",
      "Test set: Avg. loss: 0.4770, Accuracy: 190/200 (95%)\n",
      "\n",
      "Train Epoch: 14 [0/798 (0%)]\tLoss: 0.599336\n",
      "Train Epoch: 14 [100/798 (12%)]\tLoss: 0.979899\n",
      "Train Epoch: 14 [200/798 (25%)]\tLoss: 0.769621\n",
      "Train Epoch: 14 [300/798 (38%)]\tLoss: 0.609099\n",
      "Train Epoch: 14 [400/798 (50%)]\tLoss: 1.076770\n",
      "Train Epoch: 14 [500/798 (62%)]\tLoss: 1.112306\n",
      "Train Epoch: 14 [600/798 (75%)]\tLoss: 1.139933\n",
      "Train Epoch: 14 [700/798 (88%)]\tLoss: 0.778681\n",
      "\n",
      "Test set: Avg. loss: 0.3742, Accuracy: 189/200 (94%)\n",
      "\n",
      "Train Epoch: 15 [0/798 (0%)]\tLoss: 0.694540\n",
      "Train Epoch: 15 [100/798 (12%)]\tLoss: 1.075378\n",
      "Train Epoch: 15 [200/798 (25%)]\tLoss: 0.885703\n",
      "Train Epoch: 15 [300/798 (38%)]\tLoss: 1.198313\n",
      "Train Epoch: 15 [400/798 (50%)]\tLoss: 1.142935\n",
      "Train Epoch: 15 [500/798 (62%)]\tLoss: 0.428206\n",
      "Train Epoch: 15 [600/798 (75%)]\tLoss: 0.945228\n",
      "Train Epoch: 15 [700/798 (88%)]\tLoss: 1.026713\n",
      "\n",
      "Test set: Avg. loss: 0.2801, Accuracy: 193/200 (96%)\n",
      "\n",
      "Train Epoch: 16 [0/798 (0%)]\tLoss: 0.771119\n",
      "Train Epoch: 16 [100/798 (12%)]\tLoss: 0.774800\n",
      "Train Epoch: 16 [200/798 (25%)]\tLoss: 1.041125\n",
      "Train Epoch: 16 [300/798 (38%)]\tLoss: 0.479127\n",
      "Train Epoch: 16 [400/798 (50%)]\tLoss: 0.374727\n",
      "Train Epoch: 16 [500/798 (62%)]\tLoss: 0.532844\n",
      "Train Epoch: 16 [600/798 (75%)]\tLoss: 0.572438\n",
      "Train Epoch: 16 [700/798 (88%)]\tLoss: 0.566451\n",
      "\n",
      "Test set: Avg. loss: 0.2465, Accuracy: 191/200 (96%)\n",
      "\n",
      "Train Epoch: 17 [0/798 (0%)]\tLoss: 0.660889\n",
      "Train Epoch: 17 [100/798 (12%)]\tLoss: 0.759143\n",
      "Train Epoch: 17 [200/798 (25%)]\tLoss: 1.462939\n",
      "Train Epoch: 17 [300/798 (38%)]\tLoss: 0.523349\n",
      "Train Epoch: 17 [400/798 (50%)]\tLoss: 0.373049\n",
      "Train Epoch: 17 [500/798 (62%)]\tLoss: 0.793010\n",
      "Train Epoch: 17 [600/798 (75%)]\tLoss: 0.190821\n",
      "Train Epoch: 17 [700/798 (88%)]\tLoss: 1.329134\n",
      "\n",
      "Test set: Avg. loss: 0.2553, Accuracy: 193/200 (96%)\n",
      "\n",
      "Train Epoch: 18 [0/798 (0%)]\tLoss: 0.403675\n",
      "Train Epoch: 18 [100/798 (12%)]\tLoss: 0.544252\n",
      "Train Epoch: 18 [200/798 (25%)]\tLoss: 1.314761\n",
      "Train Epoch: 18 [300/798 (38%)]\tLoss: 0.514398\n",
      "Train Epoch: 18 [400/798 (50%)]\tLoss: 1.136443\n",
      "Train Epoch: 18 [500/798 (62%)]\tLoss: 0.693400\n",
      "Train Epoch: 18 [600/798 (75%)]\tLoss: 1.162904\n",
      "Train Epoch: 18 [700/798 (88%)]\tLoss: 0.438432\n",
      "\n",
      "Test set: Avg. loss: 0.2108, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 19 [0/798 (0%)]\tLoss: 1.084227\n",
      "Train Epoch: 19 [100/798 (12%)]\tLoss: 1.252645\n",
      "Train Epoch: 19 [200/798 (25%)]\tLoss: 0.922362\n",
      "Train Epoch: 19 [300/798 (38%)]\tLoss: 0.434055\n",
      "Train Epoch: 19 [400/798 (50%)]\tLoss: 0.482493\n",
      "Train Epoch: 19 [500/798 (62%)]\tLoss: 0.142674\n",
      "Train Epoch: 19 [600/798 (75%)]\tLoss: 1.085175\n",
      "Train Epoch: 19 [700/798 (88%)]\tLoss: 1.265458\n",
      "\n",
      "Test set: Avg. loss: 0.1591, Accuracy: 193/200 (96%)\n",
      "\n",
      "Train Epoch: 20 [0/798 (0%)]\tLoss: 0.341277\n",
      "Train Epoch: 20 [100/798 (12%)]\tLoss: 0.535109\n",
      "Train Epoch: 20 [200/798 (25%)]\tLoss: 0.540874\n",
      "Train Epoch: 20 [300/798 (38%)]\tLoss: 0.609031\n",
      "Train Epoch: 20 [400/798 (50%)]\tLoss: 0.238232\n",
      "Train Epoch: 20 [500/798 (62%)]\tLoss: 0.329053\n",
      "Train Epoch: 20 [600/798 (75%)]\tLoss: 0.375770\n",
      "Train Epoch: 20 [700/798 (88%)]\tLoss: 0.483692\n",
      "\n",
      "Test set: Avg. loss: 0.1325, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/798 (0%)]\tLoss: 0.646769\n",
      "Train Epoch: 21 [100/798 (12%)]\tLoss: 0.553977\n",
      "Train Epoch: 21 [200/798 (25%)]\tLoss: 1.253987\n",
      "Train Epoch: 21 [300/798 (38%)]\tLoss: 0.825487\n",
      "Train Epoch: 21 [400/798 (50%)]\tLoss: 0.606921\n",
      "Train Epoch: 21 [500/798 (62%)]\tLoss: 0.469029\n",
      "Train Epoch: 21 [600/798 (75%)]\tLoss: 0.664727\n",
      "Train Epoch: 21 [700/798 (88%)]\tLoss: 0.327048\n",
      "\n",
      "Test set: Avg. loss: 0.1138, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/798 (0%)]\tLoss: 0.208567\n",
      "Train Epoch: 22 [100/798 (12%)]\tLoss: 0.416313\n",
      "Train Epoch: 22 [200/798 (25%)]\tLoss: 0.389122\n",
      "Train Epoch: 22 [300/798 (38%)]\tLoss: 0.685832\n",
      "Train Epoch: 22 [400/798 (50%)]\tLoss: 0.713640\n",
      "Train Epoch: 22 [500/798 (62%)]\tLoss: 0.866223\n",
      "Train Epoch: 22 [600/798 (75%)]\tLoss: 0.404780\n",
      "Train Epoch: 22 [700/798 (88%)]\tLoss: 0.581305\n",
      "\n",
      "Test set: Avg. loss: 0.1234, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/798 (0%)]\tLoss: 0.144770\n",
      "Train Epoch: 23 [100/798 (12%)]\tLoss: 0.036669\n",
      "Train Epoch: 23 [200/798 (25%)]\tLoss: 0.958908\n",
      "Train Epoch: 23 [300/798 (38%)]\tLoss: 0.363828\n",
      "Train Epoch: 23 [400/798 (50%)]\tLoss: 0.305778\n",
      "Train Epoch: 23 [500/798 (62%)]\tLoss: 0.500725\n",
      "Train Epoch: 23 [600/798 (75%)]\tLoss: 0.818248\n",
      "Train Epoch: 23 [700/798 (88%)]\tLoss: 0.449057\n",
      "\n",
      "Test set: Avg. loss: 0.1053, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/798 (0%)]\tLoss: 0.150079\n",
      "Train Epoch: 24 [100/798 (12%)]\tLoss: 0.079432\n",
      "Train Epoch: 24 [200/798 (25%)]\tLoss: 0.698665\n",
      "Train Epoch: 24 [300/798 (38%)]\tLoss: 0.302142\n",
      "Train Epoch: 24 [400/798 (50%)]\tLoss: 0.064853\n",
      "Train Epoch: 24 [500/798 (62%)]\tLoss: 0.347289\n",
      "Train Epoch: 24 [600/798 (75%)]\tLoss: 0.332066\n",
      "Train Epoch: 24 [700/798 (88%)]\tLoss: 0.864155\n",
      "\n",
      "Test set: Avg. loss: 0.1215, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/798 (0%)]\tLoss: 0.370903\n",
      "Train Epoch: 25 [100/798 (12%)]\tLoss: 0.849076\n",
      "Train Epoch: 25 [200/798 (25%)]\tLoss: 0.282253\n",
      "Train Epoch: 25 [300/798 (38%)]\tLoss: 0.489729\n",
      "Train Epoch: 25 [400/798 (50%)]\tLoss: 0.521734\n",
      "Train Epoch: 25 [500/798 (62%)]\tLoss: 0.186490\n",
      "Train Epoch: 25 [600/798 (75%)]\tLoss: 0.184170\n",
      "Train Epoch: 25 [700/798 (88%)]\tLoss: 0.111345\n",
      "\n",
      "Test set: Avg. loss: 0.1108, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/798 (0%)]\tLoss: 0.322415\n",
      "Train Epoch: 26 [100/798 (12%)]\tLoss: 0.764074\n",
      "Train Epoch: 26 [200/798 (25%)]\tLoss: 0.073980\n",
      "Train Epoch: 26 [300/798 (38%)]\tLoss: 0.402387\n",
      "Train Epoch: 26 [400/798 (50%)]\tLoss: 0.078336\n",
      "Train Epoch: 26 [500/798 (62%)]\tLoss: 0.582776\n",
      "Train Epoch: 26 [600/798 (75%)]\tLoss: 0.133947\n",
      "Train Epoch: 26 [700/798 (88%)]\tLoss: 0.196372\n",
      "\n",
      "Test set: Avg. loss: 0.1627, Accuracy: 189/200 (94%)\n",
      "\n",
      "Train Epoch: 27 [0/798 (0%)]\tLoss: 0.162735\n",
      "Train Epoch: 27 [100/798 (12%)]\tLoss: 0.292643\n",
      "Train Epoch: 27 [200/798 (25%)]\tLoss: 0.282040\n",
      "Train Epoch: 27 [300/798 (38%)]\tLoss: 0.195120\n",
      "Train Epoch: 27 [400/798 (50%)]\tLoss: 0.356516\n",
      "Train Epoch: 27 [500/798 (62%)]\tLoss: 0.310408\n",
      "Train Epoch: 27 [600/798 (75%)]\tLoss: 0.384182\n",
      "Train Epoch: 27 [700/798 (88%)]\tLoss: 0.343525\n",
      "\n",
      "Test set: Avg. loss: 0.1182, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/798 (0%)]\tLoss: 0.790015\n",
      "Train Epoch: 28 [100/798 (12%)]\tLoss: 0.269437\n",
      "Train Epoch: 28 [200/798 (25%)]\tLoss: 0.909997\n",
      "Train Epoch: 28 [300/798 (38%)]\tLoss: 0.414195\n",
      "Train Epoch: 28 [400/798 (50%)]\tLoss: 0.159349\n",
      "Train Epoch: 28 [500/798 (62%)]\tLoss: 0.114288\n",
      "Train Epoch: 28 [600/798 (75%)]\tLoss: 0.961981\n",
      "Train Epoch: 28 [700/798 (88%)]\tLoss: 0.317854\n",
      "\n",
      "Test set: Avg. loss: 0.0807, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 29 [0/798 (0%)]\tLoss: 0.164586\n",
      "Train Epoch: 29 [100/798 (12%)]\tLoss: 0.455963\n",
      "Train Epoch: 29 [200/798 (25%)]\tLoss: 0.527146\n",
      "Train Epoch: 29 [300/798 (38%)]\tLoss: 0.646976\n",
      "Train Epoch: 29 [400/798 (50%)]\tLoss: 0.312950\n",
      "Train Epoch: 29 [500/798 (62%)]\tLoss: 0.333314\n",
      "Train Epoch: 29 [600/798 (75%)]\tLoss: 0.706505\n",
      "Train Epoch: 29 [700/798 (88%)]\tLoss: 0.214947\n",
      "\n",
      "Test set: Avg. loss: 0.0746, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 30 [0/798 (0%)]\tLoss: 0.025117\n",
      "Train Epoch: 30 [100/798 (12%)]\tLoss: 0.610117\n",
      "Train Epoch: 30 [200/798 (25%)]\tLoss: 0.252241\n",
      "Train Epoch: 30 [300/798 (38%)]\tLoss: 0.151909\n",
      "Train Epoch: 30 [400/798 (50%)]\tLoss: 0.195687\n",
      "Train Epoch: 30 [500/798 (62%)]\tLoss: 0.293253\n",
      "Train Epoch: 30 [600/798 (75%)]\tLoss: 0.475849\n",
      "Train Epoch: 30 [700/798 (88%)]\tLoss: 0.257783\n",
      "\n",
      "Test set: Avg. loss: 0.0867, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/798 (0%)]\tLoss: 0.086746\n",
      "Train Epoch: 31 [100/798 (12%)]\tLoss: 0.020193\n",
      "Train Epoch: 31 [200/798 (25%)]\tLoss: 0.464548\n",
      "Train Epoch: 31 [300/798 (38%)]\tLoss: 0.241037\n",
      "Train Epoch: 31 [400/798 (50%)]\tLoss: 0.278605\n",
      "Train Epoch: 31 [500/798 (62%)]\tLoss: 0.223387\n",
      "Train Epoch: 31 [600/798 (75%)]\tLoss: 0.037373\n",
      "Train Epoch: 31 [700/798 (88%)]\tLoss: 0.291974\n",
      "\n",
      "Test set: Avg. loss: 0.0592, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 32 [0/798 (0%)]\tLoss: 0.442572\n",
      "Train Epoch: 32 [100/798 (12%)]\tLoss: 0.127156\n",
      "Train Epoch: 32 [200/798 (25%)]\tLoss: 0.276605\n",
      "Train Epoch: 32 [300/798 (38%)]\tLoss: 0.232027\n",
      "Train Epoch: 32 [400/798 (50%)]\tLoss: 0.218283\n",
      "Train Epoch: 32 [500/798 (62%)]\tLoss: 0.112077\n",
      "Train Epoch: 32 [600/798 (75%)]\tLoss: 0.156823\n",
      "Train Epoch: 32 [700/798 (88%)]\tLoss: 0.034121\n",
      "\n",
      "Test set: Avg. loss: 0.1080, Accuracy: 193/200 (96%)\n",
      "\n",
      "Train Epoch: 33 [0/798 (0%)]\tLoss: 0.465076\n",
      "Train Epoch: 33 [100/798 (12%)]\tLoss: 0.665208\n",
      "Train Epoch: 33 [200/798 (25%)]\tLoss: 0.483225\n",
      "Train Epoch: 33 [300/798 (38%)]\tLoss: 0.246322\n",
      "Train Epoch: 33 [400/798 (50%)]\tLoss: 0.467022\n",
      "Train Epoch: 33 [500/798 (62%)]\tLoss: 0.543035\n",
      "Train Epoch: 33 [600/798 (75%)]\tLoss: 0.262348\n",
      "Train Epoch: 33 [700/798 (88%)]\tLoss: 0.101938\n",
      "\n",
      "Test set: Avg. loss: 0.0667, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/798 (0%)]\tLoss: 0.474270\n",
      "Train Epoch: 34 [100/798 (12%)]\tLoss: 0.709232\n",
      "Train Epoch: 34 [200/798 (25%)]\tLoss: 0.363470\n",
      "Train Epoch: 34 [300/798 (38%)]\tLoss: 0.235122\n",
      "Train Epoch: 34 [400/798 (50%)]\tLoss: 0.245296\n",
      "Train Epoch: 34 [500/798 (62%)]\tLoss: 0.268632\n",
      "Train Epoch: 34 [600/798 (75%)]\tLoss: 0.074668\n",
      "Train Epoch: 34 [700/798 (88%)]\tLoss: 0.203533\n",
      "\n",
      "Test set: Avg. loss: 0.0933, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 35 [0/798 (0%)]\tLoss: 0.208778\n",
      "Train Epoch: 35 [100/798 (12%)]\tLoss: 0.310638\n",
      "Train Epoch: 35 [200/798 (25%)]\tLoss: 0.208442\n",
      "Train Epoch: 35 [300/798 (38%)]\tLoss: 0.608196\n",
      "Train Epoch: 35 [400/798 (50%)]\tLoss: 0.344533\n",
      "Train Epoch: 35 [500/798 (62%)]\tLoss: 0.030882\n",
      "Train Epoch: 35 [600/798 (75%)]\tLoss: 0.161935\n",
      "Train Epoch: 35 [700/798 (88%)]\tLoss: 0.580101\n",
      "\n",
      "Test set: Avg. loss: 0.0994, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 36 [0/798 (0%)]\tLoss: 0.284224\n",
      "Train Epoch: 36 [100/798 (12%)]\tLoss: 0.298833\n",
      "Train Epoch: 36 [200/798 (25%)]\tLoss: 0.239935\n",
      "Train Epoch: 36 [300/798 (38%)]\tLoss: 0.295069\n",
      "Train Epoch: 36 [400/798 (50%)]\tLoss: 0.135487\n",
      "Train Epoch: 36 [500/798 (62%)]\tLoss: 0.491032\n",
      "Train Epoch: 36 [600/798 (75%)]\tLoss: 0.419417\n",
      "Train Epoch: 36 [700/798 (88%)]\tLoss: 0.165055\n",
      "\n",
      "Test set: Avg. loss: 0.0554, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 37 [0/798 (0%)]\tLoss: 0.323969\n",
      "Train Epoch: 37 [100/798 (12%)]\tLoss: 1.049877\n",
      "Train Epoch: 37 [200/798 (25%)]\tLoss: 0.114615\n",
      "Train Epoch: 37 [300/798 (38%)]\tLoss: 0.351886\n",
      "Train Epoch: 37 [400/798 (50%)]\tLoss: 0.451068\n",
      "Train Epoch: 37 [500/798 (62%)]\tLoss: 0.072112\n",
      "Train Epoch: 37 [600/798 (75%)]\tLoss: 1.234758\n",
      "Train Epoch: 37 [700/798 (88%)]\tLoss: 0.647643\n",
      "\n",
      "Test set: Avg. loss: 0.0550, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 38 [0/798 (0%)]\tLoss: 0.260222\n",
      "Train Epoch: 38 [100/798 (12%)]\tLoss: 0.024121\n",
      "Train Epoch: 38 [200/798 (25%)]\tLoss: 0.260479\n",
      "Train Epoch: 38 [300/798 (38%)]\tLoss: 0.833359\n",
      "Train Epoch: 38 [400/798 (50%)]\tLoss: 0.028562\n",
      "Train Epoch: 38 [500/798 (62%)]\tLoss: 0.125592\n",
      "Train Epoch: 38 [600/798 (75%)]\tLoss: 0.193872\n",
      "Train Epoch: 38 [700/798 (88%)]\tLoss: 0.274909\n",
      "\n",
      "Test set: Avg. loss: 0.0488, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 39 [0/798 (0%)]\tLoss: 0.017076\n",
      "Train Epoch: 39 [100/798 (12%)]\tLoss: 0.398209\n",
      "Train Epoch: 39 [200/798 (25%)]\tLoss: 0.782248\n",
      "Train Epoch: 39 [300/798 (38%)]\tLoss: 0.381632\n",
      "Train Epoch: 39 [400/798 (50%)]\tLoss: 0.075757\n",
      "Train Epoch: 39 [500/798 (62%)]\tLoss: 0.475318\n",
      "Train Epoch: 39 [600/798 (75%)]\tLoss: 0.487704\n",
      "Train Epoch: 39 [700/798 (88%)]\tLoss: 0.181372\n",
      "\n",
      "Test set: Avg. loss: 0.0620, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 40 [0/798 (0%)]\tLoss: 0.183496\n",
      "Train Epoch: 40 [100/798 (12%)]\tLoss: 0.409107\n",
      "Train Epoch: 40 [200/798 (25%)]\tLoss: 0.158534\n",
      "Train Epoch: 40 [300/798 (38%)]\tLoss: 0.040998\n",
      "Train Epoch: 40 [400/798 (50%)]\tLoss: 0.126672\n",
      "Train Epoch: 40 [500/798 (62%)]\tLoss: 0.817666\n",
      "Train Epoch: 40 [600/798 (75%)]\tLoss: 0.642590\n",
      "Train Epoch: 40 [700/798 (88%)]\tLoss: 0.143537\n",
      "\n",
      "Test set: Avg. loss: 0.0746, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 41 [0/798 (0%)]\tLoss: 0.051466\n",
      "Train Epoch: 41 [100/798 (12%)]\tLoss: 0.231085\n",
      "Train Epoch: 41 [200/798 (25%)]\tLoss: 0.245501\n",
      "Train Epoch: 41 [300/798 (38%)]\tLoss: 0.445737\n",
      "Train Epoch: 41 [400/798 (50%)]\tLoss: 0.268055\n",
      "Train Epoch: 41 [500/798 (62%)]\tLoss: 0.154206\n",
      "Train Epoch: 41 [600/798 (75%)]\tLoss: 0.457564\n",
      "Train Epoch: 41 [700/798 (88%)]\tLoss: 0.133528\n",
      "\n",
      "Test set: Avg. loss: 0.0508, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 42 [0/798 (0%)]\tLoss: 0.265478\n",
      "Train Epoch: 42 [100/798 (12%)]\tLoss: 0.218431\n",
      "Train Epoch: 42 [200/798 (25%)]\tLoss: 0.273863\n",
      "Train Epoch: 42 [300/798 (38%)]\tLoss: 0.090588\n",
      "Train Epoch: 42 [400/798 (50%)]\tLoss: 0.031547\n",
      "Train Epoch: 42 [500/798 (62%)]\tLoss: 0.472056\n",
      "Train Epoch: 42 [600/798 (75%)]\tLoss: 0.055792\n",
      "Train Epoch: 42 [700/798 (88%)]\tLoss: 0.066826\n",
      "\n",
      "Test set: Avg. loss: 0.0490, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 43 [0/798 (0%)]\tLoss: 0.201976\n",
      "Train Epoch: 43 [100/798 (12%)]\tLoss: 0.139840\n",
      "Train Epoch: 43 [200/798 (25%)]\tLoss: 0.424707\n",
      "Train Epoch: 43 [300/798 (38%)]\tLoss: 0.225474\n",
      "Train Epoch: 43 [400/798 (50%)]\tLoss: 0.078110\n",
      "Train Epoch: 43 [500/798 (62%)]\tLoss: 0.091895\n",
      "Train Epoch: 43 [600/798 (75%)]\tLoss: 0.443875\n",
      "Train Epoch: 43 [700/798 (88%)]\tLoss: 0.498000\n",
      "\n",
      "Test set: Avg. loss: 0.0419, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 44 [0/798 (0%)]\tLoss: 0.067974\n",
      "Train Epoch: 44 [100/798 (12%)]\tLoss: 0.182802\n",
      "Train Epoch: 44 [200/798 (25%)]\tLoss: 0.017440\n",
      "Train Epoch: 44 [300/798 (38%)]\tLoss: 0.213679\n",
      "Train Epoch: 44 [400/798 (50%)]\tLoss: 0.157633\n",
      "Train Epoch: 44 [500/798 (62%)]\tLoss: 0.185048\n",
      "Train Epoch: 44 [600/798 (75%)]\tLoss: 0.446643\n",
      "Train Epoch: 44 [700/798 (88%)]\tLoss: 0.072558\n",
      "\n",
      "Test set: Avg. loss: 0.0477, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 45 [0/798 (0%)]\tLoss: 0.217228\n",
      "Train Epoch: 45 [100/798 (12%)]\tLoss: 0.541975\n",
      "Train Epoch: 45 [200/798 (25%)]\tLoss: 0.395462\n",
      "Train Epoch: 45 [300/798 (38%)]\tLoss: 0.137845\n",
      "Train Epoch: 45 [400/798 (50%)]\tLoss: 0.008328\n",
      "Train Epoch: 45 [500/798 (62%)]\tLoss: 0.050921\n",
      "Train Epoch: 45 [600/798 (75%)]\tLoss: 0.252586\n",
      "Train Epoch: 45 [700/798 (88%)]\tLoss: 0.146855\n",
      "\n",
      "Test set: Avg. loss: 0.0545, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 46 [0/798 (0%)]\tLoss: 0.287308\n",
      "Train Epoch: 46 [100/798 (12%)]\tLoss: 0.042357\n",
      "Train Epoch: 46 [200/798 (25%)]\tLoss: 0.697968\n",
      "Train Epoch: 46 [300/798 (38%)]\tLoss: 0.590801\n",
      "Train Epoch: 46 [400/798 (50%)]\tLoss: 0.230273\n",
      "Train Epoch: 46 [500/798 (62%)]\tLoss: 0.375991\n",
      "Train Epoch: 46 [600/798 (75%)]\tLoss: 0.672586\n",
      "Train Epoch: 46 [700/798 (88%)]\tLoss: 0.238876\n",
      "\n",
      "Test set: Avg. loss: 0.0574, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 47 [0/798 (0%)]\tLoss: 0.103509\n",
      "Train Epoch: 47 [100/798 (12%)]\tLoss: 0.431135\n",
      "Train Epoch: 47 [200/798 (25%)]\tLoss: 0.262582\n",
      "Train Epoch: 47 [300/798 (38%)]\tLoss: 0.002754\n",
      "Train Epoch: 47 [400/798 (50%)]\tLoss: 0.032903\n",
      "Train Epoch: 47 [500/798 (62%)]\tLoss: 0.521313\n",
      "Train Epoch: 47 [600/798 (75%)]\tLoss: 0.480214\n",
      "Train Epoch: 47 [700/798 (88%)]\tLoss: 0.062798\n",
      "\n",
      "Test set: Avg. loss: 0.0434, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 48 [0/798 (0%)]\tLoss: 0.167388\n",
      "Train Epoch: 48 [100/798 (12%)]\tLoss: 0.235438\n",
      "Train Epoch: 48 [200/798 (25%)]\tLoss: 0.344013\n",
      "Train Epoch: 48 [300/798 (38%)]\tLoss: 0.354649\n",
      "Train Epoch: 48 [400/798 (50%)]\tLoss: 0.125481\n",
      "Train Epoch: 48 [500/798 (62%)]\tLoss: 0.442609\n",
      "Train Epoch: 48 [600/798 (75%)]\tLoss: 0.267416\n",
      "Train Epoch: 48 [700/798 (88%)]\tLoss: 0.025404\n",
      "\n",
      "Test set: Avg. loss: 0.0458, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 49 [0/798 (0%)]\tLoss: 0.166394\n",
      "Train Epoch: 49 [100/798 (12%)]\tLoss: 0.151480\n",
      "Train Epoch: 49 [200/798 (25%)]\tLoss: 0.000848\n",
      "Train Epoch: 49 [300/798 (38%)]\tLoss: 0.060326\n",
      "Train Epoch: 49 [400/798 (50%)]\tLoss: 0.120242\n",
      "Train Epoch: 49 [500/798 (62%)]\tLoss: 0.678931\n",
      "Train Epoch: 49 [600/798 (75%)]\tLoss: 0.077438\n",
      "Train Epoch: 49 [700/798 (88%)]\tLoss: 0.048806\n",
      "\n",
      "Test set: Avg. loss: 0.0431, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 50 [0/798 (0%)]\tLoss: 0.582211\n",
      "Train Epoch: 50 [100/798 (12%)]\tLoss: 0.111287\n",
      "Train Epoch: 50 [200/798 (25%)]\tLoss: 0.809656\n",
      "Train Epoch: 50 [300/798 (38%)]\tLoss: 0.243027\n",
      "Train Epoch: 50 [400/798 (50%)]\tLoss: 0.096822\n",
      "Train Epoch: 50 [500/798 (62%)]\tLoss: 0.119839\n",
      "Train Epoch: 50 [600/798 (75%)]\tLoss: 0.726226\n",
      "Train Epoch: 50 [700/798 (88%)]\tLoss: 0.047916\n",
      "\n",
      "Test set: Avg. loss: 0.0449, Accuracy: 198/200 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0449, Accuracy: 198/200 (99%)\n",
      "\n",
      "Running bootstrap experiment: 4\n",
      "Train Epoch: 1 [0/798 (0%)]\tLoss: 2.370861\n",
      "Train Epoch: 1 [100/798 (12%)]\tLoss: 2.292091\n",
      "Train Epoch: 1 [200/798 (25%)]\tLoss: 2.273451\n",
      "Train Epoch: 1 [300/798 (38%)]\tLoss: 2.316679\n",
      "Train Epoch: 1 [400/798 (50%)]\tLoss: 2.282995\n",
      "Train Epoch: 1 [500/798 (62%)]\tLoss: 2.358725\n",
      "Train Epoch: 1 [600/798 (75%)]\tLoss: 2.327280\n",
      "Train Epoch: 1 [700/798 (88%)]\tLoss: 2.370220\n",
      "\n",
      "Test set: Avg. loss: 2.2963, Accuracy: 32/200 (16%)\n",
      "\n",
      "Train Epoch: 2 [0/798 (0%)]\tLoss: 2.304507\n",
      "Train Epoch: 2 [100/798 (12%)]\tLoss: 2.334026\n",
      "Train Epoch: 2 [200/798 (25%)]\tLoss: 2.319467\n",
      "Train Epoch: 2 [300/798 (38%)]\tLoss: 2.261974\n",
      "Train Epoch: 2 [400/798 (50%)]\tLoss: 2.305385\n",
      "Train Epoch: 2 [500/798 (62%)]\tLoss: 2.312017\n",
      "Train Epoch: 2 [600/798 (75%)]\tLoss: 2.276752\n",
      "Train Epoch: 2 [700/798 (88%)]\tLoss: 2.311055\n",
      "\n",
      "Test set: Avg. loss: 2.2636, Accuracy: 46/200 (23%)\n",
      "\n",
      "Train Epoch: 3 [0/798 (0%)]\tLoss: 2.286606\n",
      "Train Epoch: 3 [100/798 (12%)]\tLoss: 2.265797\n",
      "Train Epoch: 3 [200/798 (25%)]\tLoss: 2.326163\n",
      "Train Epoch: 3 [300/798 (38%)]\tLoss: 2.318512\n",
      "Train Epoch: 3 [400/798 (50%)]\tLoss: 2.233391\n",
      "Train Epoch: 3 [500/798 (62%)]\tLoss: 2.300197\n",
      "Train Epoch: 3 [600/798 (75%)]\tLoss: 2.210338\n",
      "Train Epoch: 3 [700/798 (88%)]\tLoss: 2.298306\n",
      "\n",
      "Test set: Avg. loss: 2.2121, Accuracy: 38/200 (19%)\n",
      "\n",
      "Train Epoch: 4 [0/798 (0%)]\tLoss: 2.039052\n",
      "Train Epoch: 4 [100/798 (12%)]\tLoss: 2.130708\n",
      "Train Epoch: 4 [200/798 (25%)]\tLoss: 2.172338\n",
      "Train Epoch: 4 [300/798 (38%)]\tLoss: 2.264278\n",
      "Train Epoch: 4 [400/798 (50%)]\tLoss: 2.055084\n",
      "Train Epoch: 4 [500/798 (62%)]\tLoss: 2.163430\n",
      "Train Epoch: 4 [600/798 (75%)]\tLoss: 2.205610\n",
      "Train Epoch: 4 [700/798 (88%)]\tLoss: 2.355860\n",
      "\n",
      "Test set: Avg. loss: 2.0455, Accuracy: 107/200 (54%)\n",
      "\n",
      "Train Epoch: 5 [0/798 (0%)]\tLoss: 2.185633\n",
      "Train Epoch: 5 [100/798 (12%)]\tLoss: 2.067438\n",
      "Train Epoch: 5 [200/798 (25%)]\tLoss: 1.880341\n",
      "Train Epoch: 5 [300/798 (38%)]\tLoss: 2.092335\n",
      "Train Epoch: 5 [400/798 (50%)]\tLoss: 2.020703\n",
      "Train Epoch: 5 [500/798 (62%)]\tLoss: 1.943790\n",
      "Train Epoch: 5 [600/798 (75%)]\tLoss: 1.990318\n",
      "Train Epoch: 5 [700/798 (88%)]\tLoss: 1.634276\n",
      "\n",
      "Test set: Avg. loss: 1.6813, Accuracy: 104/200 (52%)\n",
      "\n",
      "Train Epoch: 6 [0/798 (0%)]\tLoss: 1.784863\n",
      "Train Epoch: 6 [100/798 (12%)]\tLoss: 1.766636\n",
      "Train Epoch: 6 [200/798 (25%)]\tLoss: 1.839435\n",
      "Train Epoch: 6 [300/798 (38%)]\tLoss: 1.852596\n",
      "Train Epoch: 6 [400/798 (50%)]\tLoss: 1.797681\n",
      "Train Epoch: 6 [500/798 (62%)]\tLoss: 1.225805\n",
      "Train Epoch: 6 [600/798 (75%)]\tLoss: 1.550214\n",
      "Train Epoch: 6 [700/798 (88%)]\tLoss: 1.161121\n",
      "\n",
      "Test set: Avg. loss: 1.3029, Accuracy: 151/200 (76%)\n",
      "\n",
      "Train Epoch: 7 [0/798 (0%)]\tLoss: 1.642264\n",
      "Train Epoch: 7 [100/798 (12%)]\tLoss: 1.367832\n",
      "Train Epoch: 7 [200/798 (25%)]\tLoss: 1.804448\n",
      "Train Epoch: 7 [300/798 (38%)]\tLoss: 1.471950\n",
      "Train Epoch: 7 [400/798 (50%)]\tLoss: 1.721736\n",
      "Train Epoch: 7 [500/798 (62%)]\tLoss: 1.242909\n",
      "Train Epoch: 7 [600/798 (75%)]\tLoss: 1.457087\n",
      "Train Epoch: 7 [700/798 (88%)]\tLoss: 1.426045\n",
      "\n",
      "Test set: Avg. loss: 0.9271, Accuracy: 172/200 (86%)\n",
      "\n",
      "Train Epoch: 8 [0/798 (0%)]\tLoss: 0.821524\n",
      "Train Epoch: 8 [100/798 (12%)]\tLoss: 1.121058\n",
      "Train Epoch: 8 [200/798 (25%)]\tLoss: 0.975235\n",
      "Train Epoch: 8 [300/798 (38%)]\tLoss: 1.240196\n",
      "Train Epoch: 8 [400/798 (50%)]\tLoss: 1.543226\n",
      "Train Epoch: 8 [500/798 (62%)]\tLoss: 1.092126\n",
      "Train Epoch: 8 [600/798 (75%)]\tLoss: 1.102823\n",
      "Train Epoch: 8 [700/798 (88%)]\tLoss: 1.563985\n",
      "\n",
      "Test set: Avg. loss: 0.7261, Accuracy: 173/200 (86%)\n",
      "\n",
      "Train Epoch: 9 [0/798 (0%)]\tLoss: 1.465170\n",
      "Train Epoch: 9 [100/798 (12%)]\tLoss: 1.359929\n",
      "Train Epoch: 9 [200/798 (25%)]\tLoss: 0.721593\n",
      "Train Epoch: 9 [300/798 (38%)]\tLoss: 0.662531\n",
      "Train Epoch: 9 [400/798 (50%)]\tLoss: 1.022994\n",
      "Train Epoch: 9 [500/798 (62%)]\tLoss: 0.748426\n",
      "Train Epoch: 9 [600/798 (75%)]\tLoss: 1.258892\n",
      "Train Epoch: 9 [700/798 (88%)]\tLoss: 1.604730\n",
      "\n",
      "Test set: Avg. loss: 0.6229, Accuracy: 170/200 (85%)\n",
      "\n",
      "Train Epoch: 10 [0/798 (0%)]\tLoss: 0.864516\n",
      "Train Epoch: 10 [100/798 (12%)]\tLoss: 0.690158\n",
      "Train Epoch: 10 [200/798 (25%)]\tLoss: 0.752861\n",
      "Train Epoch: 10 [300/798 (38%)]\tLoss: 1.258121\n",
      "Train Epoch: 10 [400/798 (50%)]\tLoss: 0.807065\n",
      "Train Epoch: 10 [500/798 (62%)]\tLoss: 0.837982\n",
      "Train Epoch: 10 [600/798 (75%)]\tLoss: 0.942509\n",
      "Train Epoch: 10 [700/798 (88%)]\tLoss: 0.824107\n",
      "\n",
      "Test set: Avg. loss: 0.4426, Accuracy: 177/200 (88%)\n",
      "\n",
      "Train Epoch: 11 [0/798 (0%)]\tLoss: 0.852160\n",
      "Train Epoch: 11 [100/798 (12%)]\tLoss: 1.378303\n",
      "Train Epoch: 11 [200/798 (25%)]\tLoss: 0.943130\n",
      "Train Epoch: 11 [300/798 (38%)]\tLoss: 1.070350\n",
      "Train Epoch: 11 [400/798 (50%)]\tLoss: 0.630355\n",
      "Train Epoch: 11 [500/798 (62%)]\tLoss: 0.462145\n",
      "Train Epoch: 11 [600/798 (75%)]\tLoss: 0.844702\n",
      "Train Epoch: 11 [700/798 (88%)]\tLoss: 0.697236\n",
      "\n",
      "Test set: Avg. loss: 0.3964, Accuracy: 176/200 (88%)\n",
      "\n",
      "Train Epoch: 12 [0/798 (0%)]\tLoss: 0.740252\n",
      "Train Epoch: 12 [100/798 (12%)]\tLoss: 1.117797\n",
      "Train Epoch: 12 [200/798 (25%)]\tLoss: 0.787185\n",
      "Train Epoch: 12 [300/798 (38%)]\tLoss: 1.013102\n",
      "Train Epoch: 12 [400/798 (50%)]\tLoss: 0.645954\n",
      "Train Epoch: 12 [500/798 (62%)]\tLoss: 0.309573\n",
      "Train Epoch: 12 [600/798 (75%)]\tLoss: 0.976128\n",
      "Train Epoch: 12 [700/798 (88%)]\tLoss: 0.853219\n",
      "\n",
      "Test set: Avg. loss: 0.3544, Accuracy: 191/200 (96%)\n",
      "\n",
      "Train Epoch: 13 [0/798 (0%)]\tLoss: 0.653272\n",
      "Train Epoch: 13 [100/798 (12%)]\tLoss: 0.661383\n",
      "Train Epoch: 13 [200/798 (25%)]\tLoss: 0.902338\n",
      "Train Epoch: 13 [300/798 (38%)]\tLoss: 0.765855\n",
      "Train Epoch: 13 [400/798 (50%)]\tLoss: 1.242189\n",
      "Train Epoch: 13 [500/798 (62%)]\tLoss: 0.912175\n",
      "Train Epoch: 13 [600/798 (75%)]\tLoss: 1.047594\n",
      "Train Epoch: 13 [700/798 (88%)]\tLoss: 0.453106\n",
      "\n",
      "Test set: Avg. loss: 0.2396, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/798 (0%)]\tLoss: 0.480392\n",
      "Train Epoch: 14 [100/798 (12%)]\tLoss: 0.342156\n",
      "Train Epoch: 14 [200/798 (25%)]\tLoss: 0.682125\n",
      "Train Epoch: 14 [300/798 (38%)]\tLoss: 0.655743\n",
      "Train Epoch: 14 [400/798 (50%)]\tLoss: 0.405849\n",
      "Train Epoch: 14 [500/798 (62%)]\tLoss: 0.506957\n",
      "Train Epoch: 14 [600/798 (75%)]\tLoss: 0.253210\n",
      "Train Epoch: 14 [700/798 (88%)]\tLoss: 1.058985\n",
      "\n",
      "Test set: Avg. loss: 0.2138, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/798 (0%)]\tLoss: 0.891253\n",
      "Train Epoch: 15 [100/798 (12%)]\tLoss: 0.610319\n",
      "Train Epoch: 15 [200/798 (25%)]\tLoss: 0.677682\n",
      "Train Epoch: 15 [300/798 (38%)]\tLoss: 0.769566\n",
      "Train Epoch: 15 [400/798 (50%)]\tLoss: 0.421284\n",
      "Train Epoch: 15 [500/798 (62%)]\tLoss: 0.394555\n",
      "Train Epoch: 15 [600/798 (75%)]\tLoss: 0.443666\n",
      "Train Epoch: 15 [700/798 (88%)]\tLoss: 1.268447\n",
      "\n",
      "Test set: Avg. loss: 0.2219, Accuracy: 192/200 (96%)\n",
      "\n",
      "Train Epoch: 16 [0/798 (0%)]\tLoss: 0.746529\n",
      "Train Epoch: 16 [100/798 (12%)]\tLoss: 0.689853\n",
      "Train Epoch: 16 [200/798 (25%)]\tLoss: 0.283239\n",
      "Train Epoch: 16 [300/798 (38%)]\tLoss: 0.401940\n",
      "Train Epoch: 16 [400/798 (50%)]\tLoss: 0.516604\n",
      "Train Epoch: 16 [500/798 (62%)]\tLoss: 0.306455\n",
      "Train Epoch: 16 [600/798 (75%)]\tLoss: 0.696605\n",
      "Train Epoch: 16 [700/798 (88%)]\tLoss: 0.598281\n",
      "\n",
      "Test set: Avg. loss: 0.1543, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/798 (0%)]\tLoss: 0.800264\n",
      "Train Epoch: 17 [100/798 (12%)]\tLoss: 0.322612\n",
      "Train Epoch: 17 [200/798 (25%)]\tLoss: 0.616717\n",
      "Train Epoch: 17 [300/798 (38%)]\tLoss: 0.064328\n",
      "Train Epoch: 17 [400/798 (50%)]\tLoss: 0.775251\n",
      "Train Epoch: 17 [500/798 (62%)]\tLoss: 1.062631\n",
      "Train Epoch: 17 [600/798 (75%)]\tLoss: 1.684790\n",
      "Train Epoch: 17 [700/798 (88%)]\tLoss: 0.239839\n",
      "\n",
      "Test set: Avg. loss: 0.2004, Accuracy: 190/200 (95%)\n",
      "\n",
      "Train Epoch: 18 [0/798 (0%)]\tLoss: 0.370936\n",
      "Train Epoch: 18 [100/798 (12%)]\tLoss: 0.588319\n",
      "Train Epoch: 18 [200/798 (25%)]\tLoss: 0.721121\n",
      "Train Epoch: 18 [300/798 (38%)]\tLoss: 0.597120\n",
      "Train Epoch: 18 [400/798 (50%)]\tLoss: 0.356268\n",
      "Train Epoch: 18 [500/798 (62%)]\tLoss: 0.731438\n",
      "Train Epoch: 18 [600/798 (75%)]\tLoss: 1.226048\n",
      "Train Epoch: 18 [700/798 (88%)]\tLoss: 0.536773\n",
      "\n",
      "Test set: Avg. loss: 0.0970, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/798 (0%)]\tLoss: 0.209455\n",
      "Train Epoch: 19 [100/798 (12%)]\tLoss: 0.306477\n",
      "Train Epoch: 19 [200/798 (25%)]\tLoss: 0.696801\n",
      "Train Epoch: 19 [300/798 (38%)]\tLoss: 0.957476\n",
      "Train Epoch: 19 [400/798 (50%)]\tLoss: 0.820249\n",
      "Train Epoch: 19 [500/798 (62%)]\tLoss: 0.243262\n",
      "Train Epoch: 19 [600/798 (75%)]\tLoss: 0.353799\n",
      "Train Epoch: 19 [700/798 (88%)]\tLoss: 0.483408\n",
      "\n",
      "Test set: Avg. loss: 0.1180, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/798 (0%)]\tLoss: 0.650771\n",
      "Train Epoch: 20 [100/798 (12%)]\tLoss: 0.437527\n",
      "Train Epoch: 20 [200/798 (25%)]\tLoss: 0.358415\n",
      "Train Epoch: 20 [300/798 (38%)]\tLoss: 0.321078\n",
      "Train Epoch: 20 [400/798 (50%)]\tLoss: 0.306420\n",
      "Train Epoch: 20 [500/798 (62%)]\tLoss: 0.341940\n",
      "Train Epoch: 20 [600/798 (75%)]\tLoss: 0.617347\n",
      "Train Epoch: 20 [700/798 (88%)]\tLoss: 0.301168\n",
      "\n",
      "Test set: Avg. loss: 0.1055, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 21 [0/798 (0%)]\tLoss: 0.688870\n",
      "Train Epoch: 21 [100/798 (12%)]\tLoss: 0.313900\n",
      "Train Epoch: 21 [200/798 (25%)]\tLoss: 0.558016\n",
      "Train Epoch: 21 [300/798 (38%)]\tLoss: 0.539383\n",
      "Train Epoch: 21 [400/798 (50%)]\tLoss: 0.392778\n",
      "Train Epoch: 21 [500/798 (62%)]\tLoss: 0.412591\n",
      "Train Epoch: 21 [600/798 (75%)]\tLoss: 0.232757\n",
      "Train Epoch: 21 [700/798 (88%)]\tLoss: 0.109717\n",
      "\n",
      "Test set: Avg. loss: 0.0835, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 22 [0/798 (0%)]\tLoss: 0.591005\n",
      "Train Epoch: 22 [100/798 (12%)]\tLoss: 0.521189\n",
      "Train Epoch: 22 [200/798 (25%)]\tLoss: 0.263604\n",
      "Train Epoch: 22 [300/798 (38%)]\tLoss: 0.336774\n",
      "Train Epoch: 22 [400/798 (50%)]\tLoss: 0.279568\n",
      "Train Epoch: 22 [500/798 (62%)]\tLoss: 0.346620\n",
      "Train Epoch: 22 [600/798 (75%)]\tLoss: 0.647197\n",
      "Train Epoch: 22 [700/798 (88%)]\tLoss: 0.771987\n",
      "\n",
      "Test set: Avg. loss: 0.0761, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/798 (0%)]\tLoss: 0.635320\n",
      "Train Epoch: 23 [100/798 (12%)]\tLoss: 0.091789\n",
      "Train Epoch: 23 [200/798 (25%)]\tLoss: 0.555768\n",
      "Train Epoch: 23 [300/798 (38%)]\tLoss: 1.100093\n",
      "Train Epoch: 23 [400/798 (50%)]\tLoss: 0.208669\n",
      "Train Epoch: 23 [500/798 (62%)]\tLoss: 0.073884\n",
      "Train Epoch: 23 [600/798 (75%)]\tLoss: 0.499794\n",
      "Train Epoch: 23 [700/798 (88%)]\tLoss: 0.263163\n",
      "\n",
      "Test set: Avg. loss: 0.0962, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/798 (0%)]\tLoss: 0.581794\n",
      "Train Epoch: 24 [100/798 (12%)]\tLoss: 0.123228\n",
      "Train Epoch: 24 [200/798 (25%)]\tLoss: 0.581878\n",
      "Train Epoch: 24 [300/798 (38%)]\tLoss: 0.727704\n",
      "Train Epoch: 24 [400/798 (50%)]\tLoss: 0.236663\n",
      "Train Epoch: 24 [500/798 (62%)]\tLoss: 0.208718\n",
      "Train Epoch: 24 [600/798 (75%)]\tLoss: 0.288807\n",
      "Train Epoch: 24 [700/798 (88%)]\tLoss: 0.175637\n",
      "\n",
      "Test set: Avg. loss: 0.0619, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/798 (0%)]\tLoss: 0.414565\n",
      "Train Epoch: 25 [100/798 (12%)]\tLoss: 0.183306\n",
      "Train Epoch: 25 [200/798 (25%)]\tLoss: 0.299251\n",
      "Train Epoch: 25 [300/798 (38%)]\tLoss: 0.603857\n",
      "Train Epoch: 25 [400/798 (50%)]\tLoss: 0.140822\n",
      "Train Epoch: 25 [500/798 (62%)]\tLoss: 0.324881\n",
      "Train Epoch: 25 [600/798 (75%)]\tLoss: 0.287609\n",
      "Train Epoch: 25 [700/798 (88%)]\tLoss: 0.308501\n",
      "\n",
      "Test set: Avg. loss: 0.0612, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/798 (0%)]\tLoss: 0.064647\n",
      "Train Epoch: 26 [100/798 (12%)]\tLoss: 0.025134\n",
      "Train Epoch: 26 [200/798 (25%)]\tLoss: 0.163465\n",
      "Train Epoch: 26 [300/798 (38%)]\tLoss: 0.226986\n",
      "Train Epoch: 26 [400/798 (50%)]\tLoss: 0.979679\n",
      "Train Epoch: 26 [500/798 (62%)]\tLoss: 0.775184\n",
      "Train Epoch: 26 [600/798 (75%)]\tLoss: 0.348361\n",
      "Train Epoch: 26 [700/798 (88%)]\tLoss: 0.221244\n",
      "\n",
      "Test set: Avg. loss: 0.0716, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/798 (0%)]\tLoss: 0.783854\n",
      "Train Epoch: 27 [100/798 (12%)]\tLoss: 0.648994\n",
      "Train Epoch: 27 [200/798 (25%)]\tLoss: 0.149641\n",
      "Train Epoch: 27 [300/798 (38%)]\tLoss: 0.218212\n",
      "Train Epoch: 27 [400/798 (50%)]\tLoss: 0.075319\n",
      "Train Epoch: 27 [500/798 (62%)]\tLoss: 0.127794\n",
      "Train Epoch: 27 [600/798 (75%)]\tLoss: 0.085607\n",
      "Train Epoch: 27 [700/798 (88%)]\tLoss: 0.431677\n",
      "\n",
      "Test set: Avg. loss: 0.0563, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/798 (0%)]\tLoss: 0.521876\n",
      "Train Epoch: 28 [100/798 (12%)]\tLoss: 0.146049\n",
      "Train Epoch: 28 [200/798 (25%)]\tLoss: 0.088981\n",
      "Train Epoch: 28 [300/798 (38%)]\tLoss: 0.598422\n",
      "Train Epoch: 28 [400/798 (50%)]\tLoss: 0.808653\n",
      "Train Epoch: 28 [500/798 (62%)]\tLoss: 0.052103\n",
      "Train Epoch: 28 [600/798 (75%)]\tLoss: 0.903727\n",
      "Train Epoch: 28 [700/798 (88%)]\tLoss: 0.341002\n",
      "\n",
      "Test set: Avg. loss: 0.0528, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/798 (0%)]\tLoss: 0.733708\n",
      "Train Epoch: 29 [100/798 (12%)]\tLoss: 0.322400\n",
      "Train Epoch: 29 [200/798 (25%)]\tLoss: 0.347847\n",
      "Train Epoch: 29 [300/798 (38%)]\tLoss: 0.411581\n",
      "Train Epoch: 29 [400/798 (50%)]\tLoss: 0.519495\n",
      "Train Epoch: 29 [500/798 (62%)]\tLoss: 0.249041\n",
      "Train Epoch: 29 [600/798 (75%)]\tLoss: 0.410472\n",
      "Train Epoch: 29 [700/798 (88%)]\tLoss: 0.546672\n",
      "\n",
      "Test set: Avg. loss: 0.0640, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 30 [0/798 (0%)]\tLoss: 0.178822\n",
      "Train Epoch: 30 [100/798 (12%)]\tLoss: 0.160958\n",
      "Train Epoch: 30 [200/798 (25%)]\tLoss: 0.516352\n",
      "Train Epoch: 30 [300/798 (38%)]\tLoss: 0.226237\n",
      "Train Epoch: 30 [400/798 (50%)]\tLoss: 0.074858\n",
      "Train Epoch: 30 [500/798 (62%)]\tLoss: 0.376218\n",
      "Train Epoch: 30 [600/798 (75%)]\tLoss: 0.218700\n",
      "Train Epoch: 30 [700/798 (88%)]\tLoss: 0.908994\n",
      "\n",
      "Test set: Avg. loss: 0.0563, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/798 (0%)]\tLoss: 0.054995\n",
      "Train Epoch: 31 [100/798 (12%)]\tLoss: 0.237485\n",
      "Train Epoch: 31 [200/798 (25%)]\tLoss: 0.926801\n",
      "Train Epoch: 31 [300/798 (38%)]\tLoss: 0.230916\n",
      "Train Epoch: 31 [400/798 (50%)]\tLoss: 0.192718\n",
      "Train Epoch: 31 [500/798 (62%)]\tLoss: 0.121824\n",
      "Train Epoch: 31 [600/798 (75%)]\tLoss: 0.110214\n",
      "Train Epoch: 31 [700/798 (88%)]\tLoss: 0.510754\n",
      "\n",
      "Test set: Avg. loss: 0.0545, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 32 [0/798 (0%)]\tLoss: 0.145577\n",
      "Train Epoch: 32 [100/798 (12%)]\tLoss: 0.760523\n",
      "Train Epoch: 32 [200/798 (25%)]\tLoss: 0.087180\n",
      "Train Epoch: 32 [300/798 (38%)]\tLoss: 0.378159\n",
      "Train Epoch: 32 [400/798 (50%)]\tLoss: 0.069626\n",
      "Train Epoch: 32 [500/798 (62%)]\tLoss: 0.270325\n",
      "Train Epoch: 32 [600/798 (75%)]\tLoss: 0.329918\n",
      "Train Epoch: 32 [700/798 (88%)]\tLoss: 0.452463\n",
      "\n",
      "Test set: Avg. loss: 0.0508, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 33 [0/798 (0%)]\tLoss: 0.120798\n",
      "Train Epoch: 33 [100/798 (12%)]\tLoss: 0.461368\n",
      "Train Epoch: 33 [200/798 (25%)]\tLoss: 0.342459\n",
      "Train Epoch: 33 [300/798 (38%)]\tLoss: 0.114609\n",
      "Train Epoch: 33 [400/798 (50%)]\tLoss: 0.272522\n",
      "Train Epoch: 33 [500/798 (62%)]\tLoss: 0.101337\n",
      "Train Epoch: 33 [600/798 (75%)]\tLoss: 0.519517\n",
      "Train Epoch: 33 [700/798 (88%)]\tLoss: 0.030281\n",
      "\n",
      "Test set: Avg. loss: 0.0568, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/798 (0%)]\tLoss: 0.081340\n",
      "Train Epoch: 34 [100/798 (12%)]\tLoss: 0.250804\n",
      "Train Epoch: 34 [200/798 (25%)]\tLoss: 0.162341\n",
      "Train Epoch: 34 [300/798 (38%)]\tLoss: 0.300688\n",
      "Train Epoch: 34 [400/798 (50%)]\tLoss: 0.207379\n",
      "Train Epoch: 34 [500/798 (62%)]\tLoss: 0.287619\n",
      "Train Epoch: 34 [600/798 (75%)]\tLoss: 0.254644\n",
      "Train Epoch: 34 [700/798 (88%)]\tLoss: 0.893774\n",
      "\n",
      "Test set: Avg. loss: 0.0582, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 35 [0/798 (0%)]\tLoss: 0.525010\n",
      "Train Epoch: 35 [100/798 (12%)]\tLoss: 0.655774\n",
      "Train Epoch: 35 [200/798 (25%)]\tLoss: 0.396059\n",
      "Train Epoch: 35 [300/798 (38%)]\tLoss: 0.225141\n",
      "Train Epoch: 35 [400/798 (50%)]\tLoss: 0.404431\n",
      "Train Epoch: 35 [500/798 (62%)]\tLoss: 0.195955\n",
      "Train Epoch: 35 [600/798 (75%)]\tLoss: 0.581333\n",
      "Train Epoch: 35 [700/798 (88%)]\tLoss: 0.345412\n",
      "\n",
      "Test set: Avg. loss: 0.0907, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 36 [0/798 (0%)]\tLoss: 0.574695\n",
      "Train Epoch: 36 [100/798 (12%)]\tLoss: 0.208771\n",
      "Train Epoch: 36 [200/798 (25%)]\tLoss: 0.256056\n",
      "Train Epoch: 36 [300/798 (38%)]\tLoss: 0.158296\n",
      "Train Epoch: 36 [400/798 (50%)]\tLoss: 0.302413\n",
      "Train Epoch: 36 [500/798 (62%)]\tLoss: 0.033391\n",
      "Train Epoch: 36 [600/798 (75%)]\tLoss: 0.200892\n",
      "Train Epoch: 36 [700/798 (88%)]\tLoss: 0.132008\n",
      "\n",
      "Test set: Avg. loss: 0.0487, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 37 [0/798 (0%)]\tLoss: 0.430857\n",
      "Train Epoch: 37 [100/798 (12%)]\tLoss: 0.269267\n",
      "Train Epoch: 37 [200/798 (25%)]\tLoss: 0.056713\n",
      "Train Epoch: 37 [300/798 (38%)]\tLoss: 0.522073\n",
      "Train Epoch: 37 [400/798 (50%)]\tLoss: 0.292129\n",
      "Train Epoch: 37 [500/798 (62%)]\tLoss: 0.353111\n",
      "Train Epoch: 37 [600/798 (75%)]\tLoss: 0.128601\n",
      "Train Epoch: 37 [700/798 (88%)]\tLoss: 0.538179\n",
      "\n",
      "Test set: Avg. loss: 0.0479, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 38 [0/798 (0%)]\tLoss: 0.121109\n",
      "Train Epoch: 38 [100/798 (12%)]\tLoss: 0.892877\n",
      "Train Epoch: 38 [200/798 (25%)]\tLoss: 0.178560\n",
      "Train Epoch: 38 [300/798 (38%)]\tLoss: 0.141442\n",
      "Train Epoch: 38 [400/798 (50%)]\tLoss: 0.484252\n",
      "Train Epoch: 38 [500/798 (62%)]\tLoss: 0.348429\n",
      "Train Epoch: 38 [600/798 (75%)]\tLoss: 0.064194\n",
      "Train Epoch: 38 [700/798 (88%)]\tLoss: 0.149061\n",
      "\n",
      "Test set: Avg. loss: 0.0410, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 39 [0/798 (0%)]\tLoss: 0.088414\n",
      "Train Epoch: 39 [100/798 (12%)]\tLoss: 0.092565\n",
      "Train Epoch: 39 [200/798 (25%)]\tLoss: 0.138221\n",
      "Train Epoch: 39 [300/798 (38%)]\tLoss: 0.530302\n",
      "Train Epoch: 39 [400/798 (50%)]\tLoss: 0.096546\n",
      "Train Epoch: 39 [500/798 (62%)]\tLoss: 0.351845\n",
      "Train Epoch: 39 [600/798 (75%)]\tLoss: 0.116739\n",
      "Train Epoch: 39 [700/798 (88%)]\tLoss: 0.029906\n",
      "\n",
      "Test set: Avg. loss: 0.0400, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 40 [0/798 (0%)]\tLoss: 0.161156\n",
      "Train Epoch: 40 [100/798 (12%)]\tLoss: 0.332822\n",
      "Train Epoch: 40 [200/798 (25%)]\tLoss: 0.631580\n",
      "Train Epoch: 40 [300/798 (38%)]\tLoss: 1.132332\n",
      "Train Epoch: 40 [400/798 (50%)]\tLoss: 0.045036\n",
      "Train Epoch: 40 [500/798 (62%)]\tLoss: 0.137354\n",
      "Train Epoch: 40 [600/798 (75%)]\tLoss: 0.183701\n",
      "Train Epoch: 40 [700/798 (88%)]\tLoss: 0.135162\n",
      "\n",
      "Test set: Avg. loss: 0.0366, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 41 [0/798 (0%)]\tLoss: 0.078645\n",
      "Train Epoch: 41 [100/798 (12%)]\tLoss: 0.029587\n",
      "Train Epoch: 41 [200/798 (25%)]\tLoss: 0.339727\n",
      "Train Epoch: 41 [300/798 (38%)]\tLoss: 0.341565\n",
      "Train Epoch: 41 [400/798 (50%)]\tLoss: 0.127388\n",
      "Train Epoch: 41 [500/798 (62%)]\tLoss: 0.075547\n",
      "Train Epoch: 41 [600/798 (75%)]\tLoss: 0.068746\n",
      "Train Epoch: 41 [700/798 (88%)]\tLoss: 0.458025\n",
      "\n",
      "Test set: Avg. loss: 0.0264, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 42 [0/798 (0%)]\tLoss: 0.730249\n",
      "Train Epoch: 42 [100/798 (12%)]\tLoss: 0.809779\n",
      "Train Epoch: 42 [200/798 (25%)]\tLoss: 0.004375\n",
      "Train Epoch: 42 [300/798 (38%)]\tLoss: 0.419235\n",
      "Train Epoch: 42 [400/798 (50%)]\tLoss: 0.166835\n",
      "Train Epoch: 42 [500/798 (62%)]\tLoss: 0.676886\n",
      "Train Epoch: 42 [600/798 (75%)]\tLoss: 0.332919\n",
      "Train Epoch: 42 [700/798 (88%)]\tLoss: 0.212336\n",
      "\n",
      "Test set: Avg. loss: 0.0389, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 43 [0/798 (0%)]\tLoss: 0.000430\n",
      "Train Epoch: 43 [100/798 (12%)]\tLoss: 0.003294\n",
      "Train Epoch: 43 [200/798 (25%)]\tLoss: 0.044234\n",
      "Train Epoch: 43 [300/798 (38%)]\tLoss: 0.160997\n",
      "Train Epoch: 43 [400/798 (50%)]\tLoss: 0.014543\n",
      "Train Epoch: 43 [500/798 (62%)]\tLoss: 0.427879\n",
      "Train Epoch: 43 [600/798 (75%)]\tLoss: 0.022948\n",
      "Train Epoch: 43 [700/798 (88%)]\tLoss: 0.332450\n",
      "\n",
      "Test set: Avg. loss: 0.0470, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 44 [0/798 (0%)]\tLoss: 0.176231\n",
      "Train Epoch: 44 [100/798 (12%)]\tLoss: 0.008283\n",
      "Train Epoch: 44 [200/798 (25%)]\tLoss: 0.108413\n",
      "Train Epoch: 44 [300/798 (38%)]\tLoss: 0.024223\n",
      "Train Epoch: 44 [400/798 (50%)]\tLoss: 0.090109\n",
      "Train Epoch: 44 [500/798 (62%)]\tLoss: 0.096082\n",
      "Train Epoch: 44 [600/798 (75%)]\tLoss: 0.158419\n",
      "Train Epoch: 44 [700/798 (88%)]\tLoss: 0.340236\n",
      "\n",
      "Test set: Avg. loss: 0.0197, Accuracy: 200/200 (100%)\n",
      "\n",
      "Train Epoch: 45 [0/798 (0%)]\tLoss: 0.411736\n",
      "Train Epoch: 45 [100/798 (12%)]\tLoss: 0.136111\n",
      "Train Epoch: 45 [200/798 (25%)]\tLoss: 0.649812\n",
      "Train Epoch: 45 [300/798 (38%)]\tLoss: 0.020356\n",
      "Train Epoch: 45 [400/798 (50%)]\tLoss: 0.004410\n",
      "Train Epoch: 45 [500/798 (62%)]\tLoss: 0.742320\n",
      "Train Epoch: 45 [600/798 (75%)]\tLoss: 0.120814\n",
      "Train Epoch: 45 [700/798 (88%)]\tLoss: 0.615311\n",
      "\n",
      "Test set: Avg. loss: 0.0219, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 46 [0/798 (0%)]\tLoss: 0.027269\n",
      "Train Epoch: 46 [100/798 (12%)]\tLoss: 0.286752\n",
      "Train Epoch: 46 [200/798 (25%)]\tLoss: 0.595568\n",
      "Train Epoch: 46 [300/798 (38%)]\tLoss: 0.216005\n",
      "Train Epoch: 46 [400/798 (50%)]\tLoss: 0.808996\n",
      "Train Epoch: 46 [500/798 (62%)]\tLoss: 0.233054\n",
      "Train Epoch: 46 [600/798 (75%)]\tLoss: 0.181575\n",
      "Train Epoch: 46 [700/798 (88%)]\tLoss: 0.356445\n",
      "\n",
      "Test set: Avg. loss: 0.0222, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 47 [0/798 (0%)]\tLoss: 0.000383\n",
      "Train Epoch: 47 [100/798 (12%)]\tLoss: 0.045283\n",
      "Train Epoch: 47 [200/798 (25%)]\tLoss: 0.089660\n",
      "Train Epoch: 47 [300/798 (38%)]\tLoss: 0.140360\n",
      "Train Epoch: 47 [400/798 (50%)]\tLoss: 0.206722\n",
      "Train Epoch: 47 [500/798 (62%)]\tLoss: 0.071724\n",
      "Train Epoch: 47 [600/798 (75%)]\tLoss: 0.038952\n",
      "Train Epoch: 47 [700/798 (88%)]\tLoss: 0.026619\n",
      "\n",
      "Test set: Avg. loss: 0.0298, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 48 [0/798 (0%)]\tLoss: 0.264260\n",
      "Train Epoch: 48 [100/798 (12%)]\tLoss: 0.496416\n",
      "Train Epoch: 48 [200/798 (25%)]\tLoss: 0.550551\n",
      "Train Epoch: 48 [300/798 (38%)]\tLoss: 0.003779\n",
      "Train Epoch: 48 [400/798 (50%)]\tLoss: 0.079246\n",
      "Train Epoch: 48 [500/798 (62%)]\tLoss: 0.210410\n",
      "Train Epoch: 48 [600/798 (75%)]\tLoss: 0.230966\n",
      "Train Epoch: 48 [700/798 (88%)]\tLoss: 0.197246\n",
      "\n",
      "Test set: Avg. loss: 0.0304, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 49 [0/798 (0%)]\tLoss: 0.217101\n",
      "Train Epoch: 49 [100/798 (12%)]\tLoss: 0.366113\n",
      "Train Epoch: 49 [200/798 (25%)]\tLoss: 0.358209\n",
      "Train Epoch: 49 [300/798 (38%)]\tLoss: 0.029298\n",
      "Train Epoch: 49 [400/798 (50%)]\tLoss: 0.228102\n",
      "Train Epoch: 49 [500/798 (62%)]\tLoss: 0.035434\n",
      "Train Epoch: 49 [600/798 (75%)]\tLoss: 0.064244\n",
      "Train Epoch: 49 [700/798 (88%)]\tLoss: 0.119472\n",
      "\n",
      "Test set: Avg. loss: 0.0304, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 50 [0/798 (0%)]\tLoss: 0.241975\n",
      "Train Epoch: 50 [100/798 (12%)]\tLoss: 0.014504\n",
      "Train Epoch: 50 [200/798 (25%)]\tLoss: 0.280364\n",
      "Train Epoch: 50 [300/798 (38%)]\tLoss: 0.256252\n",
      "Train Epoch: 50 [400/798 (50%)]\tLoss: 0.112207\n",
      "Train Epoch: 50 [500/798 (62%)]\tLoss: 0.358188\n",
      "Train Epoch: 50 [600/798 (75%)]\tLoss: 0.143175\n",
      "Train Epoch: 50 [700/798 (88%)]\tLoss: 0.309789\n",
      "\n",
      "Test set: Avg. loss: 0.0310, Accuracy: 198/200 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0310, Accuracy: 198/200 (99%)\n",
      "\n",
      "Running bootstrap experiment: 5\n",
      "Train Epoch: 1 [0/798 (0%)]\tLoss: 2.346112\n",
      "Train Epoch: 1 [100/798 (12%)]\tLoss: 2.301136\n",
      "Train Epoch: 1 [200/798 (25%)]\tLoss: 2.272983\n",
      "Train Epoch: 1 [300/798 (38%)]\tLoss: 2.332202\n",
      "Train Epoch: 1 [400/798 (50%)]\tLoss: 2.310182\n",
      "Train Epoch: 1 [500/798 (62%)]\tLoss: 2.218338\n",
      "Train Epoch: 1 [600/798 (75%)]\tLoss: 2.306102\n",
      "Train Epoch: 1 [700/798 (88%)]\tLoss: 2.244509\n",
      "\n",
      "Test set: Avg. loss: 2.2771, Accuracy: 24/200 (12%)\n",
      "\n",
      "Train Epoch: 2 [0/798 (0%)]\tLoss: 2.394022\n",
      "Train Epoch: 2 [100/798 (12%)]\tLoss: 2.236979\n",
      "Train Epoch: 2 [200/798 (25%)]\tLoss: 2.286491\n",
      "Train Epoch: 2 [300/798 (38%)]\tLoss: 2.236953\n",
      "Train Epoch: 2 [400/798 (50%)]\tLoss: 2.278082\n",
      "Train Epoch: 2 [500/798 (62%)]\tLoss: 2.267987\n",
      "Train Epoch: 2 [600/798 (75%)]\tLoss: 2.326340\n",
      "Train Epoch: 2 [700/798 (88%)]\tLoss: 2.288979\n",
      "\n",
      "Test set: Avg. loss: 2.2311, Accuracy: 52/200 (26%)\n",
      "\n",
      "Train Epoch: 3 [0/798 (0%)]\tLoss: 2.301656\n",
      "Train Epoch: 3 [100/798 (12%)]\tLoss: 2.262969\n",
      "Train Epoch: 3 [200/798 (25%)]\tLoss: 2.281328\n",
      "Train Epoch: 3 [300/798 (38%)]\tLoss: 2.204889\n",
      "Train Epoch: 3 [400/798 (50%)]\tLoss: 2.249506\n",
      "Train Epoch: 3 [500/798 (62%)]\tLoss: 2.300831\n",
      "Train Epoch: 3 [600/798 (75%)]\tLoss: 2.076197\n",
      "Train Epoch: 3 [700/798 (88%)]\tLoss: 2.228020\n",
      "\n",
      "Test set: Avg. loss: 2.1130, Accuracy: 64/200 (32%)\n",
      "\n",
      "Train Epoch: 4 [0/798 (0%)]\tLoss: 2.117926\n",
      "Train Epoch: 4 [100/798 (12%)]\tLoss: 1.961841\n",
      "Train Epoch: 4 [200/798 (25%)]\tLoss: 2.021092\n",
      "Train Epoch: 4 [300/798 (38%)]\tLoss: 2.063817\n",
      "Train Epoch: 4 [400/798 (50%)]\tLoss: 2.074523\n",
      "Train Epoch: 4 [500/798 (62%)]\tLoss: 2.088068\n",
      "Train Epoch: 4 [600/798 (75%)]\tLoss: 2.179209\n",
      "Train Epoch: 4 [700/798 (88%)]\tLoss: 1.919148\n",
      "\n",
      "Test set: Avg. loss: 1.8635, Accuracy: 69/200 (34%)\n",
      "\n",
      "Train Epoch: 5 [0/798 (0%)]\tLoss: 1.958574\n",
      "Train Epoch: 5 [100/798 (12%)]\tLoss: 2.010919\n",
      "Train Epoch: 5 [200/798 (25%)]\tLoss: 2.015887\n",
      "Train Epoch: 5 [300/798 (38%)]\tLoss: 1.948152\n",
      "Train Epoch: 5 [400/798 (50%)]\tLoss: 1.587391\n",
      "Train Epoch: 5 [500/798 (62%)]\tLoss: 1.643293\n",
      "Train Epoch: 5 [600/798 (75%)]\tLoss: 2.037017\n",
      "Train Epoch: 5 [700/798 (88%)]\tLoss: 1.820368\n",
      "\n",
      "Test set: Avg. loss: 1.5095, Accuracy: 140/200 (70%)\n",
      "\n",
      "Train Epoch: 6 [0/798 (0%)]\tLoss: 1.549552\n",
      "Train Epoch: 6 [100/798 (12%)]\tLoss: 1.410554\n",
      "Train Epoch: 6 [200/798 (25%)]\tLoss: 1.420859\n",
      "Train Epoch: 6 [300/798 (38%)]\tLoss: 1.779006\n",
      "Train Epoch: 6 [400/798 (50%)]\tLoss: 1.307266\n",
      "Train Epoch: 6 [500/798 (62%)]\tLoss: 1.007010\n",
      "Train Epoch: 6 [600/798 (75%)]\tLoss: 1.391474\n",
      "Train Epoch: 6 [700/798 (88%)]\tLoss: 1.590092\n",
      "\n",
      "Test set: Avg. loss: 1.1606, Accuracy: 139/200 (70%)\n",
      "\n",
      "Train Epoch: 7 [0/798 (0%)]\tLoss: 1.310605\n",
      "Train Epoch: 7 [100/798 (12%)]\tLoss: 1.470643\n",
      "Train Epoch: 7 [200/798 (25%)]\tLoss: 1.951045\n",
      "Train Epoch: 7 [300/798 (38%)]\tLoss: 1.177023\n",
      "Train Epoch: 7 [400/798 (50%)]\tLoss: 1.405058\n",
      "Train Epoch: 7 [500/798 (62%)]\tLoss: 1.313077\n",
      "Train Epoch: 7 [600/798 (75%)]\tLoss: 1.141870\n",
      "Train Epoch: 7 [700/798 (88%)]\tLoss: 1.087412\n",
      "\n",
      "Test set: Avg. loss: 0.7500, Accuracy: 172/200 (86%)\n",
      "\n",
      "Train Epoch: 8 [0/798 (0%)]\tLoss: 1.182272\n",
      "Train Epoch: 8 [100/798 (12%)]\tLoss: 1.156022\n",
      "Train Epoch: 8 [200/798 (25%)]\tLoss: 1.268600\n",
      "Train Epoch: 8 [300/798 (38%)]\tLoss: 1.062230\n",
      "Train Epoch: 8 [400/798 (50%)]\tLoss: 1.103066\n",
      "Train Epoch: 8 [500/798 (62%)]\tLoss: 1.049040\n",
      "Train Epoch: 8 [600/798 (75%)]\tLoss: 1.077303\n",
      "Train Epoch: 8 [700/798 (88%)]\tLoss: 1.422570\n",
      "\n",
      "Test set: Avg. loss: 0.6894, Accuracy: 165/200 (82%)\n",
      "\n",
      "Train Epoch: 9 [0/798 (0%)]\tLoss: 1.189314\n",
      "Train Epoch: 9 [100/798 (12%)]\tLoss: 1.390920\n",
      "Train Epoch: 9 [200/798 (25%)]\tLoss: 0.924153\n",
      "Train Epoch: 9 [300/798 (38%)]\tLoss: 0.565400\n",
      "Train Epoch: 9 [400/798 (50%)]\tLoss: 0.579837\n",
      "Train Epoch: 9 [500/798 (62%)]\tLoss: 1.164418\n",
      "Train Epoch: 9 [600/798 (75%)]\tLoss: 1.038990\n",
      "Train Epoch: 9 [700/798 (88%)]\tLoss: 0.812566\n",
      "\n",
      "Test set: Avg. loss: 0.5297, Accuracy: 187/200 (94%)\n",
      "\n",
      "Train Epoch: 10 [0/798 (0%)]\tLoss: 0.802161\n",
      "Train Epoch: 10 [100/798 (12%)]\tLoss: 1.380923\n",
      "Train Epoch: 10 [200/798 (25%)]\tLoss: 1.414083\n",
      "Train Epoch: 10 [300/798 (38%)]\tLoss: 0.757345\n",
      "Train Epoch: 10 [400/798 (50%)]\tLoss: 0.878046\n",
      "Train Epoch: 10 [500/798 (62%)]\tLoss: 0.698865\n",
      "Train Epoch: 10 [600/798 (75%)]\tLoss: 1.025418\n",
      "Train Epoch: 10 [700/798 (88%)]\tLoss: 1.170063\n",
      "\n",
      "Test set: Avg. loss: 0.4032, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 11 [0/798 (0%)]\tLoss: 0.981626\n",
      "Train Epoch: 11 [100/798 (12%)]\tLoss: 1.059048\n",
      "Train Epoch: 11 [200/798 (25%)]\tLoss: 1.193585\n",
      "Train Epoch: 11 [300/798 (38%)]\tLoss: 0.764539\n",
      "Train Epoch: 11 [400/798 (50%)]\tLoss: 1.150254\n",
      "Train Epoch: 11 [500/798 (62%)]\tLoss: 0.864343\n",
      "Train Epoch: 11 [600/798 (75%)]\tLoss: 1.033051\n",
      "Train Epoch: 11 [700/798 (88%)]\tLoss: 0.894219\n",
      "\n",
      "Test set: Avg. loss: 0.3541, Accuracy: 190/200 (95%)\n",
      "\n",
      "Train Epoch: 12 [0/798 (0%)]\tLoss: 1.055863\n",
      "Train Epoch: 12 [100/798 (12%)]\tLoss: 0.729580\n",
      "Train Epoch: 12 [200/798 (25%)]\tLoss: 0.722922\n",
      "Train Epoch: 12 [300/798 (38%)]\tLoss: 0.898547\n",
      "Train Epoch: 12 [400/798 (50%)]\tLoss: 0.816546\n",
      "Train Epoch: 12 [500/798 (62%)]\tLoss: 0.875515\n",
      "Train Epoch: 12 [600/798 (75%)]\tLoss: 0.671805\n",
      "Train Epoch: 12 [700/798 (88%)]\tLoss: 0.672767\n",
      "\n",
      "Test set: Avg. loss: 0.2836, Accuracy: 192/200 (96%)\n",
      "\n",
      "Train Epoch: 13 [0/798 (0%)]\tLoss: 0.706749\n",
      "Train Epoch: 13 [100/798 (12%)]\tLoss: 0.562657\n",
      "Train Epoch: 13 [200/798 (25%)]\tLoss: 0.718501\n",
      "Train Epoch: 13 [300/798 (38%)]\tLoss: 0.839438\n",
      "Train Epoch: 13 [400/798 (50%)]\tLoss: 0.764509\n",
      "Train Epoch: 13 [500/798 (62%)]\tLoss: 0.779730\n",
      "Train Epoch: 13 [600/798 (75%)]\tLoss: 0.836125\n",
      "Train Epoch: 13 [700/798 (88%)]\tLoss: 0.785100\n",
      "\n",
      "Test set: Avg. loss: 0.2424, Accuracy: 193/200 (96%)\n",
      "\n",
      "Train Epoch: 14 [0/798 (0%)]\tLoss: 0.552618\n",
      "Train Epoch: 14 [100/798 (12%)]\tLoss: 1.001797\n",
      "Train Epoch: 14 [200/798 (25%)]\tLoss: 0.977883\n",
      "Train Epoch: 14 [300/798 (38%)]\tLoss: 0.629805\n",
      "Train Epoch: 14 [400/798 (50%)]\tLoss: 0.322448\n",
      "Train Epoch: 14 [500/798 (62%)]\tLoss: 0.929715\n",
      "Train Epoch: 14 [600/798 (75%)]\tLoss: 0.813112\n",
      "Train Epoch: 14 [700/798 (88%)]\tLoss: 0.749145\n",
      "\n",
      "Test set: Avg. loss: 0.2012, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 15 [0/798 (0%)]\tLoss: 0.649511\n",
      "Train Epoch: 15 [100/798 (12%)]\tLoss: 1.132448\n",
      "Train Epoch: 15 [200/798 (25%)]\tLoss: 0.444223\n",
      "Train Epoch: 15 [300/798 (38%)]\tLoss: 0.830618\n",
      "Train Epoch: 15 [400/798 (50%)]\tLoss: 0.900118\n",
      "Train Epoch: 15 [500/798 (62%)]\tLoss: 0.738050\n",
      "Train Epoch: 15 [600/798 (75%)]\tLoss: 0.582923\n",
      "Train Epoch: 15 [700/798 (88%)]\tLoss: 0.302220\n",
      "\n",
      "Test set: Avg. loss: 0.1680, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 16 [0/798 (0%)]\tLoss: 0.741169\n",
      "Train Epoch: 16 [100/798 (12%)]\tLoss: 0.787938\n",
      "Train Epoch: 16 [200/798 (25%)]\tLoss: 0.802109\n",
      "Train Epoch: 16 [300/798 (38%)]\tLoss: 1.399007\n",
      "Train Epoch: 16 [400/798 (50%)]\tLoss: 0.573677\n",
      "Train Epoch: 16 [500/798 (62%)]\tLoss: 0.813111\n",
      "Train Epoch: 16 [600/798 (75%)]\tLoss: 0.218200\n",
      "Train Epoch: 16 [700/798 (88%)]\tLoss: 0.329055\n",
      "\n",
      "Test set: Avg. loss: 0.1362, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/798 (0%)]\tLoss: 0.846870\n",
      "Train Epoch: 17 [100/798 (12%)]\tLoss: 0.377099\n",
      "Train Epoch: 17 [200/798 (25%)]\tLoss: 0.473341\n",
      "Train Epoch: 17 [300/798 (38%)]\tLoss: 0.429490\n",
      "Train Epoch: 17 [400/798 (50%)]\tLoss: 0.422082\n",
      "Train Epoch: 17 [500/798 (62%)]\tLoss: 0.485979\n",
      "Train Epoch: 17 [600/798 (75%)]\tLoss: 0.440567\n",
      "Train Epoch: 17 [700/798 (88%)]\tLoss: 0.494576\n",
      "\n",
      "Test set: Avg. loss: 0.1122, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/798 (0%)]\tLoss: 0.418610\n",
      "Train Epoch: 18 [100/798 (12%)]\tLoss: 0.362125\n",
      "Train Epoch: 18 [200/798 (25%)]\tLoss: 0.760856\n",
      "Train Epoch: 18 [300/798 (38%)]\tLoss: 0.559544\n",
      "Train Epoch: 18 [400/798 (50%)]\tLoss: 0.571035\n",
      "Train Epoch: 18 [500/798 (62%)]\tLoss: 0.484937\n",
      "Train Epoch: 18 [600/798 (75%)]\tLoss: 0.434053\n",
      "Train Epoch: 18 [700/798 (88%)]\tLoss: 0.781614\n",
      "\n",
      "Test set: Avg. loss: 0.1109, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 19 [0/798 (0%)]\tLoss: 0.744680\n",
      "Train Epoch: 19 [100/798 (12%)]\tLoss: 0.889544\n",
      "Train Epoch: 19 [200/798 (25%)]\tLoss: 0.143013\n",
      "Train Epoch: 19 [300/798 (38%)]\tLoss: 0.200160\n",
      "Train Epoch: 19 [400/798 (50%)]\tLoss: 1.100616\n",
      "Train Epoch: 19 [500/798 (62%)]\tLoss: 0.198300\n",
      "Train Epoch: 19 [600/798 (75%)]\tLoss: 0.549310\n",
      "Train Epoch: 19 [700/798 (88%)]\tLoss: 0.368245\n",
      "\n",
      "Test set: Avg. loss: 0.0749, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 20 [0/798 (0%)]\tLoss: 0.375700\n",
      "Train Epoch: 20 [100/798 (12%)]\tLoss: 0.400075\n",
      "Train Epoch: 20 [200/798 (25%)]\tLoss: 0.532439\n",
      "Train Epoch: 20 [300/798 (38%)]\tLoss: 0.685391\n",
      "Train Epoch: 20 [400/798 (50%)]\tLoss: 0.352993\n",
      "Train Epoch: 20 [500/798 (62%)]\tLoss: 0.362723\n",
      "Train Epoch: 20 [600/798 (75%)]\tLoss: 0.596037\n",
      "Train Epoch: 20 [700/798 (88%)]\tLoss: 0.438765\n",
      "\n",
      "Test set: Avg. loss: 0.0977, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/798 (0%)]\tLoss: 0.167498\n",
      "Train Epoch: 21 [100/798 (12%)]\tLoss: 0.720075\n",
      "Train Epoch: 21 [200/798 (25%)]\tLoss: 0.388443\n",
      "Train Epoch: 21 [300/798 (38%)]\tLoss: 0.594065\n",
      "Train Epoch: 21 [400/798 (50%)]\tLoss: 0.515640\n",
      "Train Epoch: 21 [500/798 (62%)]\tLoss: 0.471663\n",
      "Train Epoch: 21 [600/798 (75%)]\tLoss: 0.616635\n",
      "Train Epoch: 21 [700/798 (88%)]\tLoss: 0.450140\n",
      "\n",
      "Test set: Avg. loss: 0.0836, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/798 (0%)]\tLoss: 0.237073\n",
      "Train Epoch: 22 [100/798 (12%)]\tLoss: 0.208675\n",
      "Train Epoch: 22 [200/798 (25%)]\tLoss: 0.495244\n",
      "Train Epoch: 22 [300/798 (38%)]\tLoss: 0.200900\n",
      "Train Epoch: 22 [400/798 (50%)]\tLoss: 0.290078\n",
      "Train Epoch: 22 [500/798 (62%)]\tLoss: 0.268618\n",
      "Train Epoch: 22 [600/798 (75%)]\tLoss: 0.296600\n",
      "Train Epoch: 22 [700/798 (88%)]\tLoss: 0.820445\n",
      "\n",
      "Test set: Avg. loss: 0.0763, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/798 (0%)]\tLoss: 0.290384\n",
      "Train Epoch: 23 [100/798 (12%)]\tLoss: 0.353525\n",
      "Train Epoch: 23 [200/798 (25%)]\tLoss: 0.274519\n",
      "Train Epoch: 23 [300/798 (38%)]\tLoss: 0.276618\n",
      "Train Epoch: 23 [400/798 (50%)]\tLoss: 0.333728\n",
      "Train Epoch: 23 [500/798 (62%)]\tLoss: 0.154595\n",
      "Train Epoch: 23 [600/798 (75%)]\tLoss: 0.320593\n",
      "Train Epoch: 23 [700/798 (88%)]\tLoss: 0.626061\n",
      "\n",
      "Test set: Avg. loss: 0.0734, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/798 (0%)]\tLoss: 0.396393\n",
      "Train Epoch: 24 [100/798 (12%)]\tLoss: 0.573744\n",
      "Train Epoch: 24 [200/798 (25%)]\tLoss: 0.279315\n",
      "Train Epoch: 24 [300/798 (38%)]\tLoss: 0.802604\n",
      "Train Epoch: 24 [400/798 (50%)]\tLoss: 0.502895\n",
      "Train Epoch: 24 [500/798 (62%)]\tLoss: 1.088082\n",
      "Train Epoch: 24 [600/798 (75%)]\tLoss: 0.164458\n",
      "Train Epoch: 24 [700/798 (88%)]\tLoss: 0.381440\n",
      "\n",
      "Test set: Avg. loss: 0.0869, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/798 (0%)]\tLoss: 0.093842\n",
      "Train Epoch: 25 [100/798 (12%)]\tLoss: 0.300787\n",
      "Train Epoch: 25 [200/798 (25%)]\tLoss: 0.199213\n",
      "Train Epoch: 25 [300/798 (38%)]\tLoss: 0.483964\n",
      "Train Epoch: 25 [400/798 (50%)]\tLoss: 0.220034\n",
      "Train Epoch: 25 [500/798 (62%)]\tLoss: 0.522847\n",
      "Train Epoch: 25 [600/798 (75%)]\tLoss: 0.299090\n",
      "Train Epoch: 25 [700/798 (88%)]\tLoss: 0.449066\n",
      "\n",
      "Test set: Avg. loss: 0.0471, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/798 (0%)]\tLoss: 0.645277\n",
      "Train Epoch: 26 [100/798 (12%)]\tLoss: 0.580702\n",
      "Train Epoch: 26 [200/798 (25%)]\tLoss: 0.186970\n",
      "Train Epoch: 26 [300/798 (38%)]\tLoss: 0.216171\n",
      "Train Epoch: 26 [400/798 (50%)]\tLoss: 0.236251\n",
      "Train Epoch: 26 [500/798 (62%)]\tLoss: 0.430697\n",
      "Train Epoch: 26 [600/798 (75%)]\tLoss: 0.983314\n",
      "Train Epoch: 26 [700/798 (88%)]\tLoss: 0.803665\n",
      "\n",
      "Test set: Avg. loss: 0.0443, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 27 [0/798 (0%)]\tLoss: 0.266622\n",
      "Train Epoch: 27 [100/798 (12%)]\tLoss: 0.095779\n",
      "Train Epoch: 27 [200/798 (25%)]\tLoss: 0.399537\n",
      "Train Epoch: 27 [300/798 (38%)]\tLoss: 0.514346\n",
      "Train Epoch: 27 [400/798 (50%)]\tLoss: 0.336713\n",
      "Train Epoch: 27 [500/798 (62%)]\tLoss: 0.295298\n",
      "Train Epoch: 27 [600/798 (75%)]\tLoss: 0.172889\n",
      "Train Epoch: 27 [700/798 (88%)]\tLoss: 0.434834\n",
      "\n",
      "Test set: Avg. loss: 0.0401, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/798 (0%)]\tLoss: 0.188914\n",
      "Train Epoch: 28 [100/798 (12%)]\tLoss: 0.652732\n",
      "Train Epoch: 28 [200/798 (25%)]\tLoss: 0.273506\n",
      "Train Epoch: 28 [300/798 (38%)]\tLoss: 0.506061\n",
      "Train Epoch: 28 [400/798 (50%)]\tLoss: 0.237585\n",
      "Train Epoch: 28 [500/798 (62%)]\tLoss: 0.197610\n",
      "Train Epoch: 28 [600/798 (75%)]\tLoss: 0.407542\n",
      "Train Epoch: 28 [700/798 (88%)]\tLoss: 0.369057\n",
      "\n",
      "Test set: Avg. loss: 0.0235, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 29 [0/798 (0%)]\tLoss: 0.589707\n",
      "Train Epoch: 29 [100/798 (12%)]\tLoss: 0.517207\n",
      "Train Epoch: 29 [200/798 (25%)]\tLoss: 0.125145\n",
      "Train Epoch: 29 [300/798 (38%)]\tLoss: 0.314394\n",
      "Train Epoch: 29 [400/798 (50%)]\tLoss: 0.607379\n",
      "Train Epoch: 29 [500/798 (62%)]\tLoss: 0.934404\n",
      "Train Epoch: 29 [600/798 (75%)]\tLoss: 0.739072\n",
      "Train Epoch: 29 [700/798 (88%)]\tLoss: 0.500416\n",
      "\n",
      "Test set: Avg. loss: 0.0368, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 30 [0/798 (0%)]\tLoss: 0.551353\n",
      "Train Epoch: 30 [100/798 (12%)]\tLoss: 0.815799\n",
      "Train Epoch: 30 [200/798 (25%)]\tLoss: 0.135726\n",
      "Train Epoch: 30 [300/798 (38%)]\tLoss: 0.068782\n",
      "Train Epoch: 30 [400/798 (50%)]\tLoss: 0.267950\n",
      "Train Epoch: 30 [500/798 (62%)]\tLoss: 0.311515\n",
      "Train Epoch: 30 [600/798 (75%)]\tLoss: 0.185456\n",
      "Train Epoch: 30 [700/798 (88%)]\tLoss: 0.163500\n",
      "\n",
      "Test set: Avg. loss: 0.0511, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 31 [0/798 (0%)]\tLoss: 0.435101\n",
      "Train Epoch: 31 [100/798 (12%)]\tLoss: 0.215381\n",
      "Train Epoch: 31 [200/798 (25%)]\tLoss: 0.220699\n",
      "Train Epoch: 31 [300/798 (38%)]\tLoss: 0.026232\n",
      "Train Epoch: 31 [400/798 (50%)]\tLoss: 0.403546\n",
      "Train Epoch: 31 [500/798 (62%)]\tLoss: 0.548396\n",
      "Train Epoch: 31 [600/798 (75%)]\tLoss: 0.252681\n",
      "Train Epoch: 31 [700/798 (88%)]\tLoss: 0.045545\n",
      "\n",
      "Test set: Avg. loss: 0.0450, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 32 [0/798 (0%)]\tLoss: 0.443916\n",
      "Train Epoch: 32 [100/798 (12%)]\tLoss: 0.074795\n",
      "Train Epoch: 32 [200/798 (25%)]\tLoss: 0.777508\n",
      "Train Epoch: 32 [300/798 (38%)]\tLoss: 0.023805\n",
      "Train Epoch: 32 [400/798 (50%)]\tLoss: 0.029601\n",
      "Train Epoch: 32 [500/798 (62%)]\tLoss: 0.482974\n",
      "Train Epoch: 32 [600/798 (75%)]\tLoss: 0.446596\n",
      "Train Epoch: 32 [700/798 (88%)]\tLoss: 0.109607\n",
      "\n",
      "Test set: Avg. loss: 0.0407, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 33 [0/798 (0%)]\tLoss: 0.400365\n",
      "Train Epoch: 33 [100/798 (12%)]\tLoss: 0.086928\n",
      "Train Epoch: 33 [200/798 (25%)]\tLoss: 0.156613\n",
      "Train Epoch: 33 [300/798 (38%)]\tLoss: 0.081213\n",
      "Train Epoch: 33 [400/798 (50%)]\tLoss: 0.362545\n",
      "Train Epoch: 33 [500/798 (62%)]\tLoss: 0.378614\n",
      "Train Epoch: 33 [600/798 (75%)]\tLoss: 0.045236\n",
      "Train Epoch: 33 [700/798 (88%)]\tLoss: 0.363350\n",
      "\n",
      "Test set: Avg. loss: 0.0407, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/798 (0%)]\tLoss: 0.579814\n",
      "Train Epoch: 34 [100/798 (12%)]\tLoss: 0.102929\n",
      "Train Epoch: 34 [200/798 (25%)]\tLoss: 0.126890\n",
      "Train Epoch: 34 [300/798 (38%)]\tLoss: 0.375158\n",
      "Train Epoch: 34 [400/798 (50%)]\tLoss: 0.683937\n",
      "Train Epoch: 34 [500/798 (62%)]\tLoss: 0.277406\n",
      "Train Epoch: 34 [600/798 (75%)]\tLoss: 0.659148\n",
      "Train Epoch: 34 [700/798 (88%)]\tLoss: 0.451920\n",
      "\n",
      "Test set: Avg. loss: 0.0329, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 35 [0/798 (0%)]\tLoss: 0.119277\n",
      "Train Epoch: 35 [100/798 (12%)]\tLoss: 0.097083\n",
      "Train Epoch: 35 [200/798 (25%)]\tLoss: 0.056921\n",
      "Train Epoch: 35 [300/798 (38%)]\tLoss: 0.348115\n",
      "Train Epoch: 35 [400/798 (50%)]\tLoss: 0.152900\n",
      "Train Epoch: 35 [500/798 (62%)]\tLoss: 0.322274\n",
      "Train Epoch: 35 [600/798 (75%)]\tLoss: 0.609053\n",
      "Train Epoch: 35 [700/798 (88%)]\tLoss: 0.178439\n",
      "\n",
      "Test set: Avg. loss: 0.0431, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 36 [0/798 (0%)]\tLoss: 0.196872\n",
      "Train Epoch: 36 [100/798 (12%)]\tLoss: 0.780987\n",
      "Train Epoch: 36 [200/798 (25%)]\tLoss: 0.104811\n",
      "Train Epoch: 36 [300/798 (38%)]\tLoss: 0.441818\n",
      "Train Epoch: 36 [400/798 (50%)]\tLoss: 0.390182\n",
      "Train Epoch: 36 [500/798 (62%)]\tLoss: 0.499858\n",
      "Train Epoch: 36 [600/798 (75%)]\tLoss: 0.163037\n",
      "Train Epoch: 36 [700/798 (88%)]\tLoss: 0.386225\n",
      "\n",
      "Test set: Avg. loss: 0.0305, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 37 [0/798 (0%)]\tLoss: 0.009302\n",
      "Train Epoch: 37 [100/798 (12%)]\tLoss: 0.526515\n",
      "Train Epoch: 37 [200/798 (25%)]\tLoss: 0.322051\n",
      "Train Epoch: 37 [300/798 (38%)]\tLoss: 0.360514\n",
      "Train Epoch: 37 [400/798 (50%)]\tLoss: 0.301671\n",
      "Train Epoch: 37 [500/798 (62%)]\tLoss: 0.287138\n",
      "Train Epoch: 37 [600/798 (75%)]\tLoss: 0.517606\n",
      "Train Epoch: 37 [700/798 (88%)]\tLoss: 0.109629\n",
      "\n",
      "Test set: Avg. loss: 0.0371, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 38 [0/798 (0%)]\tLoss: 0.068917\n",
      "Train Epoch: 38 [100/798 (12%)]\tLoss: 0.015007\n",
      "Train Epoch: 38 [200/798 (25%)]\tLoss: 0.044982\n",
      "Train Epoch: 38 [300/798 (38%)]\tLoss: 0.197122\n",
      "Train Epoch: 38 [400/798 (50%)]\tLoss: 0.293980\n",
      "Train Epoch: 38 [500/798 (62%)]\tLoss: 0.484092\n",
      "Train Epoch: 38 [600/798 (75%)]\tLoss: 0.317263\n",
      "Train Epoch: 38 [700/798 (88%)]\tLoss: 0.159780\n",
      "\n",
      "Test set: Avg. loss: 0.0323, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 39 [0/798 (0%)]\tLoss: 0.428638\n",
      "Train Epoch: 39 [100/798 (12%)]\tLoss: 0.340925\n",
      "Train Epoch: 39 [200/798 (25%)]\tLoss: 0.056712\n",
      "Train Epoch: 39 [300/798 (38%)]\tLoss: 0.022740\n",
      "Train Epoch: 39 [400/798 (50%)]\tLoss: 0.225388\n",
      "Train Epoch: 39 [500/798 (62%)]\tLoss: 0.318533\n",
      "Train Epoch: 39 [600/798 (75%)]\tLoss: 0.273401\n",
      "Train Epoch: 39 [700/798 (88%)]\tLoss: 0.018897\n",
      "\n",
      "Test set: Avg. loss: 0.0283, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 40 [0/798 (0%)]\tLoss: 0.025180\n",
      "Train Epoch: 40 [100/798 (12%)]\tLoss: 0.264288\n",
      "Train Epoch: 40 [200/798 (25%)]\tLoss: 0.045969\n",
      "Train Epoch: 40 [300/798 (38%)]\tLoss: 0.344539\n",
      "Train Epoch: 40 [400/798 (50%)]\tLoss: 0.121944\n",
      "Train Epoch: 40 [500/798 (62%)]\tLoss: 0.259688\n",
      "Train Epoch: 40 [600/798 (75%)]\tLoss: 0.761249\n",
      "Train Epoch: 40 [700/798 (88%)]\tLoss: 0.404053\n",
      "\n",
      "Test set: Avg. loss: 0.0493, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 41 [0/798 (0%)]\tLoss: 0.201088\n",
      "Train Epoch: 41 [100/798 (12%)]\tLoss: 0.259420\n",
      "Train Epoch: 41 [200/798 (25%)]\tLoss: 0.266553\n",
      "Train Epoch: 41 [300/798 (38%)]\tLoss: 0.025018\n",
      "Train Epoch: 41 [400/798 (50%)]\tLoss: 0.240577\n",
      "Train Epoch: 41 [500/798 (62%)]\tLoss: 0.096630\n",
      "Train Epoch: 41 [600/798 (75%)]\tLoss: 0.342864\n",
      "Train Epoch: 41 [700/798 (88%)]\tLoss: 0.293579\n",
      "\n",
      "Test set: Avg. loss: 0.0539, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 42 [0/798 (0%)]\tLoss: 0.326781\n",
      "Train Epoch: 42 [100/798 (12%)]\tLoss: 0.095681\n",
      "Train Epoch: 42 [200/798 (25%)]\tLoss: 0.173949\n",
      "Train Epoch: 42 [300/798 (38%)]\tLoss: 0.318085\n",
      "Train Epoch: 42 [400/798 (50%)]\tLoss: 0.086786\n",
      "Train Epoch: 42 [500/798 (62%)]\tLoss: 0.232929\n",
      "Train Epoch: 42 [600/798 (75%)]\tLoss: 0.193144\n",
      "Train Epoch: 42 [700/798 (88%)]\tLoss: 0.088549\n",
      "\n",
      "Test set: Avg. loss: 0.0217, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 43 [0/798 (0%)]\tLoss: 0.171646\n",
      "Train Epoch: 43 [100/798 (12%)]\tLoss: 0.099592\n",
      "Train Epoch: 43 [200/798 (25%)]\tLoss: 0.051359\n",
      "Train Epoch: 43 [300/798 (38%)]\tLoss: 0.139864\n",
      "Train Epoch: 43 [400/798 (50%)]\tLoss: 0.108184\n",
      "Train Epoch: 43 [500/798 (62%)]\tLoss: 0.042720\n",
      "Train Epoch: 43 [600/798 (75%)]\tLoss: 0.085841\n",
      "Train Epoch: 43 [700/798 (88%)]\tLoss: 0.099384\n",
      "\n",
      "Test set: Avg. loss: 0.0360, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 44 [0/798 (0%)]\tLoss: 0.042743\n",
      "Train Epoch: 44 [100/798 (12%)]\tLoss: 0.161348\n",
      "Train Epoch: 44 [200/798 (25%)]\tLoss: 0.261570\n",
      "Train Epoch: 44 [300/798 (38%)]\tLoss: 0.235622\n",
      "Train Epoch: 44 [400/798 (50%)]\tLoss: 0.057027\n",
      "Train Epoch: 44 [500/798 (62%)]\tLoss: 0.427580\n",
      "Train Epoch: 44 [600/798 (75%)]\tLoss: 0.145666\n",
      "Train Epoch: 44 [700/798 (88%)]\tLoss: 0.156074\n",
      "\n",
      "Test set: Avg. loss: 0.0333, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 45 [0/798 (0%)]\tLoss: 0.598893\n",
      "Train Epoch: 45 [100/798 (12%)]\tLoss: 0.086268\n",
      "Train Epoch: 45 [200/798 (25%)]\tLoss: 0.446839\n",
      "Train Epoch: 45 [300/798 (38%)]\tLoss: 0.481443\n",
      "Train Epoch: 45 [400/798 (50%)]\tLoss: 0.232141\n",
      "Train Epoch: 45 [500/798 (62%)]\tLoss: 0.501124\n",
      "Train Epoch: 45 [600/798 (75%)]\tLoss: 0.170546\n",
      "Train Epoch: 45 [700/798 (88%)]\tLoss: 0.181157\n",
      "\n",
      "Test set: Avg. loss: 0.0528, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 46 [0/798 (0%)]\tLoss: 0.016146\n",
      "Train Epoch: 46 [100/798 (12%)]\tLoss: 0.109097\n",
      "Train Epoch: 46 [200/798 (25%)]\tLoss: 0.389885\n",
      "Train Epoch: 46 [300/798 (38%)]\tLoss: 0.119282\n",
      "Train Epoch: 46 [400/798 (50%)]\tLoss: 0.275499\n",
      "Train Epoch: 46 [500/798 (62%)]\tLoss: 0.634487\n",
      "Train Epoch: 46 [600/798 (75%)]\tLoss: 0.011221\n",
      "Train Epoch: 46 [700/798 (88%)]\tLoss: 0.092315\n",
      "\n",
      "Test set: Avg. loss: 0.0375, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 47 [0/798 (0%)]\tLoss: 0.229848\n",
      "Train Epoch: 47 [100/798 (12%)]\tLoss: 0.269246\n",
      "Train Epoch: 47 [200/798 (25%)]\tLoss: 0.046750\n",
      "Train Epoch: 47 [300/798 (38%)]\tLoss: 0.003235\n",
      "Train Epoch: 47 [400/798 (50%)]\tLoss: 0.056727\n",
      "Train Epoch: 47 [500/798 (62%)]\tLoss: 0.177319\n",
      "Train Epoch: 47 [600/798 (75%)]\tLoss: 0.018933\n",
      "Train Epoch: 47 [700/798 (88%)]\tLoss: 0.148494\n",
      "\n",
      "Test set: Avg. loss: 0.0276, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 48 [0/798 (0%)]\tLoss: 0.296877\n",
      "Train Epoch: 48 [100/798 (12%)]\tLoss: 0.034909\n",
      "Train Epoch: 48 [200/798 (25%)]\tLoss: 0.287139\n",
      "Train Epoch: 48 [300/798 (38%)]\tLoss: 0.068848\n",
      "Train Epoch: 48 [400/798 (50%)]\tLoss: 0.002483\n",
      "Train Epoch: 48 [500/798 (62%)]\tLoss: 0.603426\n",
      "Train Epoch: 48 [600/798 (75%)]\tLoss: 0.232030\n",
      "Train Epoch: 48 [700/798 (88%)]\tLoss: 0.011707\n",
      "\n",
      "Test set: Avg. loss: 0.0275, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 49 [0/798 (0%)]\tLoss: 0.284504\n",
      "Train Epoch: 49 [100/798 (12%)]\tLoss: 0.138505\n",
      "Train Epoch: 49 [200/798 (25%)]\tLoss: 0.356276\n",
      "Train Epoch: 49 [300/798 (38%)]\tLoss: 0.157214\n",
      "Train Epoch: 49 [400/798 (50%)]\tLoss: 0.433350\n",
      "Train Epoch: 49 [500/798 (62%)]\tLoss: 0.050897\n",
      "Train Epoch: 49 [600/798 (75%)]\tLoss: 0.241094\n",
      "Train Epoch: 49 [700/798 (88%)]\tLoss: 0.118365\n",
      "\n",
      "Test set: Avg. loss: 0.0275, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 50 [0/798 (0%)]\tLoss: 0.143491\n",
      "Train Epoch: 50 [100/798 (12%)]\tLoss: 0.023225\n",
      "Train Epoch: 50 [200/798 (25%)]\tLoss: 0.162730\n",
      "Train Epoch: 50 [300/798 (38%)]\tLoss: 0.110861\n",
      "Train Epoch: 50 [400/798 (50%)]\tLoss: 0.021515\n",
      "Train Epoch: 50 [500/798 (62%)]\tLoss: 0.559257\n",
      "Train Epoch: 50 [600/798 (75%)]\tLoss: 0.133232\n",
      "Train Epoch: 50 [700/798 (88%)]\tLoss: 0.066017\n",
      "\n",
      "Test set: Avg. loss: 0.0259, Accuracy: 198/200 (99%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0259, Accuracy: 198/200 (99%)\n",
      "\n",
      "Running bootstrap experiment: 6\n",
      "Train Epoch: 1 [0/798 (0%)]\tLoss: 2.407048\n",
      "Train Epoch: 1 [100/798 (12%)]\tLoss: 2.425909\n",
      "Train Epoch: 1 [200/798 (25%)]\tLoss: 2.237304\n",
      "Train Epoch: 1 [300/798 (38%)]\tLoss: 2.387194\n",
      "Train Epoch: 1 [400/798 (50%)]\tLoss: 2.245982\n",
      "Train Epoch: 1 [500/798 (62%)]\tLoss: 2.341244\n",
      "Train Epoch: 1 [600/798 (75%)]\tLoss: 2.432429\n",
      "Train Epoch: 1 [700/798 (88%)]\tLoss: 2.350530\n",
      "\n",
      "Test set: Avg. loss: 2.2827, Accuracy: 23/200 (12%)\n",
      "\n",
      "Train Epoch: 2 [0/798 (0%)]\tLoss: 2.263469\n",
      "Train Epoch: 2 [100/798 (12%)]\tLoss: 2.335646\n",
      "Train Epoch: 2 [200/798 (25%)]\tLoss: 2.285817\n",
      "Train Epoch: 2 [300/798 (38%)]\tLoss: 2.271776\n",
      "Train Epoch: 2 [400/798 (50%)]\tLoss: 2.350356\n",
      "Train Epoch: 2 [500/798 (62%)]\tLoss: 2.289249\n",
      "Train Epoch: 2 [600/798 (75%)]\tLoss: 2.247838\n",
      "Train Epoch: 2 [700/798 (88%)]\tLoss: 2.331629\n",
      "\n",
      "Test set: Avg. loss: 2.2630, Accuracy: 51/200 (26%)\n",
      "\n",
      "Train Epoch: 3 [0/798 (0%)]\tLoss: 2.261257\n",
      "Train Epoch: 3 [100/798 (12%)]\tLoss: 2.204136\n",
      "Train Epoch: 3 [200/798 (25%)]\tLoss: 2.343341\n",
      "Train Epoch: 3 [300/798 (38%)]\tLoss: 2.356236\n",
      "Train Epoch: 3 [400/798 (50%)]\tLoss: 2.207850\n",
      "Train Epoch: 3 [500/798 (62%)]\tLoss: 2.234478\n",
      "Train Epoch: 3 [600/798 (75%)]\tLoss: 2.257297\n",
      "Train Epoch: 3 [700/798 (88%)]\tLoss: 2.260987\n",
      "\n",
      "Test set: Avg. loss: 2.2014, Accuracy: 75/200 (38%)\n",
      "\n",
      "Train Epoch: 4 [0/798 (0%)]\tLoss: 2.147627\n",
      "Train Epoch: 4 [100/798 (12%)]\tLoss: 2.301799\n",
      "Train Epoch: 4 [200/798 (25%)]\tLoss: 2.195452\n",
      "Train Epoch: 4 [300/798 (38%)]\tLoss: 2.325707\n",
      "Train Epoch: 4 [400/798 (50%)]\tLoss: 2.260966\n",
      "Train Epoch: 4 [500/798 (62%)]\tLoss: 2.190097\n",
      "Train Epoch: 4 [600/798 (75%)]\tLoss: 2.045078\n",
      "Train Epoch: 4 [700/798 (88%)]\tLoss: 2.270617\n",
      "\n",
      "Test set: Avg. loss: 2.1257, Accuracy: 56/200 (28%)\n",
      "\n",
      "Train Epoch: 5 [0/798 (0%)]\tLoss: 2.228234\n",
      "Train Epoch: 5 [100/798 (12%)]\tLoss: 1.959299\n",
      "Train Epoch: 5 [200/798 (25%)]\tLoss: 2.030750\n",
      "Train Epoch: 5 [300/798 (38%)]\tLoss: 2.044605\n",
      "Train Epoch: 5 [400/798 (50%)]\tLoss: 2.122987\n",
      "Train Epoch: 5 [500/798 (62%)]\tLoss: 1.862368\n",
      "Train Epoch: 5 [600/798 (75%)]\tLoss: 1.696775\n",
      "Train Epoch: 5 [700/798 (88%)]\tLoss: 2.019528\n",
      "\n",
      "Test set: Avg. loss: 1.7977, Accuracy: 105/200 (52%)\n",
      "\n",
      "Train Epoch: 6 [0/798 (0%)]\tLoss: 1.663439\n",
      "Train Epoch: 6 [100/798 (12%)]\tLoss: 1.995478\n",
      "Train Epoch: 6 [200/798 (25%)]\tLoss: 1.984482\n",
      "Train Epoch: 6 [300/798 (38%)]\tLoss: 1.692562\n",
      "Train Epoch: 6 [400/798 (50%)]\tLoss: 1.532856\n",
      "Train Epoch: 6 [500/798 (62%)]\tLoss: 1.790884\n",
      "Train Epoch: 6 [600/798 (75%)]\tLoss: 1.741848\n",
      "Train Epoch: 6 [700/798 (88%)]\tLoss: 1.529442\n",
      "\n",
      "Test set: Avg. loss: 1.4587, Accuracy: 123/200 (62%)\n",
      "\n",
      "Train Epoch: 7 [0/798 (0%)]\tLoss: 1.461152\n",
      "Train Epoch: 7 [100/798 (12%)]\tLoss: 1.145169\n",
      "Train Epoch: 7 [200/798 (25%)]\tLoss: 2.001350\n",
      "Train Epoch: 7 [300/798 (38%)]\tLoss: 1.053865\n",
      "Train Epoch: 7 [400/798 (50%)]\tLoss: 1.580430\n",
      "Train Epoch: 7 [500/798 (62%)]\tLoss: 1.312572\n",
      "Train Epoch: 7 [600/798 (75%)]\tLoss: 1.867343\n",
      "Train Epoch: 7 [700/798 (88%)]\tLoss: 0.909399\n",
      "\n",
      "Test set: Avg. loss: 1.2157, Accuracy: 165/200 (82%)\n",
      "\n",
      "Train Epoch: 8 [0/798 (0%)]\tLoss: 1.798965\n",
      "Train Epoch: 8 [100/798 (12%)]\tLoss: 1.529844\n",
      "Train Epoch: 8 [200/798 (25%)]\tLoss: 1.201315\n",
      "Train Epoch: 8 [300/798 (38%)]\tLoss: 1.326483\n",
      "Train Epoch: 8 [400/798 (50%)]\tLoss: 1.748223\n",
      "Train Epoch: 8 [500/798 (62%)]\tLoss: 1.444146\n",
      "Train Epoch: 8 [600/798 (75%)]\tLoss: 0.961048\n",
      "Train Epoch: 8 [700/798 (88%)]\tLoss: 1.599847\n",
      "\n",
      "Test set: Avg. loss: 0.9369, Accuracy: 182/200 (91%)\n",
      "\n",
      "Train Epoch: 9 [0/798 (0%)]\tLoss: 1.550298\n",
      "Train Epoch: 9 [100/798 (12%)]\tLoss: 1.450377\n",
      "Train Epoch: 9 [200/798 (25%)]\tLoss: 1.336458\n",
      "Train Epoch: 9 [300/798 (38%)]\tLoss: 1.184596\n",
      "Train Epoch: 9 [400/798 (50%)]\tLoss: 1.336883\n",
      "Train Epoch: 9 [500/798 (62%)]\tLoss: 1.339350\n",
      "Train Epoch: 9 [600/798 (75%)]\tLoss: 1.031529\n",
      "Train Epoch: 9 [700/798 (88%)]\tLoss: 1.255520\n",
      "\n",
      "Test set: Avg. loss: 0.6192, Accuracy: 187/200 (94%)\n",
      "\n",
      "Train Epoch: 10 [0/798 (0%)]\tLoss: 1.115322\n",
      "Train Epoch: 10 [100/798 (12%)]\tLoss: 1.243348\n",
      "Train Epoch: 10 [200/798 (25%)]\tLoss: 1.107675\n",
      "Train Epoch: 10 [300/798 (38%)]\tLoss: 0.906024\n",
      "Train Epoch: 10 [400/798 (50%)]\tLoss: 0.902070\n",
      "Train Epoch: 10 [500/798 (62%)]\tLoss: 1.184826\n",
      "Train Epoch: 10 [600/798 (75%)]\tLoss: 1.112199\n",
      "Train Epoch: 10 [700/798 (88%)]\tLoss: 0.349648\n",
      "\n",
      "Test set: Avg. loss: 0.4965, Accuracy: 187/200 (94%)\n",
      "\n",
      "Train Epoch: 11 [0/798 (0%)]\tLoss: 1.164489\n",
      "Train Epoch: 11 [100/798 (12%)]\tLoss: 0.729964\n",
      "Train Epoch: 11 [200/798 (25%)]\tLoss: 0.702535\n",
      "Train Epoch: 11 [300/798 (38%)]\tLoss: 1.568844\n",
      "Train Epoch: 11 [400/798 (50%)]\tLoss: 1.092959\n",
      "Train Epoch: 11 [500/798 (62%)]\tLoss: 0.537979\n",
      "Train Epoch: 11 [600/798 (75%)]\tLoss: 1.721396\n",
      "Train Epoch: 11 [700/798 (88%)]\tLoss: 1.367633\n",
      "\n",
      "Test set: Avg. loss: 0.3751, Accuracy: 192/200 (96%)\n",
      "\n",
      "Train Epoch: 12 [0/798 (0%)]\tLoss: 0.782958\n",
      "Train Epoch: 12 [100/798 (12%)]\tLoss: 0.701162\n",
      "Train Epoch: 12 [200/798 (25%)]\tLoss: 0.605631\n",
      "Train Epoch: 12 [300/798 (38%)]\tLoss: 0.227444\n",
      "Train Epoch: 12 [400/798 (50%)]\tLoss: 0.977936\n",
      "Train Epoch: 12 [500/798 (62%)]\tLoss: 0.736475\n",
      "Train Epoch: 12 [600/798 (75%)]\tLoss: 1.107866\n",
      "Train Epoch: 12 [700/798 (88%)]\tLoss: 1.299366\n",
      "\n",
      "Test set: Avg. loss: 0.3325, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/798 (0%)]\tLoss: 0.855643\n",
      "Train Epoch: 13 [100/798 (12%)]\tLoss: 0.574461\n",
      "Train Epoch: 13 [200/798 (25%)]\tLoss: 1.051505\n",
      "Train Epoch: 13 [300/798 (38%)]\tLoss: 1.094260\n",
      "Train Epoch: 13 [400/798 (50%)]\tLoss: 0.776604\n",
      "Train Epoch: 13 [500/798 (62%)]\tLoss: 1.137501\n",
      "Train Epoch: 13 [600/798 (75%)]\tLoss: 0.386002\n",
      "Train Epoch: 13 [700/798 (88%)]\tLoss: 1.065632\n",
      "\n",
      "Test set: Avg. loss: 0.2595, Accuracy: 193/200 (96%)\n",
      "\n",
      "Train Epoch: 14 [0/798 (0%)]\tLoss: 0.909288\n",
      "Train Epoch: 14 [100/798 (12%)]\tLoss: 0.546339\n",
      "Train Epoch: 14 [200/798 (25%)]\tLoss: 0.718050\n",
      "Train Epoch: 14 [300/798 (38%)]\tLoss: 0.677964\n",
      "Train Epoch: 14 [400/798 (50%)]\tLoss: 0.670894\n",
      "Train Epoch: 14 [500/798 (62%)]\tLoss: 0.227831\n",
      "Train Epoch: 14 [600/798 (75%)]\tLoss: 0.837163\n",
      "Train Epoch: 14 [700/798 (88%)]\tLoss: 0.890354\n",
      "\n",
      "Test set: Avg. loss: 0.2098, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/798 (0%)]\tLoss: 0.546752\n",
      "Train Epoch: 15 [100/798 (12%)]\tLoss: 1.012937\n",
      "Train Epoch: 15 [200/798 (25%)]\tLoss: 0.854262\n",
      "Train Epoch: 15 [300/798 (38%)]\tLoss: 0.586854\n",
      "Train Epoch: 15 [400/798 (50%)]\tLoss: 0.560042\n",
      "Train Epoch: 15 [500/798 (62%)]\tLoss: 0.309034\n",
      "Train Epoch: 15 [600/798 (75%)]\tLoss: 0.759980\n",
      "Train Epoch: 15 [700/798 (88%)]\tLoss: 0.663688\n",
      "\n",
      "Test set: Avg. loss: 0.2050, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/798 (0%)]\tLoss: 0.713437\n",
      "Train Epoch: 16 [100/798 (12%)]\tLoss: 0.625193\n",
      "Train Epoch: 16 [200/798 (25%)]\tLoss: 1.090578\n",
      "Train Epoch: 16 [300/798 (38%)]\tLoss: 0.539565\n",
      "Train Epoch: 16 [400/798 (50%)]\tLoss: 0.701964\n",
      "Train Epoch: 16 [500/798 (62%)]\tLoss: 0.311084\n",
      "Train Epoch: 16 [600/798 (75%)]\tLoss: 0.452070\n",
      "Train Epoch: 16 [700/798 (88%)]\tLoss: 1.241346\n",
      "\n",
      "Test set: Avg. loss: 0.1632, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/798 (0%)]\tLoss: 0.461044\n",
      "Train Epoch: 17 [100/798 (12%)]\tLoss: 0.638231\n",
      "Train Epoch: 17 [200/798 (25%)]\tLoss: 0.513715\n",
      "Train Epoch: 17 [300/798 (38%)]\tLoss: 0.833008\n",
      "Train Epoch: 17 [400/798 (50%)]\tLoss: 0.728804\n",
      "Train Epoch: 17 [500/798 (62%)]\tLoss: 0.457021\n",
      "Train Epoch: 17 [600/798 (75%)]\tLoss: 0.721738\n",
      "Train Epoch: 17 [700/798 (88%)]\tLoss: 0.629024\n",
      "\n",
      "Test set: Avg. loss: 0.1718, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/798 (0%)]\tLoss: 0.408702\n",
      "Train Epoch: 18 [100/798 (12%)]\tLoss: 0.530305\n",
      "Train Epoch: 18 [200/798 (25%)]\tLoss: 0.731984\n",
      "Train Epoch: 18 [300/798 (38%)]\tLoss: 0.753873\n",
      "Train Epoch: 18 [400/798 (50%)]\tLoss: 0.470551\n",
      "Train Epoch: 18 [500/798 (62%)]\tLoss: 0.927859\n",
      "Train Epoch: 18 [600/798 (75%)]\tLoss: 0.897723\n",
      "Train Epoch: 18 [700/798 (88%)]\tLoss: 0.738528\n",
      "\n",
      "Test set: Avg. loss: 0.1504, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/798 (0%)]\tLoss: 0.862834\n",
      "Train Epoch: 19 [100/798 (12%)]\tLoss: 0.177111\n",
      "Train Epoch: 19 [200/798 (25%)]\tLoss: 0.474353\n",
      "Train Epoch: 19 [300/798 (38%)]\tLoss: 0.381645\n",
      "Train Epoch: 19 [400/798 (50%)]\tLoss: 0.397544\n",
      "Train Epoch: 19 [500/798 (62%)]\tLoss: 0.265463\n",
      "Train Epoch: 19 [600/798 (75%)]\tLoss: 0.632362\n",
      "Train Epoch: 19 [700/798 (88%)]\tLoss: 0.819052\n",
      "\n",
      "Test set: Avg. loss: 0.1627, Accuracy: 192/200 (96%)\n",
      "\n",
      "Train Epoch: 20 [0/798 (0%)]\tLoss: 0.347441\n",
      "Train Epoch: 20 [100/798 (12%)]\tLoss: 0.611684\n",
      "Train Epoch: 20 [200/798 (25%)]\tLoss: 0.514996\n",
      "Train Epoch: 20 [300/798 (38%)]\tLoss: 0.723379\n",
      "Train Epoch: 20 [400/798 (50%)]\tLoss: 0.491379\n",
      "Train Epoch: 20 [500/798 (62%)]\tLoss: 0.563503\n",
      "Train Epoch: 20 [600/798 (75%)]\tLoss: 0.698690\n",
      "Train Epoch: 20 [700/798 (88%)]\tLoss: 0.642673\n",
      "\n",
      "Test set: Avg. loss: 0.1369, Accuracy: 190/200 (95%)\n",
      "\n",
      "Train Epoch: 21 [0/798 (0%)]\tLoss: 0.706110\n",
      "Train Epoch: 21 [100/798 (12%)]\tLoss: 0.509928\n",
      "Train Epoch: 21 [200/798 (25%)]\tLoss: 0.848023\n",
      "Train Epoch: 21 [300/798 (38%)]\tLoss: 0.541677\n",
      "Train Epoch: 21 [400/798 (50%)]\tLoss: 0.476235\n",
      "Train Epoch: 21 [500/798 (62%)]\tLoss: 0.522840\n",
      "Train Epoch: 21 [600/798 (75%)]\tLoss: 0.616355\n",
      "Train Epoch: 21 [700/798 (88%)]\tLoss: 0.043299\n",
      "\n",
      "Test set: Avg. loss: 0.1050, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/798 (0%)]\tLoss: 0.117730\n",
      "Train Epoch: 22 [100/798 (12%)]\tLoss: 0.836038\n",
      "Train Epoch: 22 [200/798 (25%)]\tLoss: 0.413184\n",
      "Train Epoch: 22 [300/798 (38%)]\tLoss: 0.848225\n",
      "Train Epoch: 22 [400/798 (50%)]\tLoss: 0.605919\n",
      "Train Epoch: 22 [500/798 (62%)]\tLoss: 0.424972\n",
      "Train Epoch: 22 [600/798 (75%)]\tLoss: 0.308438\n",
      "Train Epoch: 22 [700/798 (88%)]\tLoss: 0.758551\n",
      "\n",
      "Test set: Avg. loss: 0.0905, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 23 [0/798 (0%)]\tLoss: 0.626954\n",
      "Train Epoch: 23 [100/798 (12%)]\tLoss: 0.150806\n",
      "Train Epoch: 23 [200/798 (25%)]\tLoss: 0.585200\n",
      "Train Epoch: 23 [300/798 (38%)]\tLoss: 0.255532\n",
      "Train Epoch: 23 [400/798 (50%)]\tLoss: 0.184833\n",
      "Train Epoch: 23 [500/798 (62%)]\tLoss: 0.341379\n",
      "Train Epoch: 23 [600/798 (75%)]\tLoss: 0.477877\n",
      "Train Epoch: 23 [700/798 (88%)]\tLoss: 0.441109\n",
      "\n",
      "Test set: Avg. loss: 0.0930, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/798 (0%)]\tLoss: 0.541618\n",
      "Train Epoch: 24 [100/798 (12%)]\tLoss: 0.820471\n",
      "Train Epoch: 24 [200/798 (25%)]\tLoss: 0.155787\n",
      "Train Epoch: 24 [300/798 (38%)]\tLoss: 0.233800\n",
      "Train Epoch: 24 [400/798 (50%)]\tLoss: 0.501717\n",
      "Train Epoch: 24 [500/798 (62%)]\tLoss: 0.299346\n",
      "Train Epoch: 24 [600/798 (75%)]\tLoss: 0.275535\n",
      "Train Epoch: 24 [700/798 (88%)]\tLoss: 0.279770\n",
      "\n",
      "Test set: Avg. loss: 0.0848, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/798 (0%)]\tLoss: 0.959762\n",
      "Train Epoch: 25 [100/798 (12%)]\tLoss: 0.176880\n",
      "Train Epoch: 25 [200/798 (25%)]\tLoss: 0.551747\n",
      "Train Epoch: 25 [300/798 (38%)]\tLoss: 0.615230\n",
      "Train Epoch: 25 [400/798 (50%)]\tLoss: 0.314291\n",
      "Train Epoch: 25 [500/798 (62%)]\tLoss: 0.188032\n",
      "Train Epoch: 25 [600/798 (75%)]\tLoss: 0.487318\n",
      "Train Epoch: 25 [700/798 (88%)]\tLoss: 0.401172\n",
      "\n",
      "Test set: Avg. loss: 0.1142, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/798 (0%)]\tLoss: 0.308149\n",
      "Train Epoch: 26 [100/798 (12%)]\tLoss: 0.749523\n",
      "Train Epoch: 26 [200/798 (25%)]\tLoss: 0.367555\n",
      "Train Epoch: 26 [300/798 (38%)]\tLoss: 0.481270\n",
      "Train Epoch: 26 [400/798 (50%)]\tLoss: 0.090936\n",
      "Train Epoch: 26 [500/798 (62%)]\tLoss: 0.191271\n",
      "Train Epoch: 26 [600/798 (75%)]\tLoss: 0.798682\n",
      "Train Epoch: 26 [700/798 (88%)]\tLoss: 0.289055\n",
      "\n",
      "Test set: Avg. loss: 0.0660, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 27 [0/798 (0%)]\tLoss: 0.476208\n",
      "Train Epoch: 27 [100/798 (12%)]\tLoss: 0.936098\n",
      "Train Epoch: 27 [200/798 (25%)]\tLoss: 0.776430\n",
      "Train Epoch: 27 [300/798 (38%)]\tLoss: 0.281702\n",
      "Train Epoch: 27 [400/798 (50%)]\tLoss: 0.449734\n",
      "Train Epoch: 27 [500/798 (62%)]\tLoss: 0.125445\n",
      "Train Epoch: 27 [600/798 (75%)]\tLoss: 0.708783\n",
      "Train Epoch: 27 [700/798 (88%)]\tLoss: 0.593637\n",
      "\n",
      "Test set: Avg. loss: 0.0597, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/798 (0%)]\tLoss: 0.313169\n",
      "Train Epoch: 28 [100/798 (12%)]\tLoss: 0.254138\n",
      "Train Epoch: 28 [200/798 (25%)]\tLoss: 0.246372\n",
      "Train Epoch: 28 [300/798 (38%)]\tLoss: 0.317993\n",
      "Train Epoch: 28 [400/798 (50%)]\tLoss: 0.109145\n",
      "Train Epoch: 28 [500/798 (62%)]\tLoss: 0.173800\n",
      "Train Epoch: 28 [600/798 (75%)]\tLoss: 0.277147\n",
      "Train Epoch: 28 [700/798 (88%)]\tLoss: 0.326835\n",
      "\n",
      "Test set: Avg. loss: 0.0579, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/798 (0%)]\tLoss: 0.486412\n",
      "Train Epoch: 29 [100/798 (12%)]\tLoss: 0.269706\n",
      "Train Epoch: 29 [200/798 (25%)]\tLoss: 0.568515\n",
      "Train Epoch: 29 [300/798 (38%)]\tLoss: 0.044543\n",
      "Train Epoch: 29 [400/798 (50%)]\tLoss: 0.403975\n",
      "Train Epoch: 29 [500/798 (62%)]\tLoss: 0.225451\n",
      "Train Epoch: 29 [600/798 (75%)]\tLoss: 0.147113\n",
      "Train Epoch: 29 [700/798 (88%)]\tLoss: 0.701929\n",
      "\n",
      "Test set: Avg. loss: 0.0496, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 30 [0/798 (0%)]\tLoss: 0.132584\n",
      "Train Epoch: 30 [100/798 (12%)]\tLoss: 0.334291\n",
      "Train Epoch: 30 [200/798 (25%)]\tLoss: 0.128870\n",
      "Train Epoch: 30 [300/798 (38%)]\tLoss: 0.342512\n",
      "Train Epoch: 30 [400/798 (50%)]\tLoss: 0.098081\n",
      "Train Epoch: 30 [500/798 (62%)]\tLoss: 0.574076\n",
      "Train Epoch: 30 [600/798 (75%)]\tLoss: 0.159335\n",
      "Train Epoch: 30 [700/798 (88%)]\tLoss: 0.614972\n",
      "\n",
      "Test set: Avg. loss: 0.0494, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/798 (0%)]\tLoss: 0.630522\n",
      "Train Epoch: 31 [100/798 (12%)]\tLoss: 0.451924\n",
      "Train Epoch: 31 [200/798 (25%)]\tLoss: 0.460131\n",
      "Train Epoch: 31 [300/798 (38%)]\tLoss: 0.252513\n",
      "Train Epoch: 31 [400/798 (50%)]\tLoss: 0.254254\n",
      "Train Epoch: 31 [500/798 (62%)]\tLoss: 0.105714\n",
      "Train Epoch: 31 [600/798 (75%)]\tLoss: 0.190144\n",
      "Train Epoch: 31 [700/798 (88%)]\tLoss: 0.514578\n",
      "\n",
      "Test set: Avg. loss: 0.0561, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 32 [0/798 (0%)]\tLoss: 0.544784\n",
      "Train Epoch: 32 [100/798 (12%)]\tLoss: 0.235013\n",
      "Train Epoch: 32 [200/798 (25%)]\tLoss: 0.326019\n",
      "Train Epoch: 32 [300/798 (38%)]\tLoss: 0.666615\n",
      "Train Epoch: 32 [400/798 (50%)]\tLoss: 0.106483\n",
      "Train Epoch: 32 [500/798 (62%)]\tLoss: 0.250350\n",
      "Train Epoch: 32 [600/798 (75%)]\tLoss: 0.008655\n",
      "Train Epoch: 32 [700/798 (88%)]\tLoss: 1.074706\n",
      "\n",
      "Test set: Avg. loss: 0.0703, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 33 [0/798 (0%)]\tLoss: 0.152238\n",
      "Train Epoch: 33 [100/798 (12%)]\tLoss: 0.286462\n",
      "Train Epoch: 33 [200/798 (25%)]\tLoss: 0.348987\n",
      "Train Epoch: 33 [300/798 (38%)]\tLoss: 0.251632\n",
      "Train Epoch: 33 [400/798 (50%)]\tLoss: 0.487559\n",
      "Train Epoch: 33 [500/798 (62%)]\tLoss: 0.456521\n",
      "Train Epoch: 33 [600/798 (75%)]\tLoss: 0.194775\n",
      "Train Epoch: 33 [700/798 (88%)]\tLoss: 0.337473\n",
      "\n",
      "Test set: Avg. loss: 0.0562, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/798 (0%)]\tLoss: 0.096566\n",
      "Train Epoch: 34 [100/798 (12%)]\tLoss: 0.554825\n",
      "Train Epoch: 34 [200/798 (25%)]\tLoss: 0.066097\n",
      "Train Epoch: 34 [300/798 (38%)]\tLoss: 0.240854\n",
      "Train Epoch: 34 [400/798 (50%)]\tLoss: 0.429124\n",
      "Train Epoch: 34 [500/798 (62%)]\tLoss: 0.172186\n",
      "Train Epoch: 34 [600/798 (75%)]\tLoss: 0.686058\n",
      "Train Epoch: 34 [700/798 (88%)]\tLoss: 0.617060\n",
      "\n",
      "Test set: Avg. loss: 0.0665, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 35 [0/798 (0%)]\tLoss: 0.125492\n",
      "Train Epoch: 35 [100/798 (12%)]\tLoss: 0.458145\n",
      "Train Epoch: 35 [200/798 (25%)]\tLoss: 0.349132\n",
      "Train Epoch: 35 [300/798 (38%)]\tLoss: 0.301328\n",
      "Train Epoch: 35 [400/798 (50%)]\tLoss: 1.298061\n",
      "Train Epoch: 35 [500/798 (62%)]\tLoss: 0.057914\n",
      "Train Epoch: 35 [600/798 (75%)]\tLoss: 0.266006\n",
      "Train Epoch: 35 [700/798 (88%)]\tLoss: 0.671017\n",
      "\n",
      "Test set: Avg. loss: 0.0711, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 36 [0/798 (0%)]\tLoss: 0.878079\n",
      "Train Epoch: 36 [100/798 (12%)]\tLoss: 0.448813\n",
      "Train Epoch: 36 [200/798 (25%)]\tLoss: 0.272308\n",
      "Train Epoch: 36 [300/798 (38%)]\tLoss: 0.104139\n",
      "Train Epoch: 36 [400/798 (50%)]\tLoss: 0.522437\n",
      "Train Epoch: 36 [500/798 (62%)]\tLoss: 0.396977\n",
      "Train Epoch: 36 [600/798 (75%)]\tLoss: 0.188841\n",
      "Train Epoch: 36 [700/798 (88%)]\tLoss: 0.184503\n",
      "\n",
      "Test set: Avg. loss: 0.0541, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 37 [0/798 (0%)]\tLoss: 0.772182\n",
      "Train Epoch: 37 [100/798 (12%)]\tLoss: 0.415552\n",
      "Train Epoch: 37 [200/798 (25%)]\tLoss: 0.017863\n",
      "Train Epoch: 37 [300/798 (38%)]\tLoss: 0.150617\n",
      "Train Epoch: 37 [400/798 (50%)]\tLoss: 0.197053\n",
      "Train Epoch: 37 [500/798 (62%)]\tLoss: 0.228535\n",
      "Train Epoch: 37 [600/798 (75%)]\tLoss: 0.186237\n",
      "Train Epoch: 37 [700/798 (88%)]\tLoss: 0.319096\n",
      "\n",
      "Test set: Avg. loss: 0.0479, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 38 [0/798 (0%)]\tLoss: 0.079724\n",
      "Train Epoch: 38 [100/798 (12%)]\tLoss: 0.519597\n",
      "Train Epoch: 38 [200/798 (25%)]\tLoss: 0.414310\n",
      "Train Epoch: 38 [300/798 (38%)]\tLoss: 0.749708\n",
      "Train Epoch: 38 [400/798 (50%)]\tLoss: 0.142894\n",
      "Train Epoch: 38 [500/798 (62%)]\tLoss: 0.133770\n",
      "Train Epoch: 38 [600/798 (75%)]\tLoss: 0.083331\n",
      "Train Epoch: 38 [700/798 (88%)]\tLoss: 0.550844\n",
      "\n",
      "Test set: Avg. loss: 0.0577, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 39 [0/798 (0%)]\tLoss: 0.320217\n",
      "Train Epoch: 39 [100/798 (12%)]\tLoss: 0.238695\n",
      "Train Epoch: 39 [200/798 (25%)]\tLoss: 0.256664\n",
      "Train Epoch: 39 [300/798 (38%)]\tLoss: 0.283294\n",
      "Train Epoch: 39 [400/798 (50%)]\tLoss: 0.090051\n",
      "Train Epoch: 39 [500/798 (62%)]\tLoss: 0.092432\n",
      "Train Epoch: 39 [600/798 (75%)]\tLoss: 0.506616\n",
      "Train Epoch: 39 [700/798 (88%)]\tLoss: 0.243441\n",
      "\n",
      "Test set: Avg. loss: 0.0490, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 40 [0/798 (0%)]\tLoss: 0.031636\n",
      "Train Epoch: 40 [100/798 (12%)]\tLoss: 1.164680\n",
      "Train Epoch: 40 [200/798 (25%)]\tLoss: 0.344202\n",
      "Train Epoch: 40 [300/798 (38%)]\tLoss: 0.355391\n",
      "Train Epoch: 40 [400/798 (50%)]\tLoss: 0.161277\n",
      "Train Epoch: 40 [500/798 (62%)]\tLoss: 0.347512\n",
      "Train Epoch: 40 [600/798 (75%)]\tLoss: 0.417770\n",
      "Train Epoch: 40 [700/798 (88%)]\tLoss: 0.610538\n",
      "\n",
      "Test set: Avg. loss: 0.0488, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 41 [0/798 (0%)]\tLoss: 0.848138\n",
      "Train Epoch: 41 [100/798 (12%)]\tLoss: 0.254080\n",
      "Train Epoch: 41 [200/798 (25%)]\tLoss: 0.442319\n",
      "Train Epoch: 41 [300/798 (38%)]\tLoss: 0.454584\n",
      "Train Epoch: 41 [400/798 (50%)]\tLoss: 0.040472\n",
      "Train Epoch: 41 [500/798 (62%)]\tLoss: 1.021503\n",
      "Train Epoch: 41 [600/798 (75%)]\tLoss: 0.046007\n",
      "Train Epoch: 41 [700/798 (88%)]\tLoss: 0.245483\n",
      "\n",
      "Test set: Avg. loss: 0.0538, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 42 [0/798 (0%)]\tLoss: 0.361310\n",
      "Train Epoch: 42 [100/798 (12%)]\tLoss: 0.434918\n",
      "Train Epoch: 42 [200/798 (25%)]\tLoss: 0.445094\n",
      "Train Epoch: 42 [300/798 (38%)]\tLoss: 0.146512\n",
      "Train Epoch: 42 [400/798 (50%)]\tLoss: 0.103202\n",
      "Train Epoch: 42 [500/798 (62%)]\tLoss: 0.326954\n",
      "Train Epoch: 42 [600/798 (75%)]\tLoss: 0.451510\n",
      "Train Epoch: 42 [700/798 (88%)]\tLoss: 0.253713\n",
      "\n",
      "Test set: Avg. loss: 0.0385, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 43 [0/798 (0%)]\tLoss: 0.098109\n",
      "Train Epoch: 43 [100/798 (12%)]\tLoss: 0.388185\n",
      "Train Epoch: 43 [200/798 (25%)]\tLoss: 0.539449\n",
      "Train Epoch: 43 [300/798 (38%)]\tLoss: 0.210469\n",
      "Train Epoch: 43 [400/798 (50%)]\tLoss: 0.214149\n",
      "Train Epoch: 43 [500/798 (62%)]\tLoss: 0.037171\n",
      "Train Epoch: 43 [600/798 (75%)]\tLoss: 0.118960\n",
      "Train Epoch: 43 [700/798 (88%)]\tLoss: 0.061233\n",
      "\n",
      "Test set: Avg. loss: 0.0379, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 44 [0/798 (0%)]\tLoss: 0.193662\n",
      "Train Epoch: 44 [100/798 (12%)]\tLoss: 0.480310\n",
      "Train Epoch: 44 [200/798 (25%)]\tLoss: 0.016849\n",
      "Train Epoch: 44 [300/798 (38%)]\tLoss: 0.250567\n",
      "Train Epoch: 44 [400/798 (50%)]\tLoss: 0.283421\n",
      "Train Epoch: 44 [500/798 (62%)]\tLoss: 0.166647\n",
      "Train Epoch: 44 [600/798 (75%)]\tLoss: 0.093749\n",
      "Train Epoch: 44 [700/798 (88%)]\tLoss: 0.102725\n",
      "\n",
      "Test set: Avg. loss: 0.0357, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 45 [0/798 (0%)]\tLoss: 0.259606\n",
      "Train Epoch: 45 [100/798 (12%)]\tLoss: 0.114041\n",
      "Train Epoch: 45 [200/798 (25%)]\tLoss: 0.889521\n",
      "Train Epoch: 45 [300/798 (38%)]\tLoss: 0.183747\n",
      "Train Epoch: 45 [400/798 (50%)]\tLoss: 0.058910\n",
      "Train Epoch: 45 [500/798 (62%)]\tLoss: 0.391101\n",
      "Train Epoch: 45 [600/798 (75%)]\tLoss: 0.511297\n",
      "Train Epoch: 45 [700/798 (88%)]\tLoss: 0.273630\n",
      "\n",
      "Test set: Avg. loss: 0.0257, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 46 [0/798 (0%)]\tLoss: 0.512415\n",
      "Train Epoch: 46 [100/798 (12%)]\tLoss: 0.439423\n",
      "Train Epoch: 46 [200/798 (25%)]\tLoss: 0.389491\n",
      "Train Epoch: 46 [300/798 (38%)]\tLoss: 0.158217\n",
      "Train Epoch: 46 [400/798 (50%)]\tLoss: 0.752563\n",
      "Train Epoch: 46 [500/798 (62%)]\tLoss: 0.806186\n",
      "Train Epoch: 46 [600/798 (75%)]\tLoss: 0.191850\n",
      "Train Epoch: 46 [700/798 (88%)]\tLoss: 0.388275\n",
      "\n",
      "Test set: Avg. loss: 0.0291, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 47 [0/798 (0%)]\tLoss: 0.090651\n",
      "Train Epoch: 47 [100/798 (12%)]\tLoss: 0.028031\n",
      "Train Epoch: 47 [200/798 (25%)]\tLoss: 0.159869\n",
      "Train Epoch: 47 [300/798 (38%)]\tLoss: 0.138904\n",
      "Train Epoch: 47 [400/798 (50%)]\tLoss: 0.155079\n",
      "Train Epoch: 47 [500/798 (62%)]\tLoss: 0.236225\n",
      "Train Epoch: 47 [600/798 (75%)]\tLoss: 0.214463\n",
      "Train Epoch: 47 [700/798 (88%)]\tLoss: 0.471960\n",
      "\n",
      "Test set: Avg. loss: 0.0290, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 48 [0/798 (0%)]\tLoss: 0.265264\n",
      "Train Epoch: 48 [100/798 (12%)]\tLoss: 0.255550\n",
      "Train Epoch: 48 [200/798 (25%)]\tLoss: 0.584905\n",
      "Train Epoch: 48 [300/798 (38%)]\tLoss: 0.073467\n",
      "Train Epoch: 48 [400/798 (50%)]\tLoss: 0.226477\n",
      "Train Epoch: 48 [500/798 (62%)]\tLoss: 0.007216\n",
      "Train Epoch: 48 [600/798 (75%)]\tLoss: 0.038250\n",
      "Train Epoch: 48 [700/798 (88%)]\tLoss: 0.186174\n",
      "\n",
      "Test set: Avg. loss: 0.0507, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 49 [0/798 (0%)]\tLoss: 0.016510\n",
      "Train Epoch: 49 [100/798 (12%)]\tLoss: 0.298605\n",
      "Train Epoch: 49 [200/798 (25%)]\tLoss: 0.099466\n",
      "Train Epoch: 49 [300/798 (38%)]\tLoss: 0.246121\n",
      "Train Epoch: 49 [400/798 (50%)]\tLoss: 0.071545\n",
      "Train Epoch: 49 [500/798 (62%)]\tLoss: 0.024593\n",
      "Train Epoch: 49 [600/798 (75%)]\tLoss: 0.007039\n",
      "Train Epoch: 49 [700/798 (88%)]\tLoss: 0.769982\n",
      "\n",
      "Test set: Avg. loss: 0.0554, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 50 [0/798 (0%)]\tLoss: 0.178899\n",
      "Train Epoch: 50 [100/798 (12%)]\tLoss: 0.207550\n",
      "Train Epoch: 50 [200/798 (25%)]\tLoss: 0.181465\n",
      "Train Epoch: 50 [300/798 (38%)]\tLoss: 0.374546\n",
      "Train Epoch: 50 [400/798 (50%)]\tLoss: 0.143132\n",
      "Train Epoch: 50 [500/798 (62%)]\tLoss: 0.202729\n",
      "Train Epoch: 50 [600/798 (75%)]\tLoss: 0.953364\n",
      "Train Epoch: 50 [700/798 (88%)]\tLoss: 0.070020\n",
      "\n",
      "Test set: Avg. loss: 0.0229, Accuracy: 199/200 (100%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0229, Accuracy: 199/200 (100%)\n",
      "\n",
      "Running bootstrap experiment: 7\n",
      "Train Epoch: 1 [0/798 (0%)]\tLoss: 2.367383\n",
      "Train Epoch: 1 [100/798 (12%)]\tLoss: 2.311649\n",
      "Train Epoch: 1 [200/798 (25%)]\tLoss: 2.209104\n",
      "Train Epoch: 1 [300/798 (38%)]\tLoss: 2.376721\n",
      "Train Epoch: 1 [400/798 (50%)]\tLoss: 2.280102\n",
      "Train Epoch: 1 [500/798 (62%)]\tLoss: 2.368994\n",
      "Train Epoch: 1 [600/798 (75%)]\tLoss: 2.322430\n",
      "Train Epoch: 1 [700/798 (88%)]\tLoss: 2.246381\n",
      "\n",
      "Test set: Avg. loss: 2.2947, Accuracy: 35/200 (18%)\n",
      "\n",
      "Train Epoch: 2 [0/798 (0%)]\tLoss: 2.289076\n",
      "Train Epoch: 2 [100/798 (12%)]\tLoss: 2.302592\n",
      "Train Epoch: 2 [200/798 (25%)]\tLoss: 2.303763\n",
      "Train Epoch: 2 [300/798 (38%)]\tLoss: 2.370255\n",
      "Train Epoch: 2 [400/798 (50%)]\tLoss: 2.240556\n",
      "Train Epoch: 2 [500/798 (62%)]\tLoss: 2.178131\n",
      "Train Epoch: 2 [600/798 (75%)]\tLoss: 2.259923\n",
      "Train Epoch: 2 [700/798 (88%)]\tLoss: 2.270457\n",
      "\n",
      "Test set: Avg. loss: 2.2585, Accuracy: 54/200 (27%)\n",
      "\n",
      "Train Epoch: 3 [0/798 (0%)]\tLoss: 2.307630\n",
      "Train Epoch: 3 [100/798 (12%)]\tLoss: 2.177865\n",
      "Train Epoch: 3 [200/798 (25%)]\tLoss: 2.175566\n",
      "Train Epoch: 3 [300/798 (38%)]\tLoss: 2.162241\n",
      "Train Epoch: 3 [400/798 (50%)]\tLoss: 2.242539\n",
      "Train Epoch: 3 [500/798 (62%)]\tLoss: 2.224426\n",
      "Train Epoch: 3 [600/798 (75%)]\tLoss: 2.268200\n",
      "Train Epoch: 3 [700/798 (88%)]\tLoss: 2.198898\n",
      "\n",
      "Test set: Avg. loss: 2.1650, Accuracy: 72/200 (36%)\n",
      "\n",
      "Train Epoch: 4 [0/798 (0%)]\tLoss: 2.251458\n",
      "Train Epoch: 4 [100/798 (12%)]\tLoss: 2.214360\n",
      "Train Epoch: 4 [200/798 (25%)]\tLoss: 2.197550\n",
      "Train Epoch: 4 [300/798 (38%)]\tLoss: 2.172783\n",
      "Train Epoch: 4 [400/798 (50%)]\tLoss: 2.176211\n",
      "Train Epoch: 4 [500/798 (62%)]\tLoss: 2.046744\n",
      "Train Epoch: 4 [600/798 (75%)]\tLoss: 2.171612\n",
      "Train Epoch: 4 [700/798 (88%)]\tLoss: 1.839768\n",
      "\n",
      "Test set: Avg. loss: 1.9647, Accuracy: 71/200 (36%)\n",
      "\n",
      "Train Epoch: 5 [0/798 (0%)]\tLoss: 1.989162\n",
      "Train Epoch: 5 [100/798 (12%)]\tLoss: 2.105358\n",
      "Train Epoch: 5 [200/798 (25%)]\tLoss: 1.570308\n",
      "Train Epoch: 5 [300/798 (38%)]\tLoss: 1.873667\n",
      "Train Epoch: 5 [400/798 (50%)]\tLoss: 1.662948\n",
      "Train Epoch: 5 [500/798 (62%)]\tLoss: 2.305623\n",
      "Train Epoch: 5 [600/798 (75%)]\tLoss: 1.794463\n",
      "Train Epoch: 5 [700/798 (88%)]\tLoss: 1.328378\n",
      "\n",
      "Test set: Avg. loss: 1.6581, Accuracy: 117/200 (58%)\n",
      "\n",
      "Train Epoch: 6 [0/798 (0%)]\tLoss: 1.740125\n",
      "Train Epoch: 6 [100/798 (12%)]\tLoss: 1.473987\n",
      "Train Epoch: 6 [200/798 (25%)]\tLoss: 1.279263\n",
      "Train Epoch: 6 [300/798 (38%)]\tLoss: 1.607626\n",
      "Train Epoch: 6 [400/798 (50%)]\tLoss: 1.514793\n",
      "Train Epoch: 6 [500/798 (62%)]\tLoss: 1.218545\n",
      "Train Epoch: 6 [600/798 (75%)]\tLoss: 2.184872\n",
      "Train Epoch: 6 [700/798 (88%)]\tLoss: 1.557884\n",
      "\n",
      "Test set: Avg. loss: 1.2681, Accuracy: 145/200 (72%)\n",
      "\n",
      "Train Epoch: 7 [0/798 (0%)]\tLoss: 1.438621\n",
      "Train Epoch: 7 [100/798 (12%)]\tLoss: 1.222303\n",
      "Train Epoch: 7 [200/798 (25%)]\tLoss: 2.003590\n",
      "Train Epoch: 7 [300/798 (38%)]\tLoss: 1.423178\n",
      "Train Epoch: 7 [400/798 (50%)]\tLoss: 1.558152\n",
      "Train Epoch: 7 [500/798 (62%)]\tLoss: 1.455643\n",
      "Train Epoch: 7 [600/798 (75%)]\tLoss: 1.379850\n",
      "Train Epoch: 7 [700/798 (88%)]\tLoss: 1.134081\n",
      "\n",
      "Test set: Avg. loss: 0.8357, Accuracy: 171/200 (86%)\n",
      "\n",
      "Train Epoch: 8 [0/798 (0%)]\tLoss: 1.383020\n",
      "Train Epoch: 8 [100/798 (12%)]\tLoss: 1.554712\n",
      "Train Epoch: 8 [200/798 (25%)]\tLoss: 0.843941\n",
      "Train Epoch: 8 [300/798 (38%)]\tLoss: 1.537426\n",
      "Train Epoch: 8 [400/798 (50%)]\tLoss: 1.446395\n",
      "Train Epoch: 8 [500/798 (62%)]\tLoss: 1.156320\n",
      "Train Epoch: 8 [600/798 (75%)]\tLoss: 1.111265\n",
      "Train Epoch: 8 [700/798 (88%)]\tLoss: 1.174165\n",
      "\n",
      "Test set: Avg. loss: 0.6042, Accuracy: 185/200 (92%)\n",
      "\n",
      "Train Epoch: 9 [0/798 (0%)]\tLoss: 1.077657\n",
      "Train Epoch: 9 [100/798 (12%)]\tLoss: 1.185036\n",
      "Train Epoch: 9 [200/798 (25%)]\tLoss: 0.823492\n",
      "Train Epoch: 9 [300/798 (38%)]\tLoss: 1.057449\n",
      "Train Epoch: 9 [400/798 (50%)]\tLoss: 1.115205\n",
      "Train Epoch: 9 [500/798 (62%)]\tLoss: 0.833125\n",
      "Train Epoch: 9 [600/798 (75%)]\tLoss: 1.722157\n",
      "Train Epoch: 9 [700/798 (88%)]\tLoss: 1.296365\n",
      "\n",
      "Test set: Avg. loss: 0.4852, Accuracy: 179/200 (90%)\n",
      "\n",
      "Train Epoch: 10 [0/798 (0%)]\tLoss: 0.785777\n",
      "Train Epoch: 10 [100/798 (12%)]\tLoss: 1.081334\n",
      "Train Epoch: 10 [200/798 (25%)]\tLoss: 1.064860\n",
      "Train Epoch: 10 [300/798 (38%)]\tLoss: 0.952839\n",
      "Train Epoch: 10 [400/798 (50%)]\tLoss: 0.647388\n",
      "Train Epoch: 10 [500/798 (62%)]\tLoss: 0.834770\n",
      "Train Epoch: 10 [600/798 (75%)]\tLoss: 0.892935\n",
      "Train Epoch: 10 [700/798 (88%)]\tLoss: 0.645509\n",
      "\n",
      "Test set: Avg. loss: 0.3227, Accuracy: 191/200 (96%)\n",
      "\n",
      "Train Epoch: 11 [0/798 (0%)]\tLoss: 0.556599\n",
      "Train Epoch: 11 [100/798 (12%)]\tLoss: 0.642320\n",
      "Train Epoch: 11 [200/798 (25%)]\tLoss: 0.899115\n",
      "Train Epoch: 11 [300/798 (38%)]\tLoss: 1.094574\n",
      "Train Epoch: 11 [400/798 (50%)]\tLoss: 1.147723\n",
      "Train Epoch: 11 [500/798 (62%)]\tLoss: 0.910240\n",
      "Train Epoch: 11 [600/798 (75%)]\tLoss: 0.760643\n",
      "Train Epoch: 11 [700/798 (88%)]\tLoss: 0.877492\n",
      "\n",
      "Test set: Avg. loss: 0.2669, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 12 [0/798 (0%)]\tLoss: 0.995876\n",
      "Train Epoch: 12 [100/798 (12%)]\tLoss: 0.669095\n",
      "Train Epoch: 12 [200/798 (25%)]\tLoss: 0.803306\n",
      "Train Epoch: 12 [300/798 (38%)]\tLoss: 0.564486\n",
      "Train Epoch: 12 [400/798 (50%)]\tLoss: 0.730203\n",
      "Train Epoch: 12 [500/798 (62%)]\tLoss: 0.582718\n",
      "Train Epoch: 12 [600/798 (75%)]\tLoss: 0.416773\n",
      "Train Epoch: 12 [700/798 (88%)]\tLoss: 0.857000\n",
      "\n",
      "Test set: Avg. loss: 0.2255, Accuracy: 192/200 (96%)\n",
      "\n",
      "Train Epoch: 13 [0/798 (0%)]\tLoss: 0.853490\n",
      "Train Epoch: 13 [100/798 (12%)]\tLoss: 0.524647\n",
      "Train Epoch: 13 [200/798 (25%)]\tLoss: 0.815793\n",
      "Train Epoch: 13 [300/798 (38%)]\tLoss: 0.329979\n",
      "Train Epoch: 13 [400/798 (50%)]\tLoss: 0.695128\n",
      "Train Epoch: 13 [500/798 (62%)]\tLoss: 0.445001\n",
      "Train Epoch: 13 [600/798 (75%)]\tLoss: 0.465801\n",
      "Train Epoch: 13 [700/798 (88%)]\tLoss: 0.469322\n",
      "\n",
      "Test set: Avg. loss: 0.2166, Accuracy: 192/200 (96%)\n",
      "\n",
      "Train Epoch: 14 [0/798 (0%)]\tLoss: 0.954439\n",
      "Train Epoch: 14 [100/798 (12%)]\tLoss: 0.236643\n",
      "Train Epoch: 14 [200/798 (25%)]\tLoss: 0.376644\n",
      "Train Epoch: 14 [300/798 (38%)]\tLoss: 0.648510\n",
      "Train Epoch: 14 [400/798 (50%)]\tLoss: 0.623015\n",
      "Train Epoch: 14 [500/798 (62%)]\tLoss: 0.618739\n",
      "Train Epoch: 14 [600/798 (75%)]\tLoss: 0.405191\n",
      "Train Epoch: 14 [700/798 (88%)]\tLoss: 0.480584\n",
      "\n",
      "Test set: Avg. loss: 0.1390, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 15 [0/798 (0%)]\tLoss: 0.318806\n",
      "Train Epoch: 15 [100/798 (12%)]\tLoss: 0.246705\n",
      "Train Epoch: 15 [200/798 (25%)]\tLoss: 0.734024\n",
      "Train Epoch: 15 [300/798 (38%)]\tLoss: 0.309428\n",
      "Train Epoch: 15 [400/798 (50%)]\tLoss: 0.491059\n",
      "Train Epoch: 15 [500/798 (62%)]\tLoss: 0.786695\n",
      "Train Epoch: 15 [600/798 (75%)]\tLoss: 0.294686\n",
      "Train Epoch: 15 [700/798 (88%)]\tLoss: 0.334793\n",
      "\n",
      "Test set: Avg. loss: 0.1843, Accuracy: 189/200 (94%)\n",
      "\n",
      "Train Epoch: 16 [0/798 (0%)]\tLoss: 1.142111\n",
      "Train Epoch: 16 [100/798 (12%)]\tLoss: 0.388429\n",
      "Train Epoch: 16 [200/798 (25%)]\tLoss: 0.359767\n",
      "Train Epoch: 16 [300/798 (38%)]\tLoss: 0.463149\n",
      "Train Epoch: 16 [400/798 (50%)]\tLoss: 1.267033\n",
      "Train Epoch: 16 [500/798 (62%)]\tLoss: 0.525858\n",
      "Train Epoch: 16 [600/798 (75%)]\tLoss: 0.419129\n",
      "Train Epoch: 16 [700/798 (88%)]\tLoss: 0.938900\n",
      "\n",
      "Test set: Avg. loss: 0.1195, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 17 [0/798 (0%)]\tLoss: 0.614890\n",
      "Train Epoch: 17 [100/798 (12%)]\tLoss: 0.679228\n",
      "Train Epoch: 17 [200/798 (25%)]\tLoss: 0.119135\n",
      "Train Epoch: 17 [300/798 (38%)]\tLoss: 0.517120\n",
      "Train Epoch: 17 [400/798 (50%)]\tLoss: 0.762282\n",
      "Train Epoch: 17 [500/798 (62%)]\tLoss: 0.786780\n",
      "Train Epoch: 17 [600/798 (75%)]\tLoss: 0.184033\n",
      "Train Epoch: 17 [700/798 (88%)]\tLoss: 0.432910\n",
      "\n",
      "Test set: Avg. loss: 0.1276, Accuracy: 192/200 (96%)\n",
      "\n",
      "Train Epoch: 18 [0/798 (0%)]\tLoss: 0.480150\n",
      "Train Epoch: 18 [100/798 (12%)]\tLoss: 0.370713\n",
      "Train Epoch: 18 [200/798 (25%)]\tLoss: 0.543779\n",
      "Train Epoch: 18 [300/798 (38%)]\tLoss: 0.482113\n",
      "Train Epoch: 18 [400/798 (50%)]\tLoss: 0.139345\n",
      "Train Epoch: 18 [500/798 (62%)]\tLoss: 1.263751\n",
      "Train Epoch: 18 [600/798 (75%)]\tLoss: 0.931553\n",
      "Train Epoch: 18 [700/798 (88%)]\tLoss: 0.305393\n",
      "\n",
      "Test set: Avg. loss: 0.0773, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/798 (0%)]\tLoss: 0.280912\n",
      "Train Epoch: 19 [100/798 (12%)]\tLoss: 0.325715\n",
      "Train Epoch: 19 [200/798 (25%)]\tLoss: 0.166625\n",
      "Train Epoch: 19 [300/798 (38%)]\tLoss: 0.356750\n",
      "Train Epoch: 19 [400/798 (50%)]\tLoss: 0.460948\n",
      "Train Epoch: 19 [500/798 (62%)]\tLoss: 0.581857\n",
      "Train Epoch: 19 [600/798 (75%)]\tLoss: 0.636940\n",
      "Train Epoch: 19 [700/798 (88%)]\tLoss: 0.328212\n",
      "\n",
      "Test set: Avg. loss: 0.0966, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 20 [0/798 (0%)]\tLoss: 0.652117\n",
      "Train Epoch: 20 [100/798 (12%)]\tLoss: 0.208066\n",
      "Train Epoch: 20 [200/798 (25%)]\tLoss: 0.516230\n",
      "Train Epoch: 20 [300/798 (38%)]\tLoss: 0.039071\n",
      "Train Epoch: 20 [400/798 (50%)]\tLoss: 0.261808\n",
      "Train Epoch: 20 [500/798 (62%)]\tLoss: 0.350545\n",
      "Train Epoch: 20 [600/798 (75%)]\tLoss: 0.449101\n",
      "Train Epoch: 20 [700/798 (88%)]\tLoss: 0.849264\n",
      "\n",
      "Test set: Avg. loss: 0.0909, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/798 (0%)]\tLoss: 0.200111\n",
      "Train Epoch: 21 [100/798 (12%)]\tLoss: 0.229760\n",
      "Train Epoch: 21 [200/798 (25%)]\tLoss: 0.909291\n",
      "Train Epoch: 21 [300/798 (38%)]\tLoss: 0.317379\n",
      "Train Epoch: 21 [400/798 (50%)]\tLoss: 0.167730\n",
      "Train Epoch: 21 [500/798 (62%)]\tLoss: 0.512849\n",
      "Train Epoch: 21 [600/798 (75%)]\tLoss: 0.392330\n",
      "Train Epoch: 21 [700/798 (88%)]\tLoss: 0.259008\n",
      "\n",
      "Test set: Avg. loss: 0.0898, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/798 (0%)]\tLoss: 0.314466\n",
      "Train Epoch: 22 [100/798 (12%)]\tLoss: 0.729094\n",
      "Train Epoch: 22 [200/798 (25%)]\tLoss: 0.339889\n",
      "Train Epoch: 22 [300/798 (38%)]\tLoss: 0.142940\n",
      "Train Epoch: 22 [400/798 (50%)]\tLoss: 0.124247\n",
      "Train Epoch: 22 [500/798 (62%)]\tLoss: 0.857456\n",
      "Train Epoch: 22 [600/798 (75%)]\tLoss: 0.378535\n",
      "Train Epoch: 22 [700/798 (88%)]\tLoss: 0.320508\n",
      "\n",
      "Test set: Avg. loss: 0.0513, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/798 (0%)]\tLoss: 0.258944\n",
      "Train Epoch: 23 [100/798 (12%)]\tLoss: 0.699317\n",
      "Train Epoch: 23 [200/798 (25%)]\tLoss: 0.316280\n",
      "Train Epoch: 23 [300/798 (38%)]\tLoss: 0.598664\n",
      "Train Epoch: 23 [400/798 (50%)]\tLoss: 0.610050\n",
      "Train Epoch: 23 [500/798 (62%)]\tLoss: 0.352101\n",
      "Train Epoch: 23 [600/798 (75%)]\tLoss: 0.307545\n",
      "Train Epoch: 23 [700/798 (88%)]\tLoss: 0.329914\n",
      "\n",
      "Test set: Avg. loss: 0.0509, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 24 [0/798 (0%)]\tLoss: 0.097208\n",
      "Train Epoch: 24 [100/798 (12%)]\tLoss: 0.463148\n",
      "Train Epoch: 24 [200/798 (25%)]\tLoss: 0.153720\n",
      "Train Epoch: 24 [300/798 (38%)]\tLoss: 0.164713\n",
      "Train Epoch: 24 [400/798 (50%)]\tLoss: 0.303272\n",
      "Train Epoch: 24 [500/798 (62%)]\tLoss: 0.745889\n",
      "Train Epoch: 24 [600/798 (75%)]\tLoss: 0.457438\n",
      "Train Epoch: 24 [700/798 (88%)]\tLoss: 0.484980\n",
      "\n",
      "Test set: Avg. loss: 0.0417, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 25 [0/798 (0%)]\tLoss: 0.572989\n",
      "Train Epoch: 25 [100/798 (12%)]\tLoss: 0.324283\n",
      "Train Epoch: 25 [200/798 (25%)]\tLoss: 0.291156\n",
      "Train Epoch: 25 [300/798 (38%)]\tLoss: 0.166457\n",
      "Train Epoch: 25 [400/798 (50%)]\tLoss: 0.285866\n",
      "Train Epoch: 25 [500/798 (62%)]\tLoss: 0.130331\n",
      "Train Epoch: 25 [600/798 (75%)]\tLoss: 0.523700\n",
      "Train Epoch: 25 [700/798 (88%)]\tLoss: 0.040616\n",
      "\n",
      "Test set: Avg. loss: 0.0423, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 26 [0/798 (0%)]\tLoss: 0.516414\n",
      "Train Epoch: 26 [100/798 (12%)]\tLoss: 0.212436\n",
      "Train Epoch: 26 [200/798 (25%)]\tLoss: 0.064729\n",
      "Train Epoch: 26 [300/798 (38%)]\tLoss: 0.022103\n",
      "Train Epoch: 26 [400/798 (50%)]\tLoss: 1.116743\n",
      "Train Epoch: 26 [500/798 (62%)]\tLoss: 0.346463\n",
      "Train Epoch: 26 [600/798 (75%)]\tLoss: 0.915404\n",
      "Train Epoch: 26 [700/798 (88%)]\tLoss: 0.056809\n",
      "\n",
      "Test set: Avg. loss: 0.0488, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/798 (0%)]\tLoss: 0.561579\n",
      "Train Epoch: 27 [100/798 (12%)]\tLoss: 0.213232\n",
      "Train Epoch: 27 [200/798 (25%)]\tLoss: 0.312064\n",
      "Train Epoch: 27 [300/798 (38%)]\tLoss: 0.149445\n",
      "Train Epoch: 27 [400/798 (50%)]\tLoss: 0.110947\n",
      "Train Epoch: 27 [500/798 (62%)]\tLoss: 0.215862\n",
      "Train Epoch: 27 [600/798 (75%)]\tLoss: 0.405796\n",
      "Train Epoch: 27 [700/798 (88%)]\tLoss: 0.029320\n",
      "\n",
      "Test set: Avg. loss: 0.0366, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/798 (0%)]\tLoss: 0.555409\n",
      "Train Epoch: 28 [100/798 (12%)]\tLoss: 0.021723\n",
      "Train Epoch: 28 [200/798 (25%)]\tLoss: 0.095446\n",
      "Train Epoch: 28 [300/798 (38%)]\tLoss: 0.180635\n",
      "Train Epoch: 28 [400/798 (50%)]\tLoss: 0.286463\n",
      "Train Epoch: 28 [500/798 (62%)]\tLoss: 0.375830\n",
      "Train Epoch: 28 [600/798 (75%)]\tLoss: 0.141757\n",
      "Train Epoch: 28 [700/798 (88%)]\tLoss: 0.104120\n",
      "\n",
      "Test set: Avg. loss: 0.0658, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/798 (0%)]\tLoss: 0.185126\n",
      "Train Epoch: 29 [100/798 (12%)]\tLoss: 0.033773\n",
      "Train Epoch: 29 [200/798 (25%)]\tLoss: 0.124768\n",
      "Train Epoch: 29 [300/798 (38%)]\tLoss: 0.027489\n",
      "Train Epoch: 29 [400/798 (50%)]\tLoss: 0.650070\n",
      "Train Epoch: 29 [500/798 (62%)]\tLoss: 0.006494\n",
      "Train Epoch: 29 [600/798 (75%)]\tLoss: 0.419813\n",
      "Train Epoch: 29 [700/798 (88%)]\tLoss: 0.061692\n",
      "\n",
      "Test set: Avg. loss: 0.0446, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 30 [0/798 (0%)]\tLoss: 0.520523\n",
      "Train Epoch: 30 [100/798 (12%)]\tLoss: 0.198819\n",
      "Train Epoch: 30 [200/798 (25%)]\tLoss: 0.482268\n",
      "Train Epoch: 30 [300/798 (38%)]\tLoss: 0.525169\n",
      "Train Epoch: 30 [400/798 (50%)]\tLoss: 0.106311\n",
      "Train Epoch: 30 [500/798 (62%)]\tLoss: 0.079029\n",
      "Train Epoch: 30 [600/798 (75%)]\tLoss: 0.010829\n",
      "Train Epoch: 30 [700/798 (88%)]\tLoss: 1.140622\n",
      "\n",
      "Test set: Avg. loss: 0.0340, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 31 [0/798 (0%)]\tLoss: 0.200584\n",
      "Train Epoch: 31 [100/798 (12%)]\tLoss: 0.042574\n",
      "Train Epoch: 31 [200/798 (25%)]\tLoss: 0.141895\n",
      "Train Epoch: 31 [300/798 (38%)]\tLoss: 0.441717\n",
      "Train Epoch: 31 [400/798 (50%)]\tLoss: 0.311707\n",
      "Train Epoch: 31 [500/798 (62%)]\tLoss: 0.089252\n",
      "Train Epoch: 31 [600/798 (75%)]\tLoss: 0.165203\n",
      "Train Epoch: 31 [700/798 (88%)]\tLoss: 0.299243\n",
      "\n",
      "Test set: Avg. loss: 0.0282, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 32 [0/798 (0%)]\tLoss: 0.244025\n",
      "Train Epoch: 32 [100/798 (12%)]\tLoss: 0.128967\n",
      "Train Epoch: 32 [200/798 (25%)]\tLoss: 0.016326\n",
      "Train Epoch: 32 [300/798 (38%)]\tLoss: 0.251305\n",
      "Train Epoch: 32 [400/798 (50%)]\tLoss: 0.065471\n",
      "Train Epoch: 32 [500/798 (62%)]\tLoss: 0.303510\n",
      "Train Epoch: 32 [600/798 (75%)]\tLoss: 0.015338\n",
      "Train Epoch: 32 [700/798 (88%)]\tLoss: 0.130219\n",
      "\n",
      "Test set: Avg. loss: 0.0406, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 33 [0/798 (0%)]\tLoss: 0.191909\n",
      "Train Epoch: 33 [100/798 (12%)]\tLoss: 0.364613\n",
      "Train Epoch: 33 [200/798 (25%)]\tLoss: 0.164498\n",
      "Train Epoch: 33 [300/798 (38%)]\tLoss: 0.403718\n",
      "Train Epoch: 33 [400/798 (50%)]\tLoss: 0.078051\n",
      "Train Epoch: 33 [500/798 (62%)]\tLoss: 0.099814\n",
      "Train Epoch: 33 [600/798 (75%)]\tLoss: 0.593041\n",
      "Train Epoch: 33 [700/798 (88%)]\tLoss: 0.064987\n",
      "\n",
      "Test set: Avg. loss: 0.0545, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/798 (0%)]\tLoss: 0.485563\n",
      "Train Epoch: 34 [100/798 (12%)]\tLoss: 0.118920\n",
      "Train Epoch: 34 [200/798 (25%)]\tLoss: 0.437131\n",
      "Train Epoch: 34 [300/798 (38%)]\tLoss: 0.013421\n",
      "Train Epoch: 34 [400/798 (50%)]\tLoss: 0.025900\n",
      "Train Epoch: 34 [500/798 (62%)]\tLoss: 0.112904\n",
      "Train Epoch: 34 [600/798 (75%)]\tLoss: 0.062740\n",
      "Train Epoch: 34 [700/798 (88%)]\tLoss: 0.097373\n",
      "\n",
      "Test set: Avg. loss: 0.0306, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 35 [0/798 (0%)]\tLoss: 0.187598\n",
      "Train Epoch: 35 [100/798 (12%)]\tLoss: 0.095476\n",
      "Train Epoch: 35 [200/798 (25%)]\tLoss: 0.361226\n",
      "Train Epoch: 35 [300/798 (38%)]\tLoss: 0.184099\n",
      "Train Epoch: 35 [400/798 (50%)]\tLoss: 0.575231\n",
      "Train Epoch: 35 [500/798 (62%)]\tLoss: 0.167867\n",
      "Train Epoch: 35 [600/798 (75%)]\tLoss: 0.623423\n",
      "Train Epoch: 35 [700/798 (88%)]\tLoss: 0.147787\n",
      "\n",
      "Test set: Avg. loss: 0.0424, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 36 [0/798 (0%)]\tLoss: 0.565657\n",
      "Train Epoch: 36 [100/798 (12%)]\tLoss: 0.325889\n",
      "Train Epoch: 36 [200/798 (25%)]\tLoss: 0.127606\n",
      "Train Epoch: 36 [300/798 (38%)]\tLoss: 0.130991\n",
      "Train Epoch: 36 [400/798 (50%)]\tLoss: 0.351147\n",
      "Train Epoch: 36 [500/798 (62%)]\tLoss: 0.546439\n",
      "Train Epoch: 36 [600/798 (75%)]\tLoss: 0.536755\n",
      "Train Epoch: 36 [700/798 (88%)]\tLoss: 0.073618\n",
      "\n",
      "Test set: Avg. loss: 0.0352, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 37 [0/798 (0%)]\tLoss: 0.275708\n",
      "Train Epoch: 37 [100/798 (12%)]\tLoss: 0.523412\n",
      "Train Epoch: 37 [200/798 (25%)]\tLoss: 0.089311\n",
      "Train Epoch: 37 [300/798 (38%)]\tLoss: 0.502415\n",
      "Train Epoch: 37 [400/798 (50%)]\tLoss: 0.205666\n",
      "Train Epoch: 37 [500/798 (62%)]\tLoss: 0.174619\n",
      "Train Epoch: 37 [600/798 (75%)]\tLoss: 0.182949\n",
      "Train Epoch: 37 [700/798 (88%)]\tLoss: 0.096593\n",
      "\n",
      "Test set: Avg. loss: 0.0817, Accuracy: 193/200 (96%)\n",
      "\n",
      "Train Epoch: 38 [0/798 (0%)]\tLoss: 0.110702\n",
      "Train Epoch: 38 [100/798 (12%)]\tLoss: 0.518782\n",
      "Train Epoch: 38 [200/798 (25%)]\tLoss: 0.286016\n",
      "Train Epoch: 38 [300/798 (38%)]\tLoss: 0.520381\n",
      "Train Epoch: 38 [400/798 (50%)]\tLoss: 0.086333\n",
      "Train Epoch: 38 [500/798 (62%)]\tLoss: 0.488607\n",
      "Train Epoch: 38 [600/798 (75%)]\tLoss: 0.278704\n",
      "Train Epoch: 38 [700/798 (88%)]\tLoss: 0.114301\n",
      "\n",
      "Test set: Avg. loss: 0.0289, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 39 [0/798 (0%)]\tLoss: 0.404131\n",
      "Train Epoch: 39 [100/798 (12%)]\tLoss: 0.082172\n",
      "Train Epoch: 39 [200/798 (25%)]\tLoss: 0.162101\n",
      "Train Epoch: 39 [300/798 (38%)]\tLoss: 0.391781\n",
      "Train Epoch: 39 [400/798 (50%)]\tLoss: 0.358651\n",
      "Train Epoch: 39 [500/798 (62%)]\tLoss: 0.110178\n",
      "Train Epoch: 39 [600/798 (75%)]\tLoss: 0.262820\n",
      "Train Epoch: 39 [700/798 (88%)]\tLoss: 0.341025\n",
      "\n",
      "Test set: Avg. loss: 0.0195, Accuracy: 200/200 (100%)\n",
      "\n",
      "Train Epoch: 40 [0/798 (0%)]\tLoss: 0.012447\n",
      "Train Epoch: 40 [100/798 (12%)]\tLoss: 0.399273\n",
      "Train Epoch: 40 [200/798 (25%)]\tLoss: 0.226125\n",
      "Train Epoch: 40 [300/798 (38%)]\tLoss: 0.069891\n",
      "Train Epoch: 40 [400/798 (50%)]\tLoss: 0.056790\n",
      "Train Epoch: 40 [500/798 (62%)]\tLoss: 0.282236\n",
      "Train Epoch: 40 [600/798 (75%)]\tLoss: 0.130971\n",
      "Train Epoch: 40 [700/798 (88%)]\tLoss: 0.056573\n",
      "\n",
      "Test set: Avg. loss: 0.0325, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 41 [0/798 (0%)]\tLoss: 0.822419\n",
      "Train Epoch: 41 [100/798 (12%)]\tLoss: 0.260671\n",
      "Train Epoch: 41 [200/798 (25%)]\tLoss: 0.194085\n",
      "Train Epoch: 41 [300/798 (38%)]\tLoss: 0.047821\n",
      "Train Epoch: 41 [400/798 (50%)]\tLoss: 0.063754\n",
      "Train Epoch: 41 [500/798 (62%)]\tLoss: 0.034972\n",
      "Train Epoch: 41 [600/798 (75%)]\tLoss: 0.428615\n",
      "Train Epoch: 41 [700/798 (88%)]\tLoss: 0.209157\n",
      "\n",
      "Test set: Avg. loss: 0.0204, Accuracy: 200/200 (100%)\n",
      "\n",
      "Train Epoch: 42 [0/798 (0%)]\tLoss: 0.029446\n",
      "Train Epoch: 42 [100/798 (12%)]\tLoss: 0.188330\n",
      "Train Epoch: 42 [200/798 (25%)]\tLoss: 0.022711\n",
      "Train Epoch: 42 [300/798 (38%)]\tLoss: 0.247928\n",
      "Train Epoch: 42 [400/798 (50%)]\tLoss: 0.189660\n",
      "Train Epoch: 42 [500/798 (62%)]\tLoss: 0.136356\n",
      "Train Epoch: 42 [600/798 (75%)]\tLoss: 0.115042\n",
      "Train Epoch: 42 [700/798 (88%)]\tLoss: 0.331298\n",
      "\n",
      "Test set: Avg. loss: 0.0365, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 43 [0/798 (0%)]\tLoss: 0.872795\n",
      "Train Epoch: 43 [100/798 (12%)]\tLoss: 0.354920\n",
      "Train Epoch: 43 [200/798 (25%)]\tLoss: 0.032488\n",
      "Train Epoch: 43 [300/798 (38%)]\tLoss: 0.006789\n",
      "Train Epoch: 43 [400/798 (50%)]\tLoss: 0.294056\n",
      "Train Epoch: 43 [500/798 (62%)]\tLoss: 0.487607\n",
      "Train Epoch: 43 [600/798 (75%)]\tLoss: 0.029516\n",
      "Train Epoch: 43 [700/798 (88%)]\tLoss: 0.124266\n",
      "\n",
      "Test set: Avg. loss: 0.0186, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 44 [0/798 (0%)]\tLoss: 0.347698\n",
      "Train Epoch: 44 [100/798 (12%)]\tLoss: 0.284048\n",
      "Train Epoch: 44 [200/798 (25%)]\tLoss: 0.161686\n",
      "Train Epoch: 44 [300/798 (38%)]\tLoss: 0.099527\n",
      "Train Epoch: 44 [400/798 (50%)]\tLoss: 0.869990\n",
      "Train Epoch: 44 [500/798 (62%)]\tLoss: 0.160212\n",
      "Train Epoch: 44 [600/798 (75%)]\tLoss: 0.014226\n",
      "Train Epoch: 44 [700/798 (88%)]\tLoss: 0.367717\n",
      "\n",
      "Test set: Avg. loss: 0.0264, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 45 [0/798 (0%)]\tLoss: 0.037254\n",
      "Train Epoch: 45 [100/798 (12%)]\tLoss: 0.498533\n",
      "Train Epoch: 45 [200/798 (25%)]\tLoss: 0.254135\n",
      "Train Epoch: 45 [300/798 (38%)]\tLoss: 0.015420\n",
      "Train Epoch: 45 [400/798 (50%)]\tLoss: 0.817582\n",
      "Train Epoch: 45 [500/798 (62%)]\tLoss: 0.076796\n",
      "Train Epoch: 45 [600/798 (75%)]\tLoss: 0.084469\n",
      "Train Epoch: 45 [700/798 (88%)]\tLoss: 0.223182\n",
      "\n",
      "Test set: Avg. loss: 0.0152, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 46 [0/798 (0%)]\tLoss: 0.035968\n",
      "Train Epoch: 46 [100/798 (12%)]\tLoss: 0.222061\n",
      "Train Epoch: 46 [200/798 (25%)]\tLoss: 0.011021\n",
      "Train Epoch: 46 [300/798 (38%)]\tLoss: 0.041855\n",
      "Train Epoch: 46 [400/798 (50%)]\tLoss: 0.041627\n",
      "Train Epoch: 46 [500/798 (62%)]\tLoss: 0.134130\n",
      "Train Epoch: 46 [600/798 (75%)]\tLoss: 0.122856\n",
      "Train Epoch: 46 [700/798 (88%)]\tLoss: 0.041957\n",
      "\n",
      "Test set: Avg. loss: 0.0263, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 47 [0/798 (0%)]\tLoss: 0.097041\n",
      "Train Epoch: 47 [100/798 (12%)]\tLoss: 0.665828\n",
      "Train Epoch: 47 [200/798 (25%)]\tLoss: 0.048249\n",
      "Train Epoch: 47 [300/798 (38%)]\tLoss: 0.116421\n",
      "Train Epoch: 47 [400/798 (50%)]\tLoss: 0.001036\n",
      "Train Epoch: 47 [500/798 (62%)]\tLoss: 0.175165\n",
      "Train Epoch: 47 [600/798 (75%)]\tLoss: 0.039325\n",
      "Train Epoch: 47 [700/798 (88%)]\tLoss: 0.058754\n",
      "\n",
      "Test set: Avg. loss: 0.0275, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 48 [0/798 (0%)]\tLoss: 0.082574\n",
      "Train Epoch: 48 [100/798 (12%)]\tLoss: 0.031067\n",
      "Train Epoch: 48 [200/798 (25%)]\tLoss: 0.084042\n",
      "Train Epoch: 48 [300/798 (38%)]\tLoss: 0.064051\n",
      "Train Epoch: 48 [400/798 (50%)]\tLoss: 0.021255\n",
      "Train Epoch: 48 [500/798 (62%)]\tLoss: 0.042632\n",
      "Train Epoch: 48 [600/798 (75%)]\tLoss: 0.301694\n",
      "Train Epoch: 48 [700/798 (88%)]\tLoss: 0.024382\n",
      "\n",
      "Test set: Avg. loss: 0.0238, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 49 [0/798 (0%)]\tLoss: 0.153267\n",
      "Train Epoch: 49 [100/798 (12%)]\tLoss: 0.010298\n",
      "Train Epoch: 49 [200/798 (25%)]\tLoss: 0.250034\n",
      "Train Epoch: 49 [300/798 (38%)]\tLoss: 0.266857\n",
      "Train Epoch: 49 [400/798 (50%)]\tLoss: 0.105100\n",
      "Train Epoch: 49 [500/798 (62%)]\tLoss: 0.181158\n",
      "Train Epoch: 49 [600/798 (75%)]\tLoss: 0.106739\n",
      "Train Epoch: 49 [700/798 (88%)]\tLoss: 0.261259\n",
      "\n",
      "Test set: Avg. loss: 0.0191, Accuracy: 200/200 (100%)\n",
      "\n",
      "Train Epoch: 50 [0/798 (0%)]\tLoss: 0.146198\n",
      "Train Epoch: 50 [100/798 (12%)]\tLoss: 0.156466\n",
      "Train Epoch: 50 [200/798 (25%)]\tLoss: 0.026522\n",
      "Train Epoch: 50 [300/798 (38%)]\tLoss: 0.068545\n",
      "Train Epoch: 50 [400/798 (50%)]\tLoss: 0.156624\n",
      "Train Epoch: 50 [500/798 (62%)]\tLoss: 0.134127\n",
      "Train Epoch: 50 [600/798 (75%)]\tLoss: 0.152459\n",
      "Train Epoch: 50 [700/798 (88%)]\tLoss: 0.025512\n",
      "\n",
      "Test set: Avg. loss: 0.0136, Accuracy: 199/200 (100%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0136, Accuracy: 199/200 (100%)\n",
      "\n",
      "Running bootstrap experiment: 8\n",
      "Train Epoch: 1 [0/798 (0%)]\tLoss: 2.228426\n",
      "Train Epoch: 1 [100/798 (12%)]\tLoss: 2.307829\n",
      "Train Epoch: 1 [200/798 (25%)]\tLoss: 2.229156\n",
      "Train Epoch: 1 [300/798 (38%)]\tLoss: 2.308873\n",
      "Train Epoch: 1 [400/798 (50%)]\tLoss: 2.251027\n",
      "Train Epoch: 1 [500/798 (62%)]\tLoss: 2.239316\n",
      "Train Epoch: 1 [600/798 (75%)]\tLoss: 2.277588\n",
      "Train Epoch: 1 [700/798 (88%)]\tLoss: 2.242055\n",
      "\n",
      "Test set: Avg. loss: 2.2993, Accuracy: 32/200 (16%)\n",
      "\n",
      "Train Epoch: 2 [0/798 (0%)]\tLoss: 2.302521\n",
      "Train Epoch: 2 [100/798 (12%)]\tLoss: 2.336611\n",
      "Train Epoch: 2 [200/798 (25%)]\tLoss: 2.273088\n",
      "Train Epoch: 2 [300/798 (38%)]\tLoss: 2.268266\n",
      "Train Epoch: 2 [400/798 (50%)]\tLoss: 2.364345\n",
      "Train Epoch: 2 [500/798 (62%)]\tLoss: 2.292539\n",
      "Train Epoch: 2 [600/798 (75%)]\tLoss: 2.200286\n",
      "Train Epoch: 2 [700/798 (88%)]\tLoss: 2.288567\n",
      "\n",
      "Test set: Avg. loss: 2.2888, Accuracy: 28/200 (14%)\n",
      "\n",
      "Train Epoch: 3 [0/798 (0%)]\tLoss: 2.300911\n",
      "Train Epoch: 3 [100/798 (12%)]\tLoss: 2.098706\n",
      "Train Epoch: 3 [200/798 (25%)]\tLoss: 2.105094\n",
      "Train Epoch: 3 [300/798 (38%)]\tLoss: 2.364604\n",
      "Train Epoch: 3 [400/798 (50%)]\tLoss: 2.361912\n",
      "Train Epoch: 3 [500/798 (62%)]\tLoss: 2.189045\n",
      "Train Epoch: 3 [600/798 (75%)]\tLoss: 2.182867\n",
      "Train Epoch: 3 [700/798 (88%)]\tLoss: 2.129773\n",
      "\n",
      "Test set: Avg. loss: 2.2358, Accuracy: 41/200 (20%)\n",
      "\n",
      "Train Epoch: 4 [0/798 (0%)]\tLoss: 2.205643\n",
      "Train Epoch: 4 [100/798 (12%)]\tLoss: 2.179350\n",
      "Train Epoch: 4 [200/798 (25%)]\tLoss: 2.100683\n",
      "Train Epoch: 4 [300/798 (38%)]\tLoss: 2.178254\n",
      "Train Epoch: 4 [400/798 (50%)]\tLoss: 2.006744\n",
      "Train Epoch: 4 [500/798 (62%)]\tLoss: 2.225064\n",
      "Train Epoch: 4 [600/798 (75%)]\tLoss: 2.166430\n",
      "Train Epoch: 4 [700/798 (88%)]\tLoss: 2.139807\n",
      "\n",
      "Test set: Avg. loss: 2.1072, Accuracy: 39/200 (20%)\n",
      "\n",
      "Train Epoch: 5 [0/798 (0%)]\tLoss: 2.223273\n",
      "Train Epoch: 5 [100/798 (12%)]\tLoss: 2.091805\n",
      "Train Epoch: 5 [200/798 (25%)]\tLoss: 1.833061\n",
      "Train Epoch: 5 [300/798 (38%)]\tLoss: 2.102669\n",
      "Train Epoch: 5 [400/798 (50%)]\tLoss: 2.069013\n",
      "Train Epoch: 5 [500/798 (62%)]\tLoss: 1.831820\n",
      "Train Epoch: 5 [600/798 (75%)]\tLoss: 1.972358\n",
      "Train Epoch: 5 [700/798 (88%)]\tLoss: 2.215306\n",
      "\n",
      "Test set: Avg. loss: 1.9545, Accuracy: 59/200 (30%)\n",
      "\n",
      "Train Epoch: 6 [0/798 (0%)]\tLoss: 1.743112\n",
      "Train Epoch: 6 [100/798 (12%)]\tLoss: 2.063393\n",
      "Train Epoch: 6 [200/798 (25%)]\tLoss: 2.252728\n",
      "Train Epoch: 6 [300/798 (38%)]\tLoss: 1.807371\n",
      "Train Epoch: 6 [400/798 (50%)]\tLoss: 1.947294\n",
      "Train Epoch: 6 [500/798 (62%)]\tLoss: 1.629849\n",
      "Train Epoch: 6 [600/798 (75%)]\tLoss: 1.700780\n",
      "Train Epoch: 6 [700/798 (88%)]\tLoss: 1.892010\n",
      "\n",
      "Test set: Avg. loss: 1.7381, Accuracy: 81/200 (40%)\n",
      "\n",
      "Train Epoch: 7 [0/798 (0%)]\tLoss: 1.959477\n",
      "Train Epoch: 7 [100/798 (12%)]\tLoss: 1.688429\n",
      "Train Epoch: 7 [200/798 (25%)]\tLoss: 1.769378\n",
      "Train Epoch: 7 [300/798 (38%)]\tLoss: 2.259724\n",
      "Train Epoch: 7 [400/798 (50%)]\tLoss: 1.832685\n",
      "Train Epoch: 7 [500/798 (62%)]\tLoss: 1.915255\n",
      "Train Epoch: 7 [600/798 (75%)]\tLoss: 1.787632\n",
      "Train Epoch: 7 [700/798 (88%)]\tLoss: 1.744507\n",
      "\n",
      "Test set: Avg. loss: 1.4932, Accuracy: 120/200 (60%)\n",
      "\n",
      "Train Epoch: 8 [0/798 (0%)]\tLoss: 1.527713\n",
      "Train Epoch: 8 [100/798 (12%)]\tLoss: 1.331470\n",
      "Train Epoch: 8 [200/798 (25%)]\tLoss: 1.787046\n",
      "Train Epoch: 8 [300/798 (38%)]\tLoss: 1.701173\n",
      "Train Epoch: 8 [400/798 (50%)]\tLoss: 1.469291\n",
      "Train Epoch: 8 [500/798 (62%)]\tLoss: 1.434555\n",
      "Train Epoch: 8 [600/798 (75%)]\tLoss: 1.387584\n",
      "Train Epoch: 8 [700/798 (88%)]\tLoss: 1.702120\n",
      "\n",
      "Test set: Avg. loss: 1.2263, Accuracy: 131/200 (66%)\n",
      "\n",
      "Train Epoch: 9 [0/798 (0%)]\tLoss: 1.410476\n",
      "Train Epoch: 9 [100/798 (12%)]\tLoss: 1.742840\n",
      "Train Epoch: 9 [200/798 (25%)]\tLoss: 1.506705\n",
      "Train Epoch: 9 [300/798 (38%)]\tLoss: 1.564504\n",
      "Train Epoch: 9 [400/798 (50%)]\tLoss: 1.477175\n",
      "Train Epoch: 9 [500/798 (62%)]\tLoss: 1.466381\n",
      "Train Epoch: 9 [600/798 (75%)]\tLoss: 1.475111\n",
      "Train Epoch: 9 [700/798 (88%)]\tLoss: 1.255943\n",
      "\n",
      "Test set: Avg. loss: 0.9259, Accuracy: 162/200 (81%)\n",
      "\n",
      "Train Epoch: 10 [0/798 (0%)]\tLoss: 1.081334\n",
      "Train Epoch: 10 [100/798 (12%)]\tLoss: 1.194888\n",
      "Train Epoch: 10 [200/798 (25%)]\tLoss: 1.692553\n",
      "Train Epoch: 10 [300/798 (38%)]\tLoss: 1.469982\n",
      "Train Epoch: 10 [400/798 (50%)]\tLoss: 1.039500\n",
      "Train Epoch: 10 [500/798 (62%)]\tLoss: 1.514312\n",
      "Train Epoch: 10 [600/798 (75%)]\tLoss: 1.581397\n",
      "Train Epoch: 10 [700/798 (88%)]\tLoss: 0.916683\n",
      "\n",
      "Test set: Avg. loss: 0.7810, Accuracy: 181/200 (90%)\n",
      "\n",
      "Train Epoch: 11 [0/798 (0%)]\tLoss: 1.103774\n",
      "Train Epoch: 11 [100/798 (12%)]\tLoss: 0.588409\n",
      "Train Epoch: 11 [200/798 (25%)]\tLoss: 1.646621\n",
      "Train Epoch: 11 [300/798 (38%)]\tLoss: 0.894375\n",
      "Train Epoch: 11 [400/798 (50%)]\tLoss: 1.312885\n",
      "Train Epoch: 11 [500/798 (62%)]\tLoss: 1.040093\n",
      "Train Epoch: 11 [600/798 (75%)]\tLoss: 1.147947\n",
      "Train Epoch: 11 [700/798 (88%)]\tLoss: 1.065876\n",
      "\n",
      "Test set: Avg. loss: 0.6353, Accuracy: 171/200 (86%)\n",
      "\n",
      "Train Epoch: 12 [0/798 (0%)]\tLoss: 1.437750\n",
      "Train Epoch: 12 [100/798 (12%)]\tLoss: 1.300434\n",
      "Train Epoch: 12 [200/798 (25%)]\tLoss: 1.176597\n",
      "Train Epoch: 12 [300/798 (38%)]\tLoss: 0.589333\n",
      "Train Epoch: 12 [400/798 (50%)]\tLoss: 1.091325\n",
      "Train Epoch: 12 [500/798 (62%)]\tLoss: 0.715308\n",
      "Train Epoch: 12 [600/798 (75%)]\tLoss: 0.829354\n",
      "Train Epoch: 12 [700/798 (88%)]\tLoss: 1.700053\n",
      "\n",
      "Test set: Avg. loss: 0.5304, Accuracy: 163/200 (82%)\n",
      "\n",
      "Train Epoch: 13 [0/798 (0%)]\tLoss: 0.996322\n",
      "Train Epoch: 13 [100/798 (12%)]\tLoss: 1.523001\n",
      "Train Epoch: 13 [200/798 (25%)]\tLoss: 0.959127\n",
      "Train Epoch: 13 [300/798 (38%)]\tLoss: 1.136647\n",
      "Train Epoch: 13 [400/798 (50%)]\tLoss: 0.922018\n",
      "Train Epoch: 13 [500/798 (62%)]\tLoss: 0.518346\n",
      "Train Epoch: 13 [600/798 (75%)]\tLoss: 0.649926\n",
      "Train Epoch: 13 [700/798 (88%)]\tLoss: 1.062714\n",
      "\n",
      "Test set: Avg. loss: 0.5029, Accuracy: 183/200 (92%)\n",
      "\n",
      "Train Epoch: 14 [0/798 (0%)]\tLoss: 0.749159\n",
      "Train Epoch: 14 [100/798 (12%)]\tLoss: 1.138902\n",
      "Train Epoch: 14 [200/798 (25%)]\tLoss: 0.696115\n",
      "Train Epoch: 14 [300/798 (38%)]\tLoss: 0.798123\n",
      "Train Epoch: 14 [400/798 (50%)]\tLoss: 0.964142\n",
      "Train Epoch: 14 [500/798 (62%)]\tLoss: 1.138586\n",
      "Train Epoch: 14 [600/798 (75%)]\tLoss: 0.531823\n",
      "Train Epoch: 14 [700/798 (88%)]\tLoss: 0.781942\n",
      "\n",
      "Test set: Avg. loss: 0.4212, Accuracy: 189/200 (94%)\n",
      "\n",
      "Train Epoch: 15 [0/798 (0%)]\tLoss: 0.842014\n",
      "Train Epoch: 15 [100/798 (12%)]\tLoss: 0.658398\n",
      "Train Epoch: 15 [200/798 (25%)]\tLoss: 0.835621\n",
      "Train Epoch: 15 [300/798 (38%)]\tLoss: 0.538437\n",
      "Train Epoch: 15 [400/798 (50%)]\tLoss: 1.056295\n",
      "Train Epoch: 15 [500/798 (62%)]\tLoss: 0.886990\n",
      "Train Epoch: 15 [600/798 (75%)]\tLoss: 1.029873\n",
      "Train Epoch: 15 [700/798 (88%)]\tLoss: 0.787881\n",
      "\n",
      "Test set: Avg. loss: 0.3100, Accuracy: 188/200 (94%)\n",
      "\n",
      "Train Epoch: 16 [0/798 (0%)]\tLoss: 0.685039\n",
      "Train Epoch: 16 [100/798 (12%)]\tLoss: 0.580578\n",
      "Train Epoch: 16 [200/798 (25%)]\tLoss: 0.372105\n",
      "Train Epoch: 16 [300/798 (38%)]\tLoss: 0.674648\n",
      "Train Epoch: 16 [400/798 (50%)]\tLoss: 0.307175\n",
      "Train Epoch: 16 [500/798 (62%)]\tLoss: 1.009794\n",
      "Train Epoch: 16 [600/798 (75%)]\tLoss: 0.847434\n",
      "Train Epoch: 16 [700/798 (88%)]\tLoss: 0.962916\n",
      "\n",
      "Test set: Avg. loss: 0.2322, Accuracy: 192/200 (96%)\n",
      "\n",
      "Train Epoch: 17 [0/798 (0%)]\tLoss: 0.736608\n",
      "Train Epoch: 17 [100/798 (12%)]\tLoss: 0.895127\n",
      "Train Epoch: 17 [200/798 (25%)]\tLoss: 0.357501\n",
      "Train Epoch: 17 [300/798 (38%)]\tLoss: 0.773475\n",
      "Train Epoch: 17 [400/798 (50%)]\tLoss: 0.536396\n",
      "Train Epoch: 17 [500/798 (62%)]\tLoss: 0.957758\n",
      "Train Epoch: 17 [600/798 (75%)]\tLoss: 0.961500\n",
      "Train Epoch: 17 [700/798 (88%)]\tLoss: 0.341236\n",
      "\n",
      "Test set: Avg. loss: 0.1876, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/798 (0%)]\tLoss: 0.848959\n",
      "Train Epoch: 18 [100/798 (12%)]\tLoss: 0.471162\n",
      "Train Epoch: 18 [200/798 (25%)]\tLoss: 0.712207\n",
      "Train Epoch: 18 [300/798 (38%)]\tLoss: 0.806695\n",
      "Train Epoch: 18 [400/798 (50%)]\tLoss: 0.730293\n",
      "Train Epoch: 18 [500/798 (62%)]\tLoss: 0.483453\n",
      "Train Epoch: 18 [600/798 (75%)]\tLoss: 0.673791\n",
      "Train Epoch: 18 [700/798 (88%)]\tLoss: 0.515834\n",
      "\n",
      "Test set: Avg. loss: 0.1907, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/798 (0%)]\tLoss: 0.367824\n",
      "Train Epoch: 19 [100/798 (12%)]\tLoss: 0.380946\n",
      "Train Epoch: 19 [200/798 (25%)]\tLoss: 0.647050\n",
      "Train Epoch: 19 [300/798 (38%)]\tLoss: 1.192095\n",
      "Train Epoch: 19 [400/798 (50%)]\tLoss: 0.644845\n",
      "Train Epoch: 19 [500/798 (62%)]\tLoss: 0.324699\n",
      "Train Epoch: 19 [600/798 (75%)]\tLoss: 0.758625\n",
      "Train Epoch: 19 [700/798 (88%)]\tLoss: 0.437036\n",
      "\n",
      "Test set: Avg. loss: 0.1383, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/798 (0%)]\tLoss: 0.376478\n",
      "Train Epoch: 20 [100/798 (12%)]\tLoss: 0.706129\n",
      "Train Epoch: 20 [200/798 (25%)]\tLoss: 0.428466\n",
      "Train Epoch: 20 [300/798 (38%)]\tLoss: 0.574704\n",
      "Train Epoch: 20 [400/798 (50%)]\tLoss: 0.604296\n",
      "Train Epoch: 20 [500/798 (62%)]\tLoss: 0.739363\n",
      "Train Epoch: 20 [600/798 (75%)]\tLoss: 0.253000\n",
      "Train Epoch: 20 [700/798 (88%)]\tLoss: 0.784317\n",
      "\n",
      "Test set: Avg. loss: 0.1868, Accuracy: 192/200 (96%)\n",
      "\n",
      "Train Epoch: 21 [0/798 (0%)]\tLoss: 0.492063\n",
      "Train Epoch: 21 [100/798 (12%)]\tLoss: 0.492127\n",
      "Train Epoch: 21 [200/798 (25%)]\tLoss: 0.563995\n",
      "Train Epoch: 21 [300/798 (38%)]\tLoss: 0.197867\n",
      "Train Epoch: 21 [400/798 (50%)]\tLoss: 0.349964\n",
      "Train Epoch: 21 [500/798 (62%)]\tLoss: 1.278770\n",
      "Train Epoch: 21 [600/798 (75%)]\tLoss: 0.043398\n",
      "Train Epoch: 21 [700/798 (88%)]\tLoss: 1.162993\n",
      "\n",
      "Test set: Avg. loss: 0.1218, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/798 (0%)]\tLoss: 0.718057\n",
      "Train Epoch: 22 [100/798 (12%)]\tLoss: 1.012541\n",
      "Train Epoch: 22 [200/798 (25%)]\tLoss: 0.333091\n",
      "Train Epoch: 22 [300/798 (38%)]\tLoss: 0.185282\n",
      "Train Epoch: 22 [400/798 (50%)]\tLoss: 0.446943\n",
      "Train Epoch: 22 [500/798 (62%)]\tLoss: 0.272013\n",
      "Train Epoch: 22 [600/798 (75%)]\tLoss: 0.572974\n",
      "Train Epoch: 22 [700/798 (88%)]\tLoss: 0.239420\n",
      "\n",
      "Test set: Avg. loss: 0.1073, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 23 [0/798 (0%)]\tLoss: 0.490339\n",
      "Train Epoch: 23 [100/798 (12%)]\tLoss: 0.908722\n",
      "Train Epoch: 23 [200/798 (25%)]\tLoss: 0.903685\n",
      "Train Epoch: 23 [300/798 (38%)]\tLoss: 0.575855\n",
      "Train Epoch: 23 [400/798 (50%)]\tLoss: 0.196336\n",
      "Train Epoch: 23 [500/798 (62%)]\tLoss: 1.163101\n",
      "Train Epoch: 23 [600/798 (75%)]\tLoss: 0.335003\n",
      "Train Epoch: 23 [700/798 (88%)]\tLoss: 0.564689\n",
      "\n",
      "Test set: Avg. loss: 0.1002, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/798 (0%)]\tLoss: 0.577017\n",
      "Train Epoch: 24 [100/798 (12%)]\tLoss: 1.021278\n",
      "Train Epoch: 24 [200/798 (25%)]\tLoss: 0.659821\n",
      "Train Epoch: 24 [300/798 (38%)]\tLoss: 0.753245\n",
      "Train Epoch: 24 [400/798 (50%)]\tLoss: 0.172004\n",
      "Train Epoch: 24 [500/798 (62%)]\tLoss: 0.184723\n",
      "Train Epoch: 24 [600/798 (75%)]\tLoss: 0.118747\n",
      "Train Epoch: 24 [700/798 (88%)]\tLoss: 0.559213\n",
      "\n",
      "Test set: Avg. loss: 0.1003, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/798 (0%)]\tLoss: 0.238304\n",
      "Train Epoch: 25 [100/798 (12%)]\tLoss: 0.504744\n",
      "Train Epoch: 25 [200/798 (25%)]\tLoss: 0.282146\n",
      "Train Epoch: 25 [300/798 (38%)]\tLoss: 0.316590\n",
      "Train Epoch: 25 [400/798 (50%)]\tLoss: 0.210662\n",
      "Train Epoch: 25 [500/798 (62%)]\tLoss: 0.482004\n",
      "Train Epoch: 25 [600/798 (75%)]\tLoss: 0.562066\n",
      "Train Epoch: 25 [700/798 (88%)]\tLoss: 0.236238\n",
      "\n",
      "Test set: Avg. loss: 0.0772, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/798 (0%)]\tLoss: 0.319917\n",
      "Train Epoch: 26 [100/798 (12%)]\tLoss: 0.660965\n",
      "Train Epoch: 26 [200/798 (25%)]\tLoss: 0.164560\n",
      "Train Epoch: 26 [300/798 (38%)]\tLoss: 0.445082\n",
      "Train Epoch: 26 [400/798 (50%)]\tLoss: 0.582272\n",
      "Train Epoch: 26 [500/798 (62%)]\tLoss: 0.288849\n",
      "Train Epoch: 26 [600/798 (75%)]\tLoss: 0.286632\n",
      "Train Epoch: 26 [700/798 (88%)]\tLoss: 0.461143\n",
      "\n",
      "Test set: Avg. loss: 0.0639, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 27 [0/798 (0%)]\tLoss: 0.157923\n",
      "Train Epoch: 27 [100/798 (12%)]\tLoss: 0.280441\n",
      "Train Epoch: 27 [200/798 (25%)]\tLoss: 0.316327\n",
      "Train Epoch: 27 [300/798 (38%)]\tLoss: 0.690809\n",
      "Train Epoch: 27 [400/798 (50%)]\tLoss: 0.510752\n",
      "Train Epoch: 27 [500/798 (62%)]\tLoss: 0.569123\n",
      "Train Epoch: 27 [600/798 (75%)]\tLoss: 0.560278\n",
      "Train Epoch: 27 [700/798 (88%)]\tLoss: 0.104402\n",
      "\n",
      "Test set: Avg. loss: 0.0677, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/798 (0%)]\tLoss: 0.292323\n",
      "Train Epoch: 28 [100/798 (12%)]\tLoss: 0.127252\n",
      "Train Epoch: 28 [200/798 (25%)]\tLoss: 0.224056\n",
      "Train Epoch: 28 [300/798 (38%)]\tLoss: 0.052942\n",
      "Train Epoch: 28 [400/798 (50%)]\tLoss: 0.627414\n",
      "Train Epoch: 28 [500/798 (62%)]\tLoss: 0.963771\n",
      "Train Epoch: 28 [600/798 (75%)]\tLoss: 0.400720\n",
      "Train Epoch: 28 [700/798 (88%)]\tLoss: 0.429409\n",
      "\n",
      "Test set: Avg. loss: 0.0650, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/798 (0%)]\tLoss: 0.203509\n",
      "Train Epoch: 29 [100/798 (12%)]\tLoss: 0.611422\n",
      "Train Epoch: 29 [200/798 (25%)]\tLoss: 0.217211\n",
      "Train Epoch: 29 [300/798 (38%)]\tLoss: 0.558567\n",
      "Train Epoch: 29 [400/798 (50%)]\tLoss: 0.065197\n",
      "Train Epoch: 29 [500/798 (62%)]\tLoss: 0.273248\n",
      "Train Epoch: 29 [600/798 (75%)]\tLoss: 0.092066\n",
      "Train Epoch: 29 [700/798 (88%)]\tLoss: 0.052726\n",
      "\n",
      "Test set: Avg. loss: 0.0475, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 30 [0/798 (0%)]\tLoss: 0.040734\n",
      "Train Epoch: 30 [100/798 (12%)]\tLoss: 0.021670\n",
      "Train Epoch: 30 [200/798 (25%)]\tLoss: 0.419138\n",
      "Train Epoch: 30 [300/798 (38%)]\tLoss: 0.090469\n",
      "Train Epoch: 30 [400/798 (50%)]\tLoss: 0.280576\n",
      "Train Epoch: 30 [500/798 (62%)]\tLoss: 0.385183\n",
      "Train Epoch: 30 [600/798 (75%)]\tLoss: 0.165403\n",
      "Train Epoch: 30 [700/798 (88%)]\tLoss: 0.071214\n",
      "\n",
      "Test set: Avg. loss: 0.0455, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 31 [0/798 (0%)]\tLoss: 0.317764\n",
      "Train Epoch: 31 [100/798 (12%)]\tLoss: 0.068954\n",
      "Train Epoch: 31 [200/798 (25%)]\tLoss: 0.524607\n",
      "Train Epoch: 31 [300/798 (38%)]\tLoss: 0.089874\n",
      "Train Epoch: 31 [400/798 (50%)]\tLoss: 0.572495\n",
      "Train Epoch: 31 [500/798 (62%)]\tLoss: 0.095722\n",
      "Train Epoch: 31 [600/798 (75%)]\tLoss: 0.272385\n",
      "Train Epoch: 31 [700/798 (88%)]\tLoss: 0.494153\n",
      "\n",
      "Test set: Avg. loss: 0.0495, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 32 [0/798 (0%)]\tLoss: 0.249996\n",
      "Train Epoch: 32 [100/798 (12%)]\tLoss: 0.284805\n",
      "Train Epoch: 32 [200/798 (25%)]\tLoss: 0.706351\n",
      "Train Epoch: 32 [300/798 (38%)]\tLoss: 0.178841\n",
      "Train Epoch: 32 [400/798 (50%)]\tLoss: 0.083585\n",
      "Train Epoch: 32 [500/798 (62%)]\tLoss: 0.501116\n",
      "Train Epoch: 32 [600/798 (75%)]\tLoss: 0.267984\n",
      "Train Epoch: 32 [700/798 (88%)]\tLoss: 0.176553\n",
      "\n",
      "Test set: Avg. loss: 0.0679, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 33 [0/798 (0%)]\tLoss: 0.321211\n",
      "Train Epoch: 33 [100/798 (12%)]\tLoss: 0.035270\n",
      "Train Epoch: 33 [200/798 (25%)]\tLoss: 0.317730\n",
      "Train Epoch: 33 [300/798 (38%)]\tLoss: 0.178888\n",
      "Train Epoch: 33 [400/798 (50%)]\tLoss: 0.304949\n",
      "Train Epoch: 33 [500/798 (62%)]\tLoss: 0.054547\n",
      "Train Epoch: 33 [600/798 (75%)]\tLoss: 0.879134\n",
      "Train Epoch: 33 [700/798 (88%)]\tLoss: 0.660290\n",
      "\n",
      "Test set: Avg. loss: 0.0518, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 34 [0/798 (0%)]\tLoss: 0.264018\n",
      "Train Epoch: 34 [100/798 (12%)]\tLoss: 0.083588\n",
      "Train Epoch: 34 [200/798 (25%)]\tLoss: 0.567381\n",
      "Train Epoch: 34 [300/798 (38%)]\tLoss: 0.369413\n",
      "Train Epoch: 34 [400/798 (50%)]\tLoss: 0.535370\n",
      "Train Epoch: 34 [500/798 (62%)]\tLoss: 0.468017\n",
      "Train Epoch: 34 [600/798 (75%)]\tLoss: 0.169978\n",
      "Train Epoch: 34 [700/798 (88%)]\tLoss: 0.453652\n",
      "\n",
      "Test set: Avg. loss: 0.0372, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 35 [0/798 (0%)]\tLoss: 0.023883\n",
      "Train Epoch: 35 [100/798 (12%)]\tLoss: 0.291508\n",
      "Train Epoch: 35 [200/798 (25%)]\tLoss: 0.140395\n",
      "Train Epoch: 35 [300/798 (38%)]\tLoss: 0.172125\n",
      "Train Epoch: 35 [400/798 (50%)]\tLoss: 0.448592\n",
      "Train Epoch: 35 [500/798 (62%)]\tLoss: 0.234110\n",
      "Train Epoch: 35 [600/798 (75%)]\tLoss: 0.287861\n",
      "Train Epoch: 35 [700/798 (88%)]\tLoss: 0.157329\n",
      "\n",
      "Test set: Avg. loss: 0.0278, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 36 [0/798 (0%)]\tLoss: 0.010911\n",
      "Train Epoch: 36 [100/798 (12%)]\tLoss: 0.085683\n",
      "Train Epoch: 36 [200/798 (25%)]\tLoss: 0.304623\n",
      "Train Epoch: 36 [300/798 (38%)]\tLoss: 0.010248\n",
      "Train Epoch: 36 [400/798 (50%)]\tLoss: 0.077710\n",
      "Train Epoch: 36 [500/798 (62%)]\tLoss: 0.503867\n",
      "Train Epoch: 36 [600/798 (75%)]\tLoss: 0.721664\n",
      "Train Epoch: 36 [700/798 (88%)]\tLoss: 0.024740\n",
      "\n",
      "Test set: Avg. loss: 0.0516, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 37 [0/798 (0%)]\tLoss: 0.164167\n",
      "Train Epoch: 37 [100/798 (12%)]\tLoss: 0.150866\n",
      "Train Epoch: 37 [200/798 (25%)]\tLoss: 0.207183\n",
      "Train Epoch: 37 [300/798 (38%)]\tLoss: 0.073159\n",
      "Train Epoch: 37 [400/798 (50%)]\tLoss: 0.395132\n",
      "Train Epoch: 37 [500/798 (62%)]\tLoss: 0.150832\n",
      "Train Epoch: 37 [600/798 (75%)]\tLoss: 0.422992\n",
      "Train Epoch: 37 [700/798 (88%)]\tLoss: 0.474040\n",
      "\n",
      "Test set: Avg. loss: 0.0424, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 38 [0/798 (0%)]\tLoss: 0.157287\n",
      "Train Epoch: 38 [100/798 (12%)]\tLoss: 0.035812\n",
      "Train Epoch: 38 [200/798 (25%)]\tLoss: 0.207174\n",
      "Train Epoch: 38 [300/798 (38%)]\tLoss: 0.386038\n",
      "Train Epoch: 38 [400/798 (50%)]\tLoss: 0.092626\n",
      "Train Epoch: 38 [500/798 (62%)]\tLoss: 0.204716\n",
      "Train Epoch: 38 [600/798 (75%)]\tLoss: 0.534878\n",
      "Train Epoch: 38 [700/798 (88%)]\tLoss: 0.161559\n",
      "\n",
      "Test set: Avg. loss: 0.0451, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 39 [0/798 (0%)]\tLoss: 0.125324\n",
      "Train Epoch: 39 [100/798 (12%)]\tLoss: 0.083783\n",
      "Train Epoch: 39 [200/798 (25%)]\tLoss: 0.137627\n",
      "Train Epoch: 39 [300/798 (38%)]\tLoss: 0.223649\n",
      "Train Epoch: 39 [400/798 (50%)]\tLoss: 0.586515\n",
      "Train Epoch: 39 [500/798 (62%)]\tLoss: 0.154759\n",
      "Train Epoch: 39 [600/798 (75%)]\tLoss: 0.325669\n",
      "Train Epoch: 39 [700/798 (88%)]\tLoss: 0.498865\n",
      "\n",
      "Test set: Avg. loss: 0.0352, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 40 [0/798 (0%)]\tLoss: 0.374595\n",
      "Train Epoch: 40 [100/798 (12%)]\tLoss: 0.048268\n",
      "Train Epoch: 40 [200/798 (25%)]\tLoss: 0.434960\n",
      "Train Epoch: 40 [300/798 (38%)]\tLoss: 0.262519\n",
      "Train Epoch: 40 [400/798 (50%)]\tLoss: 0.169582\n",
      "Train Epoch: 40 [500/798 (62%)]\tLoss: 0.014624\n",
      "Train Epoch: 40 [600/798 (75%)]\tLoss: 0.481855\n",
      "Train Epoch: 40 [700/798 (88%)]\tLoss: 0.816993\n",
      "\n",
      "Test set: Avg. loss: 0.0648, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 41 [0/798 (0%)]\tLoss: 0.304928\n",
      "Train Epoch: 41 [100/798 (12%)]\tLoss: 0.160134\n",
      "Train Epoch: 41 [200/798 (25%)]\tLoss: 0.014719\n",
      "Train Epoch: 41 [300/798 (38%)]\tLoss: 0.089730\n",
      "Train Epoch: 41 [400/798 (50%)]\tLoss: 0.252190\n",
      "Train Epoch: 41 [500/798 (62%)]\tLoss: 0.533975\n",
      "Train Epoch: 41 [600/798 (75%)]\tLoss: 0.329806\n",
      "Train Epoch: 41 [700/798 (88%)]\tLoss: 0.294202\n",
      "\n",
      "Test set: Avg. loss: 0.0355, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 42 [0/798 (0%)]\tLoss: 0.038028\n",
      "Train Epoch: 42 [100/798 (12%)]\tLoss: 0.232054\n",
      "Train Epoch: 42 [200/798 (25%)]\tLoss: 0.071489\n",
      "Train Epoch: 42 [300/798 (38%)]\tLoss: 0.004053\n",
      "Train Epoch: 42 [400/798 (50%)]\tLoss: 0.563339\n",
      "Train Epoch: 42 [500/798 (62%)]\tLoss: 0.384173\n",
      "Train Epoch: 42 [600/798 (75%)]\tLoss: 0.520456\n",
      "Train Epoch: 42 [700/798 (88%)]\tLoss: 0.487144\n",
      "\n",
      "Test set: Avg. loss: 0.0270, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 43 [0/798 (0%)]\tLoss: 0.726564\n",
      "Train Epoch: 43 [100/798 (12%)]\tLoss: 0.058027\n",
      "Train Epoch: 43 [200/798 (25%)]\tLoss: 0.008030\n",
      "Train Epoch: 43 [300/798 (38%)]\tLoss: 0.290440\n",
      "Train Epoch: 43 [400/798 (50%)]\tLoss: 0.411216\n",
      "Train Epoch: 43 [500/798 (62%)]\tLoss: 0.347019\n",
      "Train Epoch: 43 [600/798 (75%)]\tLoss: 0.392606\n",
      "Train Epoch: 43 [700/798 (88%)]\tLoss: 0.214526\n",
      "\n",
      "Test set: Avg. loss: 0.0261, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 44 [0/798 (0%)]\tLoss: 0.112399\n",
      "Train Epoch: 44 [100/798 (12%)]\tLoss: 0.149866\n",
      "Train Epoch: 44 [200/798 (25%)]\tLoss: 0.163436\n",
      "Train Epoch: 44 [300/798 (38%)]\tLoss: 0.741934\n",
      "Train Epoch: 44 [400/798 (50%)]\tLoss: 0.619380\n",
      "Train Epoch: 44 [500/798 (62%)]\tLoss: 0.041596\n",
      "Train Epoch: 44 [600/798 (75%)]\tLoss: 0.458857\n",
      "Train Epoch: 44 [700/798 (88%)]\tLoss: 0.168079\n",
      "\n",
      "Test set: Avg. loss: 0.0233, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 45 [0/798 (0%)]\tLoss: 0.141976\n",
      "Train Epoch: 45 [100/798 (12%)]\tLoss: 0.167789\n",
      "Train Epoch: 45 [200/798 (25%)]\tLoss: 0.082948\n",
      "Train Epoch: 45 [300/798 (38%)]\tLoss: 0.198482\n",
      "Train Epoch: 45 [400/798 (50%)]\tLoss: 0.021271\n",
      "Train Epoch: 45 [500/798 (62%)]\tLoss: 0.304053\n",
      "Train Epoch: 45 [600/798 (75%)]\tLoss: 0.103444\n",
      "Train Epoch: 45 [700/798 (88%)]\tLoss: 0.141589\n",
      "\n",
      "Test set: Avg. loss: 0.0176, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 46 [0/798 (0%)]\tLoss: 0.122613\n",
      "Train Epoch: 46 [100/798 (12%)]\tLoss: 0.153687\n",
      "Train Epoch: 46 [200/798 (25%)]\tLoss: 0.038488\n",
      "Train Epoch: 46 [300/798 (38%)]\tLoss: 0.218932\n",
      "Train Epoch: 46 [400/798 (50%)]\tLoss: 0.184635\n",
      "Train Epoch: 46 [500/798 (62%)]\tLoss: 0.056300\n",
      "Train Epoch: 46 [600/798 (75%)]\tLoss: 0.130680\n",
      "Train Epoch: 46 [700/798 (88%)]\tLoss: 0.066684\n",
      "\n",
      "Test set: Avg. loss: 0.0245, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 47 [0/798 (0%)]\tLoss: 0.490226\n",
      "Train Epoch: 47 [100/798 (12%)]\tLoss: 0.941641\n",
      "Train Epoch: 47 [200/798 (25%)]\tLoss: 0.728984\n",
      "Train Epoch: 47 [300/798 (38%)]\tLoss: 0.449682\n",
      "Train Epoch: 47 [400/798 (50%)]\tLoss: 0.303337\n",
      "Train Epoch: 47 [500/798 (62%)]\tLoss: 0.092618\n",
      "Train Epoch: 47 [600/798 (75%)]\tLoss: 0.056058\n",
      "Train Epoch: 47 [700/798 (88%)]\tLoss: 0.203599\n",
      "\n",
      "Test set: Avg. loss: 0.0433, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 48 [0/798 (0%)]\tLoss: 0.177136\n",
      "Train Epoch: 48 [100/798 (12%)]\tLoss: 0.285538\n",
      "Train Epoch: 48 [200/798 (25%)]\tLoss: 0.012100\n",
      "Train Epoch: 48 [300/798 (38%)]\tLoss: 0.265796\n",
      "Train Epoch: 48 [400/798 (50%)]\tLoss: 0.249633\n",
      "Train Epoch: 48 [500/798 (62%)]\tLoss: 0.306641\n",
      "Train Epoch: 48 [600/798 (75%)]\tLoss: 0.029495\n",
      "Train Epoch: 48 [700/798 (88%)]\tLoss: 0.027957\n",
      "\n",
      "Test set: Avg. loss: 0.0278, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 49 [0/798 (0%)]\tLoss: 0.378039\n",
      "Train Epoch: 49 [100/798 (12%)]\tLoss: 0.068810\n",
      "Train Epoch: 49 [200/798 (25%)]\tLoss: 0.258257\n",
      "Train Epoch: 49 [300/798 (38%)]\tLoss: 0.344238\n",
      "Train Epoch: 49 [400/798 (50%)]\tLoss: 0.048568\n",
      "Train Epoch: 49 [500/798 (62%)]\tLoss: 0.108603\n",
      "Train Epoch: 49 [600/798 (75%)]\tLoss: 0.329986\n",
      "Train Epoch: 49 [700/798 (88%)]\tLoss: 0.294006\n",
      "\n",
      "Test set: Avg. loss: 0.0239, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 50 [0/798 (0%)]\tLoss: 0.060198\n",
      "Train Epoch: 50 [100/798 (12%)]\tLoss: 0.047477\n",
      "Train Epoch: 50 [200/798 (25%)]\tLoss: 0.126850\n",
      "Train Epoch: 50 [300/798 (38%)]\tLoss: 0.063785\n",
      "Train Epoch: 50 [400/798 (50%)]\tLoss: 0.057899\n",
      "Train Epoch: 50 [500/798 (62%)]\tLoss: 0.330233\n",
      "Train Epoch: 50 [600/798 (75%)]\tLoss: 0.101336\n",
      "Train Epoch: 50 [700/798 (88%)]\tLoss: 0.254239\n",
      "\n",
      "Test set: Avg. loss: 0.0256, Accuracy: 199/200 (100%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0256, Accuracy: 199/200 (100%)\n",
      "\n",
      "Running bootstrap experiment: 9\n",
      "Train Epoch: 1 [0/798 (0%)]\tLoss: 2.412808\n",
      "Train Epoch: 1 [100/798 (12%)]\tLoss: 2.317214\n",
      "Train Epoch: 1 [200/798 (25%)]\tLoss: 2.302866\n",
      "Train Epoch: 1 [300/798 (38%)]\tLoss: 2.289159\n",
      "Train Epoch: 1 [400/798 (50%)]\tLoss: 2.359224\n",
      "Train Epoch: 1 [500/798 (62%)]\tLoss: 2.332310\n",
      "Train Epoch: 1 [600/798 (75%)]\tLoss: 2.295802\n",
      "Train Epoch: 1 [700/798 (88%)]\tLoss: 2.312264\n",
      "\n",
      "Test set: Avg. loss: 2.2918, Accuracy: 31/200 (16%)\n",
      "\n",
      "Train Epoch: 2 [0/798 (0%)]\tLoss: 2.268990\n",
      "Train Epoch: 2 [100/798 (12%)]\tLoss: 2.262238\n",
      "Train Epoch: 2 [200/798 (25%)]\tLoss: 2.293319\n",
      "Train Epoch: 2 [300/798 (38%)]\tLoss: 2.366814\n",
      "Train Epoch: 2 [400/798 (50%)]\tLoss: 2.257999\n",
      "Train Epoch: 2 [500/798 (62%)]\tLoss: 2.327236\n",
      "Train Epoch: 2 [600/798 (75%)]\tLoss: 2.289551\n",
      "Train Epoch: 2 [700/798 (88%)]\tLoss: 2.309914\n",
      "\n",
      "Test set: Avg. loss: 2.2831, Accuracy: 22/200 (11%)\n",
      "\n",
      "Train Epoch: 3 [0/798 (0%)]\tLoss: 2.271417\n",
      "Train Epoch: 3 [100/798 (12%)]\tLoss: 2.268816\n",
      "Train Epoch: 3 [200/798 (25%)]\tLoss: 2.291903\n",
      "Train Epoch: 3 [300/798 (38%)]\tLoss: 2.230815\n",
      "Train Epoch: 3 [400/798 (50%)]\tLoss: 2.273102\n",
      "Train Epoch: 3 [500/798 (62%)]\tLoss: 2.276083\n",
      "Train Epoch: 3 [600/798 (75%)]\tLoss: 2.321853\n",
      "Train Epoch: 3 [700/798 (88%)]\tLoss: 2.398655\n",
      "\n",
      "Test set: Avg. loss: 2.2661, Accuracy: 37/200 (18%)\n",
      "\n",
      "Train Epoch: 4 [0/798 (0%)]\tLoss: 2.226757\n",
      "Train Epoch: 4 [100/798 (12%)]\tLoss: 2.233210\n",
      "Train Epoch: 4 [200/798 (25%)]\tLoss: 2.207396\n",
      "Train Epoch: 4 [300/798 (38%)]\tLoss: 2.306279\n",
      "Train Epoch: 4 [400/798 (50%)]\tLoss: 2.292022\n",
      "Train Epoch: 4 [500/798 (62%)]\tLoss: 2.200362\n",
      "Train Epoch: 4 [600/798 (75%)]\tLoss: 2.274161\n",
      "Train Epoch: 4 [700/798 (88%)]\tLoss: 2.209186\n",
      "\n",
      "Test set: Avg. loss: 2.2175, Accuracy: 60/200 (30%)\n",
      "\n",
      "Train Epoch: 5 [0/798 (0%)]\tLoss: 2.160457\n",
      "Train Epoch: 5 [100/798 (12%)]\tLoss: 2.275937\n",
      "Train Epoch: 5 [200/798 (25%)]\tLoss: 2.387184\n",
      "Train Epoch: 5 [300/798 (38%)]\tLoss: 2.264596\n",
      "Train Epoch: 5 [400/798 (50%)]\tLoss: 2.199206\n",
      "Train Epoch: 5 [500/798 (62%)]\tLoss: 2.197925\n",
      "Train Epoch: 5 [600/798 (75%)]\tLoss: 2.201238\n",
      "Train Epoch: 5 [700/798 (88%)]\tLoss: 2.245334\n",
      "\n",
      "Test set: Avg. loss: 2.0911, Accuracy: 76/200 (38%)\n",
      "\n",
      "Train Epoch: 6 [0/798 (0%)]\tLoss: 2.141314\n",
      "Train Epoch: 6 [100/798 (12%)]\tLoss: 2.019206\n",
      "Train Epoch: 6 [200/798 (25%)]\tLoss: 1.703527\n",
      "Train Epoch: 6 [300/798 (38%)]\tLoss: 1.981456\n",
      "Train Epoch: 6 [400/798 (50%)]\tLoss: 1.948735\n",
      "Train Epoch: 6 [500/798 (62%)]\tLoss: 2.060906\n",
      "Train Epoch: 6 [600/798 (75%)]\tLoss: 2.105953\n",
      "Train Epoch: 6 [700/798 (88%)]\tLoss: 2.078511\n",
      "\n",
      "Test set: Avg. loss: 1.8184, Accuracy: 124/200 (62%)\n",
      "\n",
      "Train Epoch: 7 [0/798 (0%)]\tLoss: 2.120457\n",
      "Train Epoch: 7 [100/798 (12%)]\tLoss: 1.894932\n",
      "Train Epoch: 7 [200/798 (25%)]\tLoss: 1.691490\n",
      "Train Epoch: 7 [300/798 (38%)]\tLoss: 1.916873\n",
      "Train Epoch: 7 [400/798 (50%)]\tLoss: 1.646018\n",
      "Train Epoch: 7 [500/798 (62%)]\tLoss: 1.541353\n",
      "Train Epoch: 7 [600/798 (75%)]\tLoss: 1.876710\n",
      "Train Epoch: 7 [700/798 (88%)]\tLoss: 1.623611\n",
      "\n",
      "Test set: Avg. loss: 1.4057, Accuracy: 128/200 (64%)\n",
      "\n",
      "Train Epoch: 8 [0/798 (0%)]\tLoss: 1.956854\n",
      "Train Epoch: 8 [100/798 (12%)]\tLoss: 1.596606\n",
      "Train Epoch: 8 [200/798 (25%)]\tLoss: 1.927166\n",
      "Train Epoch: 8 [300/798 (38%)]\tLoss: 1.381371\n",
      "Train Epoch: 8 [400/798 (50%)]\tLoss: 1.850868\n",
      "Train Epoch: 8 [500/798 (62%)]\tLoss: 1.829690\n",
      "Train Epoch: 8 [600/798 (75%)]\tLoss: 1.337353\n",
      "Train Epoch: 8 [700/798 (88%)]\tLoss: 1.538634\n",
      "\n",
      "Test set: Avg. loss: 0.9424, Accuracy: 173/200 (86%)\n",
      "\n",
      "Train Epoch: 9 [0/798 (0%)]\tLoss: 1.180647\n",
      "Train Epoch: 9 [100/798 (12%)]\tLoss: 1.030309\n",
      "Train Epoch: 9 [200/798 (25%)]\tLoss: 1.604532\n",
      "Train Epoch: 9 [300/798 (38%)]\tLoss: 1.299684\n",
      "Train Epoch: 9 [400/798 (50%)]\tLoss: 1.785016\n",
      "Train Epoch: 9 [500/798 (62%)]\tLoss: 1.143960\n",
      "Train Epoch: 9 [600/798 (75%)]\tLoss: 1.327194\n",
      "Train Epoch: 9 [700/798 (88%)]\tLoss: 1.329629\n",
      "\n",
      "Test set: Avg. loss: 0.6939, Accuracy: 192/200 (96%)\n",
      "\n",
      "Train Epoch: 10 [0/798 (0%)]\tLoss: 1.368001\n",
      "Train Epoch: 10 [100/798 (12%)]\tLoss: 0.664582\n",
      "Train Epoch: 10 [200/798 (25%)]\tLoss: 0.739188\n",
      "Train Epoch: 10 [300/798 (38%)]\tLoss: 1.716473\n",
      "Train Epoch: 10 [400/798 (50%)]\tLoss: 1.042157\n",
      "Train Epoch: 10 [500/798 (62%)]\tLoss: 0.901436\n",
      "Train Epoch: 10 [600/798 (75%)]\tLoss: 0.446297\n",
      "Train Epoch: 10 [700/798 (88%)]\tLoss: 1.228690\n",
      "\n",
      "Test set: Avg. loss: 0.4191, Accuracy: 187/200 (94%)\n",
      "\n",
      "Train Epoch: 11 [0/798 (0%)]\tLoss: 1.275922\n",
      "Train Epoch: 11 [100/798 (12%)]\tLoss: 0.556793\n",
      "Train Epoch: 11 [200/798 (25%)]\tLoss: 1.476652\n",
      "Train Epoch: 11 [300/798 (38%)]\tLoss: 1.116736\n",
      "Train Epoch: 11 [400/798 (50%)]\tLoss: 0.906584\n",
      "Train Epoch: 11 [500/798 (62%)]\tLoss: 0.826116\n",
      "Train Epoch: 11 [600/798 (75%)]\tLoss: 0.976753\n",
      "Train Epoch: 11 [700/798 (88%)]\tLoss: 1.374092\n",
      "\n",
      "Test set: Avg. loss: 0.3669, Accuracy: 191/200 (96%)\n",
      "\n",
      "Train Epoch: 12 [0/798 (0%)]\tLoss: 0.879270\n",
      "Train Epoch: 12 [100/798 (12%)]\tLoss: 1.103092\n",
      "Train Epoch: 12 [200/798 (25%)]\tLoss: 1.164752\n",
      "Train Epoch: 12 [300/798 (38%)]\tLoss: 0.486294\n",
      "Train Epoch: 12 [400/798 (50%)]\tLoss: 0.513533\n",
      "Train Epoch: 12 [500/798 (62%)]\tLoss: 0.833563\n",
      "Train Epoch: 12 [600/798 (75%)]\tLoss: 0.801032\n",
      "Train Epoch: 12 [700/798 (88%)]\tLoss: 1.188530\n",
      "\n",
      "Test set: Avg. loss: 0.2902, Accuracy: 191/200 (96%)\n",
      "\n",
      "Train Epoch: 13 [0/798 (0%)]\tLoss: 0.540712\n",
      "Train Epoch: 13 [100/798 (12%)]\tLoss: 1.010378\n",
      "Train Epoch: 13 [200/798 (25%)]\tLoss: 0.699900\n",
      "Train Epoch: 13 [300/798 (38%)]\tLoss: 0.739280\n",
      "Train Epoch: 13 [400/798 (50%)]\tLoss: 0.402780\n",
      "Train Epoch: 13 [500/798 (62%)]\tLoss: 0.734473\n",
      "Train Epoch: 13 [600/798 (75%)]\tLoss: 1.045474\n",
      "Train Epoch: 13 [700/798 (88%)]\tLoss: 0.313762\n",
      "\n",
      "Test set: Avg. loss: 0.2528, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/798 (0%)]\tLoss: 0.640411\n",
      "Train Epoch: 14 [100/798 (12%)]\tLoss: 0.593210\n",
      "Train Epoch: 14 [200/798 (25%)]\tLoss: 1.109150\n",
      "Train Epoch: 14 [300/798 (38%)]\tLoss: 1.020140\n",
      "Train Epoch: 14 [400/798 (50%)]\tLoss: 0.413971\n",
      "Train Epoch: 14 [500/798 (62%)]\tLoss: 0.386864\n",
      "Train Epoch: 14 [600/798 (75%)]\tLoss: 1.516692\n",
      "Train Epoch: 14 [700/798 (88%)]\tLoss: 0.715669\n",
      "\n",
      "Test set: Avg. loss: 0.2563, Accuracy: 192/200 (96%)\n",
      "\n",
      "Train Epoch: 15 [0/798 (0%)]\tLoss: 0.995186\n",
      "Train Epoch: 15 [100/798 (12%)]\tLoss: 0.663937\n",
      "Train Epoch: 15 [200/798 (25%)]\tLoss: 0.437419\n",
      "Train Epoch: 15 [300/798 (38%)]\tLoss: 0.534500\n",
      "Train Epoch: 15 [400/798 (50%)]\tLoss: 0.744749\n",
      "Train Epoch: 15 [500/798 (62%)]\tLoss: 0.050471\n",
      "Train Epoch: 15 [600/798 (75%)]\tLoss: 0.504008\n",
      "Train Epoch: 15 [700/798 (88%)]\tLoss: 1.011040\n",
      "\n",
      "Test set: Avg. loss: 0.1962, Accuracy: 193/200 (96%)\n",
      "\n",
      "Train Epoch: 16 [0/798 (0%)]\tLoss: 0.468542\n",
      "Train Epoch: 16 [100/798 (12%)]\tLoss: 1.051075\n",
      "Train Epoch: 16 [200/798 (25%)]\tLoss: 1.090596\n",
      "Train Epoch: 16 [300/798 (38%)]\tLoss: 0.833172\n",
      "Train Epoch: 16 [400/798 (50%)]\tLoss: 0.710834\n",
      "Train Epoch: 16 [500/798 (62%)]\tLoss: 0.425232\n",
      "Train Epoch: 16 [600/798 (75%)]\tLoss: 0.432940\n",
      "Train Epoch: 16 [700/798 (88%)]\tLoss: 0.156265\n",
      "\n",
      "Test set: Avg. loss: 0.1409, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/798 (0%)]\tLoss: 0.497098\n",
      "Train Epoch: 17 [100/798 (12%)]\tLoss: 0.577934\n",
      "Train Epoch: 17 [200/798 (25%)]\tLoss: 0.271689\n",
      "Train Epoch: 17 [300/798 (38%)]\tLoss: 0.680389\n",
      "Train Epoch: 17 [400/798 (50%)]\tLoss: 0.304888\n",
      "Train Epoch: 17 [500/798 (62%)]\tLoss: 0.739852\n",
      "Train Epoch: 17 [600/798 (75%)]\tLoss: 0.239784\n",
      "Train Epoch: 17 [700/798 (88%)]\tLoss: 0.420070\n",
      "\n",
      "Test set: Avg. loss: 0.1191, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/798 (0%)]\tLoss: 0.267779\n",
      "Train Epoch: 18 [100/798 (12%)]\tLoss: 0.510649\n",
      "Train Epoch: 18 [200/798 (25%)]\tLoss: 0.480509\n",
      "Train Epoch: 18 [300/798 (38%)]\tLoss: 0.787571\n",
      "Train Epoch: 18 [400/798 (50%)]\tLoss: 0.606100\n",
      "Train Epoch: 18 [500/798 (62%)]\tLoss: 0.280002\n",
      "Train Epoch: 18 [600/798 (75%)]\tLoss: 0.639434\n",
      "Train Epoch: 18 [700/798 (88%)]\tLoss: 0.158602\n",
      "\n",
      "Test set: Avg. loss: 0.1076, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/798 (0%)]\tLoss: 0.203354\n",
      "Train Epoch: 19 [100/798 (12%)]\tLoss: 0.418555\n",
      "Train Epoch: 19 [200/798 (25%)]\tLoss: 0.451059\n",
      "Train Epoch: 19 [300/798 (38%)]\tLoss: 0.290781\n",
      "Train Epoch: 19 [400/798 (50%)]\tLoss: 0.464574\n",
      "Train Epoch: 19 [500/798 (62%)]\tLoss: 0.456001\n",
      "Train Epoch: 19 [600/798 (75%)]\tLoss: 0.251624\n",
      "Train Epoch: 19 [700/798 (88%)]\tLoss: 0.649365\n",
      "\n",
      "Test set: Avg. loss: 0.1679, Accuracy: 190/200 (95%)\n",
      "\n",
      "Train Epoch: 20 [0/798 (0%)]\tLoss: 0.874182\n",
      "Train Epoch: 20 [100/798 (12%)]\tLoss: 0.313718\n",
      "Train Epoch: 20 [200/798 (25%)]\tLoss: 0.262669\n",
      "Train Epoch: 20 [300/798 (38%)]\tLoss: 0.389475\n",
      "Train Epoch: 20 [400/798 (50%)]\tLoss: 0.133916\n",
      "Train Epoch: 20 [500/798 (62%)]\tLoss: 0.882441\n",
      "Train Epoch: 20 [600/798 (75%)]\tLoss: 0.623712\n",
      "Train Epoch: 20 [700/798 (88%)]\tLoss: 0.570735\n",
      "\n",
      "Test set: Avg. loss: 0.0791, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/798 (0%)]\tLoss: 1.062290\n",
      "Train Epoch: 21 [100/798 (12%)]\tLoss: 0.099465\n",
      "Train Epoch: 21 [200/798 (25%)]\tLoss: 0.314370\n",
      "Train Epoch: 21 [300/798 (38%)]\tLoss: 0.310055\n",
      "Train Epoch: 21 [400/798 (50%)]\tLoss: 0.131383\n",
      "Train Epoch: 21 [500/798 (62%)]\tLoss: 0.489196\n",
      "Train Epoch: 21 [600/798 (75%)]\tLoss: 0.237122\n",
      "Train Epoch: 21 [700/798 (88%)]\tLoss: 0.403557\n",
      "\n",
      "Test set: Avg. loss: 0.0879, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/798 (0%)]\tLoss: 0.501438\n",
      "Train Epoch: 22 [100/798 (12%)]\tLoss: 0.264711\n",
      "Train Epoch: 22 [200/798 (25%)]\tLoss: 0.379399\n",
      "Train Epoch: 22 [300/798 (38%)]\tLoss: 1.172746\n",
      "Train Epoch: 22 [400/798 (50%)]\tLoss: 0.272290\n",
      "Train Epoch: 22 [500/798 (62%)]\tLoss: 0.259340\n",
      "Train Epoch: 22 [600/798 (75%)]\tLoss: 0.458171\n",
      "Train Epoch: 22 [700/798 (88%)]\tLoss: 0.782903\n",
      "\n",
      "Test set: Avg. loss: 0.1015, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/798 (0%)]\tLoss: 0.395098\n",
      "Train Epoch: 23 [100/798 (12%)]\tLoss: 0.381994\n",
      "Train Epoch: 23 [200/798 (25%)]\tLoss: 0.069516\n",
      "Train Epoch: 23 [300/798 (38%)]\tLoss: 0.068118\n",
      "Train Epoch: 23 [400/798 (50%)]\tLoss: 0.543648\n",
      "Train Epoch: 23 [500/798 (62%)]\tLoss: 0.670204\n",
      "Train Epoch: 23 [600/798 (75%)]\tLoss: 0.172098\n",
      "Train Epoch: 23 [700/798 (88%)]\tLoss: 0.764510\n",
      "\n",
      "Test set: Avg. loss: 0.0983, Accuracy: 193/200 (96%)\n",
      "\n",
      "Train Epoch: 24 [0/798 (0%)]\tLoss: 0.032794\n",
      "Train Epoch: 24 [100/798 (12%)]\tLoss: 0.267541\n",
      "Train Epoch: 24 [200/798 (25%)]\tLoss: 0.155190\n",
      "Train Epoch: 24 [300/798 (38%)]\tLoss: 0.605291\n",
      "Train Epoch: 24 [400/798 (50%)]\tLoss: 0.112150\n",
      "Train Epoch: 24 [500/798 (62%)]\tLoss: 0.578332\n",
      "Train Epoch: 24 [600/798 (75%)]\tLoss: 0.429811\n",
      "Train Epoch: 24 [700/798 (88%)]\tLoss: 0.396760\n",
      "\n",
      "Test set: Avg. loss: 0.0585, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 25 [0/798 (0%)]\tLoss: 0.440911\n",
      "Train Epoch: 25 [100/798 (12%)]\tLoss: 0.127993\n",
      "Train Epoch: 25 [200/798 (25%)]\tLoss: 0.486918\n",
      "Train Epoch: 25 [300/798 (38%)]\tLoss: 0.289150\n",
      "Train Epoch: 25 [400/798 (50%)]\tLoss: 0.276450\n",
      "Train Epoch: 25 [500/798 (62%)]\tLoss: 0.040821\n",
      "Train Epoch: 25 [600/798 (75%)]\tLoss: 0.141878\n",
      "Train Epoch: 25 [700/798 (88%)]\tLoss: 0.330934\n",
      "\n",
      "Test set: Avg. loss: 0.0709, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/798 (0%)]\tLoss: 0.633030\n",
      "Train Epoch: 26 [100/798 (12%)]\tLoss: 0.177495\n",
      "Train Epoch: 26 [200/798 (25%)]\tLoss: 0.284322\n",
      "Train Epoch: 26 [300/798 (38%)]\tLoss: 0.054849\n",
      "Train Epoch: 26 [400/798 (50%)]\tLoss: 0.591570\n",
      "Train Epoch: 26 [500/798 (62%)]\tLoss: 0.128737\n",
      "Train Epoch: 26 [600/798 (75%)]\tLoss: 0.349604\n",
      "Train Epoch: 26 [700/798 (88%)]\tLoss: 0.587848\n",
      "\n",
      "Test set: Avg. loss: 0.0669, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/798 (0%)]\tLoss: 0.033473\n",
      "Train Epoch: 27 [100/798 (12%)]\tLoss: 0.121731\n",
      "Train Epoch: 27 [200/798 (25%)]\tLoss: 0.263200\n",
      "Train Epoch: 27 [300/798 (38%)]\tLoss: 0.366133\n",
      "Train Epoch: 27 [400/798 (50%)]\tLoss: 0.144467\n",
      "Train Epoch: 27 [500/798 (62%)]\tLoss: 0.120104\n",
      "Train Epoch: 27 [600/798 (75%)]\tLoss: 0.459999\n",
      "Train Epoch: 27 [700/798 (88%)]\tLoss: 0.181489\n",
      "\n",
      "Test set: Avg. loss: 0.0499, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/798 (0%)]\tLoss: 0.532618\n",
      "Train Epoch: 28 [100/798 (12%)]\tLoss: 0.037156\n",
      "Train Epoch: 28 [200/798 (25%)]\tLoss: 0.749978\n",
      "Train Epoch: 28 [300/798 (38%)]\tLoss: 0.095314\n",
      "Train Epoch: 28 [400/798 (50%)]\tLoss: 0.002176\n",
      "Train Epoch: 28 [500/798 (62%)]\tLoss: 0.032347\n",
      "Train Epoch: 28 [600/798 (75%)]\tLoss: 0.149277\n",
      "Train Epoch: 28 [700/798 (88%)]\tLoss: 0.654850\n",
      "\n",
      "Test set: Avg. loss: 0.0393, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 29 [0/798 (0%)]\tLoss: 0.369691\n",
      "Train Epoch: 29 [100/798 (12%)]\tLoss: 0.462314\n",
      "Train Epoch: 29 [200/798 (25%)]\tLoss: 0.238713\n",
      "Train Epoch: 29 [300/798 (38%)]\tLoss: 0.084966\n",
      "Train Epoch: 29 [400/798 (50%)]\tLoss: 0.232132\n",
      "Train Epoch: 29 [500/798 (62%)]\tLoss: 0.407187\n",
      "Train Epoch: 29 [600/798 (75%)]\tLoss: 0.070058\n",
      "Train Epoch: 29 [700/798 (88%)]\tLoss: 0.134653\n",
      "\n",
      "Test set: Avg. loss: 0.0332, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 30 [0/798 (0%)]\tLoss: 0.064507\n",
      "Train Epoch: 30 [100/798 (12%)]\tLoss: 0.264422\n",
      "Train Epoch: 30 [200/798 (25%)]\tLoss: 0.660986\n",
      "Train Epoch: 30 [300/798 (38%)]\tLoss: 0.028050\n",
      "Train Epoch: 30 [400/798 (50%)]\tLoss: 0.650904\n",
      "Train Epoch: 30 [500/798 (62%)]\tLoss: 0.168933\n",
      "Train Epoch: 30 [600/798 (75%)]\tLoss: 0.249143\n",
      "Train Epoch: 30 [700/798 (88%)]\tLoss: 0.124752\n",
      "\n",
      "Test set: Avg. loss: 0.0601, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/798 (0%)]\tLoss: 0.030258\n",
      "Train Epoch: 31 [100/798 (12%)]\tLoss: 0.151942\n",
      "Train Epoch: 31 [200/798 (25%)]\tLoss: 0.460549\n",
      "Train Epoch: 31 [300/798 (38%)]\tLoss: 0.111461\n",
      "Train Epoch: 31 [400/798 (50%)]\tLoss: 0.293027\n",
      "Train Epoch: 31 [500/798 (62%)]\tLoss: 0.206043\n",
      "Train Epoch: 31 [600/798 (75%)]\tLoss: 0.090049\n",
      "Train Epoch: 31 [700/798 (88%)]\tLoss: 0.202809\n",
      "\n",
      "Test set: Avg. loss: 0.0593, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 32 [0/798 (0%)]\tLoss: 0.028170\n",
      "Train Epoch: 32 [100/798 (12%)]\tLoss: 0.157160\n",
      "Train Epoch: 32 [200/798 (25%)]\tLoss: 0.066453\n",
      "Train Epoch: 32 [300/798 (38%)]\tLoss: 0.242967\n",
      "Train Epoch: 32 [400/798 (50%)]\tLoss: 0.705041\n",
      "Train Epoch: 32 [500/798 (62%)]\tLoss: 0.197125\n",
      "Train Epoch: 32 [600/798 (75%)]\tLoss: 0.096449\n",
      "Train Epoch: 32 [700/798 (88%)]\tLoss: 0.101587\n",
      "\n",
      "Test set: Avg. loss: 0.0354, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 33 [0/798 (0%)]\tLoss: 0.675831\n",
      "Train Epoch: 33 [100/798 (12%)]\tLoss: 0.243267\n",
      "Train Epoch: 33 [200/798 (25%)]\tLoss: 0.166332\n",
      "Train Epoch: 33 [300/798 (38%)]\tLoss: 0.091594\n",
      "Train Epoch: 33 [400/798 (50%)]\tLoss: 0.233551\n",
      "Train Epoch: 33 [500/798 (62%)]\tLoss: 0.292267\n",
      "Train Epoch: 33 [600/798 (75%)]\tLoss: 0.063012\n",
      "Train Epoch: 33 [700/798 (88%)]\tLoss: 0.041734\n",
      "\n",
      "Test set: Avg. loss: 0.0407, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/798 (0%)]\tLoss: 0.118369\n",
      "Train Epoch: 34 [100/798 (12%)]\tLoss: 0.118822\n",
      "Train Epoch: 34 [200/798 (25%)]\tLoss: 0.098701\n",
      "Train Epoch: 34 [300/798 (38%)]\tLoss: 0.062054\n",
      "Train Epoch: 34 [400/798 (50%)]\tLoss: 0.111813\n",
      "Train Epoch: 34 [500/798 (62%)]\tLoss: 0.061155\n",
      "Train Epoch: 34 [600/798 (75%)]\tLoss: 0.449613\n",
      "Train Epoch: 34 [700/798 (88%)]\tLoss: 0.242415\n",
      "\n",
      "Test set: Avg. loss: 0.0374, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 35 [0/798 (0%)]\tLoss: 0.799744\n",
      "Train Epoch: 35 [100/798 (12%)]\tLoss: 0.495212\n",
      "Train Epoch: 35 [200/798 (25%)]\tLoss: 0.284457\n",
      "Train Epoch: 35 [300/798 (38%)]\tLoss: 0.864708\n",
      "Train Epoch: 35 [400/798 (50%)]\tLoss: 0.139908\n",
      "Train Epoch: 35 [500/798 (62%)]\tLoss: 0.360682\n",
      "Train Epoch: 35 [600/798 (75%)]\tLoss: 0.194124\n",
      "Train Epoch: 35 [700/798 (88%)]\tLoss: 0.134870\n",
      "\n",
      "Test set: Avg. loss: 0.0455, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 36 [0/798 (0%)]\tLoss: 0.293988\n",
      "Train Epoch: 36 [100/798 (12%)]\tLoss: 0.262182\n",
      "Train Epoch: 36 [200/798 (25%)]\tLoss: 0.294402\n",
      "Train Epoch: 36 [300/798 (38%)]\tLoss: 0.560934\n",
      "Train Epoch: 36 [400/798 (50%)]\tLoss: 0.163343\n",
      "Train Epoch: 36 [500/798 (62%)]\tLoss: 0.752425\n",
      "Train Epoch: 36 [600/798 (75%)]\tLoss: 0.325422\n",
      "Train Epoch: 36 [700/798 (88%)]\tLoss: 0.033942\n",
      "\n",
      "Test set: Avg. loss: 0.0418, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 37 [0/798 (0%)]\tLoss: 0.037672\n",
      "Train Epoch: 37 [100/798 (12%)]\tLoss: 0.152115\n",
      "Train Epoch: 37 [200/798 (25%)]\tLoss: 0.244668\n",
      "Train Epoch: 37 [300/798 (38%)]\tLoss: 0.032330\n",
      "Train Epoch: 37 [400/798 (50%)]\tLoss: 0.051037\n",
      "Train Epoch: 37 [500/798 (62%)]\tLoss: 0.068406\n",
      "Train Epoch: 37 [600/798 (75%)]\tLoss: 0.002636\n",
      "Train Epoch: 37 [700/798 (88%)]\tLoss: 0.203729\n",
      "\n",
      "Test set: Avg. loss: 0.0587, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 38 [0/798 (0%)]\tLoss: 0.662252\n",
      "Train Epoch: 38 [100/798 (12%)]\tLoss: 0.104377\n",
      "Train Epoch: 38 [200/798 (25%)]\tLoss: 0.251762\n",
      "Train Epoch: 38 [300/798 (38%)]\tLoss: 0.383775\n",
      "Train Epoch: 38 [400/798 (50%)]\tLoss: 0.182938\n",
      "Train Epoch: 38 [500/798 (62%)]\tLoss: 0.568669\n",
      "Train Epoch: 38 [600/798 (75%)]\tLoss: 0.436233\n",
      "Train Epoch: 38 [700/798 (88%)]\tLoss: 0.056450\n",
      "\n",
      "Test set: Avg. loss: 0.0375, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 39 [0/798 (0%)]\tLoss: 0.534396\n",
      "Train Epoch: 39 [100/798 (12%)]\tLoss: 0.153359\n",
      "Train Epoch: 39 [200/798 (25%)]\tLoss: 0.418530\n",
      "Train Epoch: 39 [300/798 (38%)]\tLoss: 0.064510\n",
      "Train Epoch: 39 [400/798 (50%)]\tLoss: 0.260787\n",
      "Train Epoch: 39 [500/798 (62%)]\tLoss: 0.049453\n",
      "Train Epoch: 39 [600/798 (75%)]\tLoss: 0.530578\n",
      "Train Epoch: 39 [700/798 (88%)]\tLoss: 0.022230\n",
      "\n",
      "Test set: Avg. loss: 0.0581, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 40 [0/798 (0%)]\tLoss: 0.008195\n",
      "Train Epoch: 40 [100/798 (12%)]\tLoss: 0.136152\n",
      "Train Epoch: 40 [200/798 (25%)]\tLoss: 0.017495\n",
      "Train Epoch: 40 [300/798 (38%)]\tLoss: 1.199738\n",
      "Train Epoch: 40 [400/798 (50%)]\tLoss: 0.279215\n",
      "Train Epoch: 40 [500/798 (62%)]\tLoss: 0.104664\n",
      "Train Epoch: 40 [600/798 (75%)]\tLoss: 0.006687\n",
      "Train Epoch: 40 [700/798 (88%)]\tLoss: 0.018577\n",
      "\n",
      "Test set: Avg. loss: 0.0264, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 41 [0/798 (0%)]\tLoss: 0.435212\n",
      "Train Epoch: 41 [100/798 (12%)]\tLoss: 0.390603\n",
      "Train Epoch: 41 [200/798 (25%)]\tLoss: 0.110123\n",
      "Train Epoch: 41 [300/798 (38%)]\tLoss: 0.063750\n",
      "Train Epoch: 41 [400/798 (50%)]\tLoss: 0.030267\n",
      "Train Epoch: 41 [500/798 (62%)]\tLoss: 0.300842\n",
      "Train Epoch: 41 [600/798 (75%)]\tLoss: 0.259909\n",
      "Train Epoch: 41 [700/798 (88%)]\tLoss: 0.064604\n",
      "\n",
      "Test set: Avg. loss: 0.0547, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 42 [0/798 (0%)]\tLoss: 0.422264\n",
      "Train Epoch: 42 [100/798 (12%)]\tLoss: 1.136175\n",
      "Train Epoch: 42 [200/798 (25%)]\tLoss: 0.005348\n",
      "Train Epoch: 42 [300/798 (38%)]\tLoss: 0.192769\n",
      "Train Epoch: 42 [400/798 (50%)]\tLoss: 0.005792\n",
      "Train Epoch: 42 [500/798 (62%)]\tLoss: 0.002526\n",
      "Train Epoch: 42 [600/798 (75%)]\tLoss: 0.020865\n",
      "Train Epoch: 42 [700/798 (88%)]\tLoss: 0.092465\n",
      "\n",
      "Test set: Avg. loss: 0.0418, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 43 [0/798 (0%)]\tLoss: 0.383198\n",
      "Train Epoch: 43 [100/798 (12%)]\tLoss: 0.015487\n",
      "Train Epoch: 43 [200/798 (25%)]\tLoss: 0.198574\n",
      "Train Epoch: 43 [300/798 (38%)]\tLoss: 0.203622\n",
      "Train Epoch: 43 [400/798 (50%)]\tLoss: 0.264802\n",
      "Train Epoch: 43 [500/798 (62%)]\tLoss: 0.030307\n",
      "Train Epoch: 43 [600/798 (75%)]\tLoss: 0.116863\n",
      "Train Epoch: 43 [700/798 (88%)]\tLoss: 0.032206\n",
      "\n",
      "Test set: Avg. loss: 0.0412, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 44 [0/798 (0%)]\tLoss: 0.146631\n",
      "Train Epoch: 44 [100/798 (12%)]\tLoss: 0.071658\n",
      "Train Epoch: 44 [200/798 (25%)]\tLoss: 0.019673\n",
      "Train Epoch: 44 [300/798 (38%)]\tLoss: 0.039182\n",
      "Train Epoch: 44 [400/798 (50%)]\tLoss: 0.680121\n",
      "Train Epoch: 44 [500/798 (62%)]\tLoss: 0.253244\n",
      "Train Epoch: 44 [600/798 (75%)]\tLoss: 0.002440\n",
      "Train Epoch: 44 [700/798 (88%)]\tLoss: 0.292215\n",
      "\n",
      "Test set: Avg. loss: 0.0540, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 45 [0/798 (0%)]\tLoss: 0.013790\n",
      "Train Epoch: 45 [100/798 (12%)]\tLoss: 0.033032\n",
      "Train Epoch: 45 [200/798 (25%)]\tLoss: 0.002274\n",
      "Train Epoch: 45 [300/798 (38%)]\tLoss: 0.389812\n",
      "Train Epoch: 45 [400/798 (50%)]\tLoss: 0.042470\n",
      "Train Epoch: 45 [500/798 (62%)]\tLoss: 0.148265\n",
      "Train Epoch: 45 [600/798 (75%)]\tLoss: 0.374705\n",
      "Train Epoch: 45 [700/798 (88%)]\tLoss: 0.123724\n",
      "\n",
      "Test set: Avg. loss: 0.0110, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 46 [0/798 (0%)]\tLoss: 0.284167\n",
      "Train Epoch: 46 [100/798 (12%)]\tLoss: 0.383261\n",
      "Train Epoch: 46 [200/798 (25%)]\tLoss: 0.002871\n",
      "Train Epoch: 46 [300/798 (38%)]\tLoss: 0.099892\n",
      "Train Epoch: 46 [400/798 (50%)]\tLoss: 0.025333\n",
      "Train Epoch: 46 [500/798 (62%)]\tLoss: 0.136117\n",
      "Train Epoch: 46 [600/798 (75%)]\tLoss: 0.036295\n",
      "Train Epoch: 46 [700/798 (88%)]\tLoss: 0.172265\n",
      "\n",
      "Test set: Avg. loss: 0.0234, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 47 [0/798 (0%)]\tLoss: 0.174215\n",
      "Train Epoch: 47 [100/798 (12%)]\tLoss: 0.178788\n",
      "Train Epoch: 47 [200/798 (25%)]\tLoss: 0.086235\n",
      "Train Epoch: 47 [300/798 (38%)]\tLoss: 0.634845\n",
      "Train Epoch: 47 [400/798 (50%)]\tLoss: 0.039895\n",
      "Train Epoch: 47 [500/798 (62%)]\tLoss: 0.023993\n",
      "Train Epoch: 47 [600/798 (75%)]\tLoss: 0.292350\n",
      "Train Epoch: 47 [700/798 (88%)]\tLoss: 0.054882\n",
      "\n",
      "Test set: Avg. loss: 0.0360, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 48 [0/798 (0%)]\tLoss: 0.013729\n",
      "Train Epoch: 48 [100/798 (12%)]\tLoss: 0.000945\n",
      "Train Epoch: 48 [200/798 (25%)]\tLoss: 0.051251\n",
      "Train Epoch: 48 [300/798 (38%)]\tLoss: 0.056644\n",
      "Train Epoch: 48 [400/798 (50%)]\tLoss: 0.086645\n",
      "Train Epoch: 48 [500/798 (62%)]\tLoss: 0.650440\n",
      "Train Epoch: 48 [600/798 (75%)]\tLoss: 0.232902\n",
      "Train Epoch: 48 [700/798 (88%)]\tLoss: 0.110147\n",
      "\n",
      "Test set: Avg. loss: 0.0125, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 49 [0/798 (0%)]\tLoss: 0.086290\n",
      "Train Epoch: 49 [100/798 (12%)]\tLoss: 0.017568\n",
      "Train Epoch: 49 [200/798 (25%)]\tLoss: 0.415329\n",
      "Train Epoch: 49 [300/798 (38%)]\tLoss: 0.000856\n",
      "Train Epoch: 49 [400/798 (50%)]\tLoss: 0.310376\n",
      "Train Epoch: 49 [500/798 (62%)]\tLoss: 0.148816\n",
      "Train Epoch: 49 [600/798 (75%)]\tLoss: 0.189536\n",
      "Train Epoch: 49 [700/798 (88%)]\tLoss: 0.016564\n",
      "\n",
      "Test set: Avg. loss: 0.0568, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 50 [0/798 (0%)]\tLoss: 0.263282\n",
      "Train Epoch: 50 [100/798 (12%)]\tLoss: 0.062957\n",
      "Train Epoch: 50 [200/798 (25%)]\tLoss: 0.054687\n",
      "Train Epoch: 50 [300/798 (38%)]\tLoss: 0.101339\n",
      "Train Epoch: 50 [400/798 (50%)]\tLoss: 0.041017\n",
      "Train Epoch: 50 [500/798 (62%)]\tLoss: 0.036387\n",
      "Train Epoch: 50 [600/798 (75%)]\tLoss: 0.724857\n",
      "Train Epoch: 50 [700/798 (88%)]\tLoss: 0.789508\n",
      "\n",
      "Test set: Avg. loss: 0.0326, Accuracy: 197/200 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0326, Accuracy: 197/200 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = bootstrap_experiment(50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It looks like this is much btter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/798 (0%)]\tLoss: 2.327458\n",
      "Train Epoch: 1 [100/798 (12%)]\tLoss: 2.255511\n",
      "Train Epoch: 1 [200/798 (25%)]\tLoss: 2.272627\n",
      "Train Epoch: 1 [300/798 (38%)]\tLoss: 2.324379\n",
      "Train Epoch: 1 [400/798 (50%)]\tLoss: 2.305150\n",
      "Train Epoch: 1 [500/798 (62%)]\tLoss: 2.377299\n",
      "Train Epoch: 1 [600/798 (75%)]\tLoss: 2.316823\n",
      "Train Epoch: 1 [700/798 (88%)]\tLoss: 2.329024\n",
      "\n",
      "Test set: Avg. loss: 2.3006, Accuracy: 24/200 (12%)\n",
      "\n",
      "Train Epoch: 2 [0/798 (0%)]\tLoss: 2.316864\n",
      "Train Epoch: 2 [100/798 (12%)]\tLoss: 2.289572\n",
      "Train Epoch: 2 [200/798 (25%)]\tLoss: 2.311148\n",
      "Train Epoch: 2 [300/798 (38%)]\tLoss: 2.312396\n",
      "Train Epoch: 2 [400/798 (50%)]\tLoss: 2.297044\n",
      "Train Epoch: 2 [500/798 (62%)]\tLoss: 2.262494\n",
      "Train Epoch: 2 [600/798 (75%)]\tLoss: 2.310344\n",
      "Train Epoch: 2 [700/798 (88%)]\tLoss: 2.227211\n",
      "\n",
      "Test set: Avg. loss: 2.2850, Accuracy: 41/200 (20%)\n",
      "\n",
      "Train Epoch: 3 [0/798 (0%)]\tLoss: 2.335038\n",
      "Train Epoch: 3 [100/798 (12%)]\tLoss: 2.247199\n",
      "Train Epoch: 3 [200/798 (25%)]\tLoss: 2.232827\n",
      "Train Epoch: 3 [300/798 (38%)]\tLoss: 2.281665\n",
      "Train Epoch: 3 [400/798 (50%)]\tLoss: 2.233399\n",
      "Train Epoch: 3 [500/798 (62%)]\tLoss: 2.312641\n",
      "Train Epoch: 3 [600/798 (75%)]\tLoss: 2.236316\n",
      "Train Epoch: 3 [700/798 (88%)]\tLoss: 2.282947\n",
      "\n",
      "Test set: Avg. loss: 2.2510, Accuracy: 59/200 (30%)\n",
      "\n",
      "Train Epoch: 4 [0/798 (0%)]\tLoss: 2.323568\n",
      "Train Epoch: 4 [100/798 (12%)]\tLoss: 2.355956\n",
      "Train Epoch: 4 [200/798 (25%)]\tLoss: 2.202698\n",
      "Train Epoch: 4 [300/798 (38%)]\tLoss: 2.205495\n",
      "Train Epoch: 4 [400/798 (50%)]\tLoss: 2.183485\n",
      "Train Epoch: 4 [500/798 (62%)]\tLoss: 2.050833\n",
      "Train Epoch: 4 [600/798 (75%)]\tLoss: 2.146229\n",
      "Train Epoch: 4 [700/798 (88%)]\tLoss: 2.013511\n",
      "\n",
      "Test set: Avg. loss: 2.1465, Accuracy: 64/200 (32%)\n",
      "\n",
      "Train Epoch: 5 [0/798 (0%)]\tLoss: 2.261576\n",
      "Train Epoch: 5 [100/798 (12%)]\tLoss: 2.067879\n",
      "Train Epoch: 5 [200/798 (25%)]\tLoss: 2.079840\n",
      "Train Epoch: 5 [300/798 (38%)]\tLoss: 2.028410\n",
      "Train Epoch: 5 [400/798 (50%)]\tLoss: 2.068699\n",
      "Train Epoch: 5 [500/798 (62%)]\tLoss: 1.827436\n",
      "Train Epoch: 5 [600/798 (75%)]\tLoss: 2.239217\n",
      "Train Epoch: 5 [700/798 (88%)]\tLoss: 1.908305\n",
      "\n",
      "Test set: Avg. loss: 1.9169, Accuracy: 100/200 (50%)\n",
      "\n",
      "Train Epoch: 6 [0/798 (0%)]\tLoss: 1.937178\n",
      "Train Epoch: 6 [100/798 (12%)]\tLoss: 1.846765\n",
      "Train Epoch: 6 [200/798 (25%)]\tLoss: 1.827271\n",
      "Train Epoch: 6 [300/798 (38%)]\tLoss: 1.947750\n",
      "Train Epoch: 6 [400/798 (50%)]\tLoss: 1.820559\n",
      "Train Epoch: 6 [500/798 (62%)]\tLoss: 1.568912\n",
      "Train Epoch: 6 [600/798 (75%)]\tLoss: 1.639727\n",
      "Train Epoch: 6 [700/798 (88%)]\tLoss: 1.408394\n",
      "\n",
      "Test set: Avg. loss: 1.5987, Accuracy: 100/200 (50%)\n",
      "\n",
      "Train Epoch: 7 [0/798 (0%)]\tLoss: 1.612627\n",
      "Train Epoch: 7 [100/798 (12%)]\tLoss: 1.692289\n",
      "Train Epoch: 7 [200/798 (25%)]\tLoss: 1.517186\n",
      "Train Epoch: 7 [300/798 (38%)]\tLoss: 1.723734\n",
      "Train Epoch: 7 [400/798 (50%)]\tLoss: 1.767224\n",
      "Train Epoch: 7 [500/798 (62%)]\tLoss: 1.758225\n",
      "Train Epoch: 7 [600/798 (75%)]\tLoss: 1.448182\n",
      "Train Epoch: 7 [700/798 (88%)]\tLoss: 1.563723\n",
      "\n",
      "Test set: Avg. loss: 1.3698, Accuracy: 121/200 (60%)\n",
      "\n",
      "Train Epoch: 8 [0/798 (0%)]\tLoss: 1.860264\n",
      "Train Epoch: 8 [100/798 (12%)]\tLoss: 1.395244\n",
      "Train Epoch: 8 [200/798 (25%)]\tLoss: 1.949747\n",
      "Train Epoch: 8 [300/798 (38%)]\tLoss: 1.198247\n",
      "Train Epoch: 8 [400/798 (50%)]\tLoss: 1.297028\n",
      "Train Epoch: 8 [500/798 (62%)]\tLoss: 1.529265\n",
      "Train Epoch: 8 [600/798 (75%)]\tLoss: 1.533501\n",
      "Train Epoch: 8 [700/798 (88%)]\tLoss: 1.617656\n",
      "\n",
      "Test set: Avg. loss: 1.0489, Accuracy: 157/200 (78%)\n",
      "\n",
      "Train Epoch: 9 [0/798 (0%)]\tLoss: 1.310610\n",
      "Train Epoch: 9 [100/798 (12%)]\tLoss: 1.369693\n",
      "Train Epoch: 9 [200/798 (25%)]\tLoss: 1.357412\n",
      "Train Epoch: 9 [300/798 (38%)]\tLoss: 1.319593\n",
      "Train Epoch: 9 [400/798 (50%)]\tLoss: 1.271342\n",
      "Train Epoch: 9 [500/798 (62%)]\tLoss: 1.586929\n",
      "Train Epoch: 9 [600/798 (75%)]\tLoss: 1.579869\n",
      "Train Epoch: 9 [700/798 (88%)]\tLoss: 1.512216\n",
      "\n",
      "Test set: Avg. loss: 0.7418, Accuracy: 182/200 (91%)\n",
      "\n",
      "Train Epoch: 10 [0/798 (0%)]\tLoss: 2.102529\n",
      "Train Epoch: 10 [100/798 (12%)]\tLoss: 1.082520\n",
      "Train Epoch: 10 [200/798 (25%)]\tLoss: 0.642233\n",
      "Train Epoch: 10 [300/798 (38%)]\tLoss: 0.981159\n",
      "Train Epoch: 10 [400/798 (50%)]\tLoss: 0.867631\n",
      "Train Epoch: 10 [500/798 (62%)]\tLoss: 1.039907\n",
      "Train Epoch: 10 [600/798 (75%)]\tLoss: 1.486533\n",
      "Train Epoch: 10 [700/798 (88%)]\tLoss: 1.186426\n",
      "\n",
      "Test set: Avg. loss: 0.6301, Accuracy: 189/200 (94%)\n",
      "\n",
      "Train Epoch: 11 [0/798 (0%)]\tLoss: 1.353364\n",
      "Train Epoch: 11 [100/798 (12%)]\tLoss: 1.212783\n",
      "Train Epoch: 11 [200/798 (25%)]\tLoss: 1.202422\n",
      "Train Epoch: 11 [300/798 (38%)]\tLoss: 0.805666\n",
      "Train Epoch: 11 [400/798 (50%)]\tLoss: 0.963664\n",
      "Train Epoch: 11 [500/798 (62%)]\tLoss: 1.091508\n",
      "Train Epoch: 11 [600/798 (75%)]\tLoss: 0.859110\n",
      "Train Epoch: 11 [700/798 (88%)]\tLoss: 0.791290\n",
      "\n",
      "Test set: Avg. loss: 0.4205, Accuracy: 176/200 (88%)\n",
      "\n",
      "Train Epoch: 12 [0/798 (0%)]\tLoss: 1.118366\n",
      "Train Epoch: 12 [100/798 (12%)]\tLoss: 0.821033\n",
      "Train Epoch: 12 [200/798 (25%)]\tLoss: 1.072103\n",
      "Train Epoch: 12 [300/798 (38%)]\tLoss: 1.037855\n",
      "Train Epoch: 12 [400/798 (50%)]\tLoss: 1.071553\n",
      "Train Epoch: 12 [500/798 (62%)]\tLoss: 0.692470\n",
      "Train Epoch: 12 [600/798 (75%)]\tLoss: 0.746955\n",
      "Train Epoch: 12 [700/798 (88%)]\tLoss: 0.597111\n",
      "\n",
      "Test set: Avg. loss: 0.3679, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 13 [0/798 (0%)]\tLoss: 0.499979\n",
      "Train Epoch: 13 [100/798 (12%)]\tLoss: 0.627144\n",
      "Train Epoch: 13 [200/798 (25%)]\tLoss: 0.594090\n",
      "Train Epoch: 13 [300/798 (38%)]\tLoss: 1.520859\n",
      "Train Epoch: 13 [400/798 (50%)]\tLoss: 0.305888\n",
      "Train Epoch: 13 [500/798 (62%)]\tLoss: 1.398220\n",
      "Train Epoch: 13 [600/798 (75%)]\tLoss: 1.393972\n",
      "Train Epoch: 13 [700/798 (88%)]\tLoss: 0.318131\n",
      "\n",
      "Test set: Avg. loss: 0.2827, Accuracy: 192/200 (96%)\n",
      "\n",
      "Train Epoch: 14 [0/798 (0%)]\tLoss: 0.943492\n",
      "Train Epoch: 14 [100/798 (12%)]\tLoss: 0.762600\n",
      "Train Epoch: 14 [200/798 (25%)]\tLoss: 0.623284\n",
      "Train Epoch: 14 [300/798 (38%)]\tLoss: 0.996704\n",
      "Train Epoch: 14 [400/798 (50%)]\tLoss: 0.924302\n",
      "Train Epoch: 14 [500/798 (62%)]\tLoss: 1.133994\n",
      "Train Epoch: 14 [600/798 (75%)]\tLoss: 0.623235\n",
      "Train Epoch: 14 [700/798 (88%)]\tLoss: 1.070178\n",
      "\n",
      "Test set: Avg. loss: 0.2424, Accuracy: 191/200 (96%)\n",
      "\n",
      "Train Epoch: 15 [0/798 (0%)]\tLoss: 0.969121\n",
      "Train Epoch: 15 [100/798 (12%)]\tLoss: 0.340669\n",
      "Train Epoch: 15 [200/798 (25%)]\tLoss: 0.462220\n",
      "Train Epoch: 15 [300/798 (38%)]\tLoss: 0.645952\n",
      "Train Epoch: 15 [400/798 (50%)]\tLoss: 1.407236\n",
      "Train Epoch: 15 [500/798 (62%)]\tLoss: 0.792930\n",
      "Train Epoch: 15 [600/798 (75%)]\tLoss: 0.696135\n",
      "Train Epoch: 15 [700/798 (88%)]\tLoss: 0.917436\n",
      "\n",
      "Test set: Avg. loss: 0.1842, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/798 (0%)]\tLoss: 0.572702\n",
      "Train Epoch: 16 [100/798 (12%)]\tLoss: 0.445801\n",
      "Train Epoch: 16 [200/798 (25%)]\tLoss: 0.233629\n",
      "Train Epoch: 16 [300/798 (38%)]\tLoss: 0.325866\n",
      "Train Epoch: 16 [400/798 (50%)]\tLoss: 0.847151\n",
      "Train Epoch: 16 [500/798 (62%)]\tLoss: 0.499125\n",
      "Train Epoch: 16 [600/798 (75%)]\tLoss: 0.390975\n",
      "Train Epoch: 16 [700/798 (88%)]\tLoss: 0.711426\n",
      "\n",
      "Test set: Avg. loss: 0.1975, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 17 [0/798 (0%)]\tLoss: 0.677043\n",
      "Train Epoch: 17 [100/798 (12%)]\tLoss: 0.447557\n",
      "Train Epoch: 17 [200/798 (25%)]\tLoss: 1.153237\n",
      "Train Epoch: 17 [300/798 (38%)]\tLoss: 0.584745\n",
      "Train Epoch: 17 [400/798 (50%)]\tLoss: 0.534852\n",
      "Train Epoch: 17 [500/798 (62%)]\tLoss: 0.328497\n",
      "Train Epoch: 17 [600/798 (75%)]\tLoss: 0.371533\n",
      "Train Epoch: 17 [700/798 (88%)]\tLoss: 0.481874\n",
      "\n",
      "Test set: Avg. loss: 0.1851, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 18 [0/798 (0%)]\tLoss: 1.079666\n",
      "Train Epoch: 18 [100/798 (12%)]\tLoss: 1.373904\n",
      "Train Epoch: 18 [200/798 (25%)]\tLoss: 0.818859\n",
      "Train Epoch: 18 [300/798 (38%)]\tLoss: 0.448847\n",
      "Train Epoch: 18 [400/798 (50%)]\tLoss: 0.677934\n",
      "Train Epoch: 18 [500/798 (62%)]\tLoss: 0.322870\n",
      "Train Epoch: 18 [600/798 (75%)]\tLoss: 0.675322\n",
      "Train Epoch: 18 [700/798 (88%)]\tLoss: 0.772976\n",
      "\n",
      "Test set: Avg. loss: 0.1302, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/798 (0%)]\tLoss: 0.355421\n",
      "Train Epoch: 19 [100/798 (12%)]\tLoss: 0.234188\n",
      "Train Epoch: 19 [200/798 (25%)]\tLoss: 0.415446\n",
      "Train Epoch: 19 [300/798 (38%)]\tLoss: 0.410035\n",
      "Train Epoch: 19 [400/798 (50%)]\tLoss: 0.632093\n",
      "Train Epoch: 19 [500/798 (62%)]\tLoss: 0.396848\n",
      "Train Epoch: 19 [600/798 (75%)]\tLoss: 0.679493\n",
      "Train Epoch: 19 [700/798 (88%)]\tLoss: 0.292499\n",
      "\n",
      "Test set: Avg. loss: 0.1504, Accuracy: 193/200 (96%)\n",
      "\n",
      "Train Epoch: 20 [0/798 (0%)]\tLoss: 0.528760\n",
      "Train Epoch: 20 [100/798 (12%)]\tLoss: 0.616647\n",
      "Train Epoch: 20 [200/798 (25%)]\tLoss: 0.438111\n",
      "Train Epoch: 20 [300/798 (38%)]\tLoss: 0.320051\n",
      "Train Epoch: 20 [400/798 (50%)]\tLoss: 0.369401\n",
      "Train Epoch: 20 [500/798 (62%)]\tLoss: 0.341697\n",
      "Train Epoch: 20 [600/798 (75%)]\tLoss: 0.787324\n",
      "Train Epoch: 20 [700/798 (88%)]\tLoss: 0.440497\n",
      "\n",
      "Test set: Avg. loss: 0.1147, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/798 (0%)]\tLoss: 0.176674\n",
      "Train Epoch: 21 [100/798 (12%)]\tLoss: 0.184600\n",
      "Train Epoch: 21 [200/798 (25%)]\tLoss: 0.299925\n",
      "Train Epoch: 21 [300/798 (38%)]\tLoss: 0.272228\n",
      "Train Epoch: 21 [400/798 (50%)]\tLoss: 0.348563\n",
      "Train Epoch: 21 [500/798 (62%)]\tLoss: 0.342265\n",
      "Train Epoch: 21 [600/798 (75%)]\tLoss: 0.278350\n",
      "Train Epoch: 21 [700/798 (88%)]\tLoss: 0.192436\n",
      "\n",
      "Test set: Avg. loss: 0.0920, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/798 (0%)]\tLoss: 0.598002\n",
      "Train Epoch: 22 [100/798 (12%)]\tLoss: 0.341633\n",
      "Train Epoch: 22 [200/798 (25%)]\tLoss: 0.293181\n",
      "Train Epoch: 22 [300/798 (38%)]\tLoss: 0.160973\n",
      "Train Epoch: 22 [400/798 (50%)]\tLoss: 0.694324\n",
      "Train Epoch: 22 [500/798 (62%)]\tLoss: 0.365184\n",
      "Train Epoch: 22 [600/798 (75%)]\tLoss: 0.507210\n",
      "Train Epoch: 22 [700/798 (88%)]\tLoss: 0.400138\n",
      "\n",
      "Test set: Avg. loss: 0.0741, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 23 [0/798 (0%)]\tLoss: 0.414244\n",
      "Train Epoch: 23 [100/798 (12%)]\tLoss: 0.330135\n",
      "Train Epoch: 23 [200/798 (25%)]\tLoss: 0.288649\n",
      "Train Epoch: 23 [300/798 (38%)]\tLoss: 0.709978\n",
      "Train Epoch: 23 [400/798 (50%)]\tLoss: 0.509214\n",
      "Train Epoch: 23 [500/798 (62%)]\tLoss: 0.176495\n",
      "Train Epoch: 23 [600/798 (75%)]\tLoss: 1.045393\n",
      "Train Epoch: 23 [700/798 (88%)]\tLoss: 0.599680\n",
      "\n",
      "Test set: Avg. loss: 0.0865, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/798 (0%)]\tLoss: 0.650768\n",
      "Train Epoch: 24 [100/798 (12%)]\tLoss: 0.006524\n",
      "Train Epoch: 24 [200/798 (25%)]\tLoss: 0.680826\n",
      "Train Epoch: 24 [300/798 (38%)]\tLoss: 0.843319\n",
      "Train Epoch: 24 [400/798 (50%)]\tLoss: 0.214423\n",
      "Train Epoch: 24 [500/798 (62%)]\tLoss: 0.205098\n",
      "Train Epoch: 24 [600/798 (75%)]\tLoss: 0.456959\n",
      "Train Epoch: 24 [700/798 (88%)]\tLoss: 0.204085\n",
      "\n",
      "Test set: Avg. loss: 0.0865, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/798 (0%)]\tLoss: 0.285148\n",
      "Train Epoch: 25 [100/798 (12%)]\tLoss: 0.393147\n",
      "Train Epoch: 25 [200/798 (25%)]\tLoss: 0.448515\n",
      "Train Epoch: 25 [300/798 (38%)]\tLoss: 0.060491\n",
      "Train Epoch: 25 [400/798 (50%)]\tLoss: 0.836540\n",
      "Train Epoch: 25 [500/798 (62%)]\tLoss: 0.069747\n",
      "Train Epoch: 25 [600/798 (75%)]\tLoss: 0.302241\n",
      "Train Epoch: 25 [700/798 (88%)]\tLoss: 0.214319\n",
      "\n",
      "Test set: Avg. loss: 0.0947, Accuracy: 195/200 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/798 (0%)]\tLoss: 0.501059\n",
      "Train Epoch: 26 [100/798 (12%)]\tLoss: 0.105771\n",
      "Train Epoch: 26 [200/798 (25%)]\tLoss: 0.371514\n",
      "Train Epoch: 26 [300/798 (38%)]\tLoss: 0.128877\n",
      "Train Epoch: 26 [400/798 (50%)]\tLoss: 0.378575\n",
      "Train Epoch: 26 [500/798 (62%)]\tLoss: 0.238740\n",
      "Train Epoch: 26 [600/798 (75%)]\tLoss: 0.356944\n",
      "Train Epoch: 26 [700/798 (88%)]\tLoss: 0.229182\n",
      "\n",
      "Test set: Avg. loss: 0.0774, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/798 (0%)]\tLoss: 0.250967\n",
      "Train Epoch: 27 [100/798 (12%)]\tLoss: 0.083678\n",
      "Train Epoch: 27 [200/798 (25%)]\tLoss: 0.018433\n",
      "Train Epoch: 27 [300/798 (38%)]\tLoss: 0.111477\n",
      "Train Epoch: 27 [400/798 (50%)]\tLoss: 0.557797\n",
      "Train Epoch: 27 [500/798 (62%)]\tLoss: 0.684687\n",
      "Train Epoch: 27 [600/798 (75%)]\tLoss: 0.423280\n",
      "Train Epoch: 27 [700/798 (88%)]\tLoss: 0.173535\n",
      "\n",
      "Test set: Avg. loss: 0.0643, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/798 (0%)]\tLoss: 0.674489\n",
      "Train Epoch: 28 [100/798 (12%)]\tLoss: 0.161907\n",
      "Train Epoch: 28 [200/798 (25%)]\tLoss: 0.315475\n",
      "Train Epoch: 28 [300/798 (38%)]\tLoss: 0.332156\n",
      "Train Epoch: 28 [400/798 (50%)]\tLoss: 0.758849\n",
      "Train Epoch: 28 [500/798 (62%)]\tLoss: 0.376131\n",
      "Train Epoch: 28 [600/798 (75%)]\tLoss: 0.534808\n",
      "Train Epoch: 28 [700/798 (88%)]\tLoss: 0.367837\n",
      "\n",
      "Test set: Avg. loss: 0.0507, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/798 (0%)]\tLoss: 0.060774\n",
      "Train Epoch: 29 [100/798 (12%)]\tLoss: 0.050928\n",
      "Train Epoch: 29 [200/798 (25%)]\tLoss: 0.258726\n",
      "Train Epoch: 29 [300/798 (38%)]\tLoss: 0.196585\n",
      "Train Epoch: 29 [400/798 (50%)]\tLoss: 0.364069\n",
      "Train Epoch: 29 [500/798 (62%)]\tLoss: 0.347481\n",
      "Train Epoch: 29 [600/798 (75%)]\tLoss: 0.152345\n",
      "Train Epoch: 29 [700/798 (88%)]\tLoss: 0.060215\n",
      "\n",
      "Test set: Avg. loss: 0.0510, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 30 [0/798 (0%)]\tLoss: 0.478491\n",
      "Train Epoch: 30 [100/798 (12%)]\tLoss: 0.273448\n",
      "Train Epoch: 30 [200/798 (25%)]\tLoss: 0.426819\n",
      "Train Epoch: 30 [300/798 (38%)]\tLoss: 0.233146\n",
      "Train Epoch: 30 [400/798 (50%)]\tLoss: 0.430691\n",
      "Train Epoch: 30 [500/798 (62%)]\tLoss: 0.304596\n",
      "Train Epoch: 30 [600/798 (75%)]\tLoss: 0.186363\n",
      "Train Epoch: 30 [700/798 (88%)]\tLoss: 0.250945\n",
      "\n",
      "Test set: Avg. loss: 0.0650, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/798 (0%)]\tLoss: 0.338205\n",
      "Train Epoch: 31 [100/798 (12%)]\tLoss: 0.298544\n",
      "Train Epoch: 31 [200/798 (25%)]\tLoss: 0.493737\n",
      "Train Epoch: 31 [300/798 (38%)]\tLoss: 0.117360\n",
      "Train Epoch: 31 [400/798 (50%)]\tLoss: 0.426367\n",
      "Train Epoch: 31 [500/798 (62%)]\tLoss: 0.036158\n",
      "Train Epoch: 31 [600/798 (75%)]\tLoss: 0.437325\n",
      "Train Epoch: 31 [700/798 (88%)]\tLoss: 0.286919\n",
      "\n",
      "Test set: Avg. loss: 0.0582, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 32 [0/798 (0%)]\tLoss: 0.523322\n",
      "Train Epoch: 32 [100/798 (12%)]\tLoss: 0.606014\n",
      "Train Epoch: 32 [200/798 (25%)]\tLoss: 0.360078\n",
      "Train Epoch: 32 [300/798 (38%)]\tLoss: 0.285955\n",
      "Train Epoch: 32 [400/798 (50%)]\tLoss: 0.256226\n",
      "Train Epoch: 32 [500/798 (62%)]\tLoss: 0.350665\n",
      "Train Epoch: 32 [600/798 (75%)]\tLoss: 0.175975\n",
      "Train Epoch: 32 [700/798 (88%)]\tLoss: 0.472417\n",
      "\n",
      "Test set: Avg. loss: 0.0883, Accuracy: 194/200 (97%)\n",
      "\n",
      "Train Epoch: 33 [0/798 (0%)]\tLoss: 0.384267\n",
      "Train Epoch: 33 [100/798 (12%)]\tLoss: 0.083217\n",
      "Train Epoch: 33 [200/798 (25%)]\tLoss: 0.544881\n",
      "Train Epoch: 33 [300/798 (38%)]\tLoss: 0.140110\n",
      "Train Epoch: 33 [400/798 (50%)]\tLoss: 0.005338\n",
      "Train Epoch: 33 [500/798 (62%)]\tLoss: 0.073221\n",
      "Train Epoch: 33 [600/798 (75%)]\tLoss: 0.263503\n",
      "Train Epoch: 33 [700/798 (88%)]\tLoss: 0.924443\n",
      "\n",
      "Test set: Avg. loss: 0.0490, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/798 (0%)]\tLoss: 0.125822\n",
      "Train Epoch: 34 [100/798 (12%)]\tLoss: 0.173759\n",
      "Train Epoch: 34 [200/798 (25%)]\tLoss: 0.311431\n",
      "Train Epoch: 34 [300/798 (38%)]\tLoss: 0.260654\n",
      "Train Epoch: 34 [400/798 (50%)]\tLoss: 0.937754\n",
      "Train Epoch: 34 [500/798 (62%)]\tLoss: 0.212616\n",
      "Train Epoch: 34 [600/798 (75%)]\tLoss: 0.273042\n",
      "Train Epoch: 34 [700/798 (88%)]\tLoss: 0.452209\n",
      "\n",
      "Test set: Avg. loss: 0.0296, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 35 [0/798 (0%)]\tLoss: 0.113999\n",
      "Train Epoch: 35 [100/798 (12%)]\tLoss: 0.219571\n",
      "Train Epoch: 35 [200/798 (25%)]\tLoss: 0.659558\n",
      "Train Epoch: 35 [300/798 (38%)]\tLoss: 0.221098\n",
      "Train Epoch: 35 [400/798 (50%)]\tLoss: 0.819982\n",
      "Train Epoch: 35 [500/798 (62%)]\tLoss: 0.899796\n",
      "Train Epoch: 35 [600/798 (75%)]\tLoss: 0.096837\n",
      "Train Epoch: 35 [700/798 (88%)]\tLoss: 0.018290\n",
      "\n",
      "Test set: Avg. loss: 0.0419, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 36 [0/798 (0%)]\tLoss: 0.328243\n",
      "Train Epoch: 36 [100/798 (12%)]\tLoss: 0.319570\n",
      "Train Epoch: 36 [200/798 (25%)]\tLoss: 0.314211\n",
      "Train Epoch: 36 [300/798 (38%)]\tLoss: 0.118891\n",
      "Train Epoch: 36 [400/798 (50%)]\tLoss: 0.129532\n",
      "Train Epoch: 36 [500/798 (62%)]\tLoss: 0.565666\n",
      "Train Epoch: 36 [600/798 (75%)]\tLoss: 0.071503\n",
      "Train Epoch: 36 [700/798 (88%)]\tLoss: 0.035823\n",
      "\n",
      "Test set: Avg. loss: 0.0240, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 37 [0/798 (0%)]\tLoss: 0.248251\n",
      "Train Epoch: 37 [100/798 (12%)]\tLoss: 0.142208\n",
      "Train Epoch: 37 [200/798 (25%)]\tLoss: 0.212757\n",
      "Train Epoch: 37 [300/798 (38%)]\tLoss: 0.021729\n",
      "Train Epoch: 37 [400/798 (50%)]\tLoss: 0.304888\n",
      "Train Epoch: 37 [500/798 (62%)]\tLoss: 0.309499\n",
      "Train Epoch: 37 [600/798 (75%)]\tLoss: 0.432312\n",
      "Train Epoch: 37 [700/798 (88%)]\tLoss: 0.425980\n",
      "\n",
      "Test set: Avg. loss: 0.0248, Accuracy: 200/200 (100%)\n",
      "\n",
      "Train Epoch: 38 [0/798 (0%)]\tLoss: 0.079425\n",
      "Train Epoch: 38 [100/798 (12%)]\tLoss: 0.136710\n",
      "Train Epoch: 38 [200/798 (25%)]\tLoss: 0.112061\n",
      "Train Epoch: 38 [300/798 (38%)]\tLoss: 0.057521\n",
      "Train Epoch: 38 [400/798 (50%)]\tLoss: 0.147245\n",
      "Train Epoch: 38 [500/798 (62%)]\tLoss: 0.501998\n",
      "Train Epoch: 38 [600/798 (75%)]\tLoss: 0.415093\n",
      "Train Epoch: 38 [700/798 (88%)]\tLoss: 0.471009\n",
      "\n",
      "Test set: Avg. loss: 0.0286, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 39 [0/798 (0%)]\tLoss: 0.158013\n",
      "Train Epoch: 39 [100/798 (12%)]\tLoss: 0.229207\n",
      "Train Epoch: 39 [200/798 (25%)]\tLoss: 0.008930\n",
      "Train Epoch: 39 [300/798 (38%)]\tLoss: 0.433646\n",
      "Train Epoch: 39 [400/798 (50%)]\tLoss: 0.063616\n",
      "Train Epoch: 39 [500/798 (62%)]\tLoss: 0.065422\n",
      "Train Epoch: 39 [600/798 (75%)]\tLoss: 0.242068\n",
      "Train Epoch: 39 [700/798 (88%)]\tLoss: 0.166693\n",
      "\n",
      "Test set: Avg. loss: 0.0320, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 40 [0/798 (0%)]\tLoss: 0.172012\n",
      "Train Epoch: 40 [100/798 (12%)]\tLoss: 0.235032\n",
      "Train Epoch: 40 [200/798 (25%)]\tLoss: 0.045472\n",
      "Train Epoch: 40 [300/798 (38%)]\tLoss: 0.007025\n",
      "Train Epoch: 40 [400/798 (50%)]\tLoss: 0.294424\n",
      "Train Epoch: 40 [500/798 (62%)]\tLoss: 0.300024\n",
      "Train Epoch: 40 [600/798 (75%)]\tLoss: 0.198470\n",
      "Train Epoch: 40 [700/798 (88%)]\tLoss: 0.059086\n",
      "\n",
      "Test set: Avg. loss: 0.0333, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 41 [0/798 (0%)]\tLoss: 0.336920\n",
      "Train Epoch: 41 [100/798 (12%)]\tLoss: 0.014662\n",
      "Train Epoch: 41 [200/798 (25%)]\tLoss: 0.024502\n",
      "Train Epoch: 41 [300/798 (38%)]\tLoss: 0.047205\n",
      "Train Epoch: 41 [400/798 (50%)]\tLoss: 0.551611\n",
      "Train Epoch: 41 [500/798 (62%)]\tLoss: 0.036887\n",
      "Train Epoch: 41 [600/798 (75%)]\tLoss: 0.089178\n",
      "Train Epoch: 41 [700/798 (88%)]\tLoss: 0.310889\n",
      "\n",
      "Test set: Avg. loss: 0.0207, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 42 [0/798 (0%)]\tLoss: 0.062159\n",
      "Train Epoch: 42 [100/798 (12%)]\tLoss: 0.032745\n",
      "Train Epoch: 42 [200/798 (25%)]\tLoss: 0.103619\n",
      "Train Epoch: 42 [300/798 (38%)]\tLoss: 0.044865\n",
      "Train Epoch: 42 [400/798 (50%)]\tLoss: 0.068191\n",
      "Train Epoch: 42 [500/798 (62%)]\tLoss: 0.437242\n",
      "Train Epoch: 42 [600/798 (75%)]\tLoss: 0.080260\n",
      "Train Epoch: 42 [700/798 (88%)]\tLoss: 0.316675\n",
      "\n",
      "Test set: Avg. loss: 0.0353, Accuracy: 196/200 (98%)\n",
      "\n",
      "Train Epoch: 43 [0/798 (0%)]\tLoss: 0.008216\n",
      "Train Epoch: 43 [100/798 (12%)]\tLoss: 0.157911\n",
      "Train Epoch: 43 [200/798 (25%)]\tLoss: 0.540152\n",
      "Train Epoch: 43 [300/798 (38%)]\tLoss: 0.068926\n",
      "Train Epoch: 43 [400/798 (50%)]\tLoss: 0.038215\n",
      "Train Epoch: 43 [500/798 (62%)]\tLoss: 0.336303\n",
      "Train Epoch: 43 [600/798 (75%)]\tLoss: 0.072312\n",
      "Train Epoch: 43 [700/798 (88%)]\tLoss: 0.444800\n",
      "\n",
      "Test set: Avg. loss: 0.0357, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 44 [0/798 (0%)]\tLoss: 0.034913\n",
      "Train Epoch: 44 [100/798 (12%)]\tLoss: 0.161425\n",
      "Train Epoch: 44 [200/798 (25%)]\tLoss: 0.202341\n",
      "Train Epoch: 44 [300/798 (38%)]\tLoss: 0.132484\n",
      "Train Epoch: 44 [400/798 (50%)]\tLoss: 0.336609\n",
      "Train Epoch: 44 [500/798 (62%)]\tLoss: 0.094707\n",
      "Train Epoch: 44 [600/798 (75%)]\tLoss: 0.114543\n",
      "Train Epoch: 44 [700/798 (88%)]\tLoss: 0.513039\n",
      "\n",
      "Test set: Avg. loss: 0.0307, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 45 [0/798 (0%)]\tLoss: 0.351732\n",
      "Train Epoch: 45 [100/798 (12%)]\tLoss: 0.163902\n",
      "Train Epoch: 45 [200/798 (25%)]\tLoss: 0.059297\n",
      "Train Epoch: 45 [300/798 (38%)]\tLoss: 0.549238\n",
      "Train Epoch: 45 [400/798 (50%)]\tLoss: 0.403955\n",
      "Train Epoch: 45 [500/798 (62%)]\tLoss: 0.020940\n",
      "Train Epoch: 45 [600/798 (75%)]\tLoss: 0.350066\n",
      "Train Epoch: 45 [700/798 (88%)]\tLoss: 0.279097\n",
      "\n",
      "Test set: Avg. loss: 0.0229, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 46 [0/798 (0%)]\tLoss: 0.044684\n",
      "Train Epoch: 46 [100/798 (12%)]\tLoss: 0.282069\n",
      "Train Epoch: 46 [200/798 (25%)]\tLoss: 0.046887\n",
      "Train Epoch: 46 [300/798 (38%)]\tLoss: 0.234248\n",
      "Train Epoch: 46 [400/798 (50%)]\tLoss: 0.053834\n",
      "Train Epoch: 46 [500/798 (62%)]\tLoss: 0.304823\n",
      "Train Epoch: 46 [600/798 (75%)]\tLoss: 0.247465\n",
      "Train Epoch: 46 [700/798 (88%)]\tLoss: 0.028561\n",
      "\n",
      "Test set: Avg. loss: 0.0260, Accuracy: 198/200 (99%)\n",
      "\n",
      "Train Epoch: 47 [0/798 (0%)]\tLoss: 0.296536\n",
      "Train Epoch: 47 [100/798 (12%)]\tLoss: 0.121515\n",
      "Train Epoch: 47 [200/798 (25%)]\tLoss: 0.131668\n",
      "Train Epoch: 47 [300/798 (38%)]\tLoss: 0.264085\n",
      "Train Epoch: 47 [400/798 (50%)]\tLoss: 0.299653\n",
      "Train Epoch: 47 [500/798 (62%)]\tLoss: 0.522466\n",
      "Train Epoch: 47 [600/798 (75%)]\tLoss: 0.037414\n",
      "Train Epoch: 47 [700/798 (88%)]\tLoss: 0.119573\n",
      "\n",
      "Test set: Avg. loss: 0.0397, Accuracy: 197/200 (98%)\n",
      "\n",
      "Train Epoch: 48 [0/798 (0%)]\tLoss: 0.147935\n",
      "Train Epoch: 48 [100/798 (12%)]\tLoss: 0.064375\n",
      "Train Epoch: 48 [200/798 (25%)]\tLoss: 0.003113\n",
      "Train Epoch: 48 [300/798 (38%)]\tLoss: 0.243016\n",
      "Train Epoch: 48 [400/798 (50%)]\tLoss: 0.022243\n",
      "Train Epoch: 48 [500/798 (62%)]\tLoss: 0.206361\n",
      "Train Epoch: 48 [600/798 (75%)]\tLoss: 0.159728\n",
      "Train Epoch: 48 [700/798 (88%)]\tLoss: 0.513225\n",
      "\n",
      "Test set: Avg. loss: 0.0136, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 49 [0/798 (0%)]\tLoss: 0.169956\n",
      "Train Epoch: 49 [100/798 (12%)]\tLoss: 0.149962\n",
      "Train Epoch: 49 [200/798 (25%)]\tLoss: 0.658130\n",
      "Train Epoch: 49 [300/798 (38%)]\tLoss: 0.100894\n",
      "Train Epoch: 49 [400/798 (50%)]\tLoss: 0.017813\n",
      "Train Epoch: 49 [500/798 (62%)]\tLoss: 0.060635\n",
      "Train Epoch: 49 [600/798 (75%)]\tLoss: 0.067234\n",
      "Train Epoch: 49 [700/798 (88%)]\tLoss: 0.033534\n",
      "\n",
      "Test set: Avg. loss: 0.0243, Accuracy: 199/200 (100%)\n",
      "\n",
      "Train Epoch: 50 [0/798 (0%)]\tLoss: 0.016504\n",
      "Train Epoch: 50 [100/798 (12%)]\tLoss: 0.327888\n",
      "Train Epoch: 50 [200/798 (25%)]\tLoss: 0.129882\n",
      "Train Epoch: 50 [300/798 (38%)]\tLoss: 0.129395\n",
      "Train Epoch: 50 [400/798 (50%)]\tLoss: 0.782361\n",
      "Train Epoch: 50 [500/798 (62%)]\tLoss: 0.403197\n",
      "Train Epoch: 50 [600/798 (75%)]\tLoss: 0.347169\n",
      "Train Epoch: 50 [700/798 (88%)]\tLoss: 0.074160\n",
      "\n",
      "Test set: Avg. loss: 0.0423, Accuracy: 197/200 (98%)\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0423, Accuracy: 197/200 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network, optimizer = get_model()\n",
    "train_loader, test_loader = get_dataloaders_splits(data)\n",
    "result, model = training_experiment(50, network, optimizer, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=60, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.5105,  1.5105,  1.5105,  ...,  1.5105,  1.5105,  1.5105],\n",
       "          [ 1.5105,  1.5105,  1.5105,  ...,  1.5105,  1.5105,  1.5105],\n",
       "          [ 1.5526,  1.5470,  1.5547,  ...,  1.5105,  1.5105,  1.5105],\n",
       "          ...,\n",
       "          [ 1.5868,  1.5868,  1.5868,  ...,  1.6153,  1.6265,  1.6282],\n",
       "          [ 1.5868,  1.5868,  1.5868,  ...,  1.5758,  1.5815,  1.5759],\n",
       "          [ 1.5708,  1.5503,  1.5497,  ...,  1.5861,  1.5865,  1.5868]],\n",
       "\n",
       "         [[ 1.3832,  1.3832,  1.3832,  ...,  1.3832,  1.3832,  1.3832],\n",
       "          [ 1.3832,  1.3832,  1.3832,  ...,  1.3832,  1.3832,  1.3832],\n",
       "          [ 1.4254,  1.4197,  1.4274,  ...,  1.3832,  1.3832,  1.3832],\n",
       "          ...,\n",
       "          [ 1.4468,  1.4468,  1.4468,  ...,  1.4880,  1.4993,  1.5009],\n",
       "          [ 1.4468,  1.4468,  1.4468,  ...,  1.4485,  1.4542,  1.4486],\n",
       "          [ 1.4485,  1.4588,  1.4766,  ...,  1.4468,  1.4473,  1.4476]],\n",
       "\n",
       "         [[ 1.4341,  1.4341,  1.4341,  ...,  1.4341,  1.4341,  1.4341],\n",
       "          [ 1.4341,  1.4341,  1.4341,  ...,  1.4341,  1.4341,  1.4341],\n",
       "          [ 1.4763,  1.4706,  1.4783,  ...,  1.4341,  1.4341,  1.4341],\n",
       "          ...,\n",
       "          [ 1.5359,  1.5359,  1.5359,  ...,  1.5390,  1.5502,  1.5518],\n",
       "          [ 1.5359,  1.5359,  1.5359,  ...,  1.4994,  1.5051,  1.4995],\n",
       "          [ 1.4381,  1.4381,  1.4888,  ...,  1.5335,  1.5340,  1.5343]]],\n",
       "\n",
       "\n",
       "        [[[ 0.9504,  0.9504,  0.9504,  ...,  1.3840,  1.3832,  1.3832],\n",
       "          [ 0.9504,  0.9504,  0.9504,  ...,  1.2559,  1.3119,  1.3789],\n",
       "          [ 0.9390,  0.9617,  0.9828,  ...,  1.0689,  0.9946,  0.9253],\n",
       "          ...,\n",
       "          [ 0.4848,  0.6324,  0.6820,  ...,  1.3583,  1.1527,  0.6143],\n",
       "          [ 0.7010,  0.7512,  0.8297,  ...,  0.7837,  0.8199,  0.8469],\n",
       "          [ 0.8540,  0.9028,  0.9428,  ...,  0.8730,  0.9026,  0.9550]],\n",
       "\n",
       "         [[ 0.9886,  0.9886,  0.9886,  ...,  1.2440,  1.2432,  1.2432],\n",
       "          [ 0.9886,  0.9886,  0.9886,  ...,  1.1159,  1.1719,  1.2389],\n",
       "          [ 0.9135,  0.9363,  0.9573,  ...,  1.0052,  0.9310,  0.8617],\n",
       "          ...,\n",
       "          [ 0.4204,  0.5680,  0.6176,  ...,  1.2947,  1.1038,  0.5761],\n",
       "          [ 0.6501,  0.7002,  0.7788,  ...,  0.7455,  0.8038,  0.8469],\n",
       "          [ 0.8285,  0.8774,  0.9173,  ...,  0.8730,  0.9039,  0.9574]],\n",
       "\n",
       "         [[ 0.8868,  0.8868,  0.8868,  ...,  1.2058,  1.2050,  1.2050],\n",
       "          [ 0.8868,  0.8868,  0.8868,  ...,  1.0777,  1.1337,  1.2007],\n",
       "          [ 0.8626,  0.8854,  0.9064,  ...,  0.9925,  0.9182,  0.8490],\n",
       "          ...,\n",
       "          [ 0.1396,  0.2871,  0.3368,  ...,  1.1165,  0.9182,  0.3852],\n",
       "          [ 0.3828,  0.4329,  0.5115,  ...,  0.5546,  0.6055,  0.6433],\n",
       "          [ 0.5739,  0.6228,  0.6628,  ...,  0.6948,  0.7251,  0.7780]]],\n",
       "\n",
       "\n",
       "        [[[-0.0625, -0.1093, -0.1331,  ...,  0.0666,  0.1617,  0.2406],\n",
       "          [-0.0795, -0.1153, -0.1387,  ...,  0.1659,  0.2226,  0.2687],\n",
       "          [-0.0873, -0.1698, -0.2245,  ...,  0.1671,  0.2127,  0.2465],\n",
       "          ...,\n",
       "          [ 0.1788,  0.1730,  0.1701,  ...,  0.1819,  0.1929,  0.1978],\n",
       "          [ 0.2031,  0.1812,  0.1901,  ...,  0.1341,  0.1430,  0.1539],\n",
       "          [ 0.1814,  0.1486,  0.1486,  ...,  0.1053,  0.1157,  0.1213]],\n",
       "\n",
       "         [[-0.2753, -0.3002, -0.3241,  ..., -0.2325, -0.1819, -0.1797],\n",
       "          [-0.2924, -0.3062, -0.3296,  ..., -0.1332, -0.1211, -0.1516],\n",
       "          [-0.3002, -0.3608, -0.4137,  ..., -0.1320, -0.1310, -0.1532],\n",
       "          ...,\n",
       "          [-0.1357, -0.1723, -0.1935,  ..., -0.0771, -0.1023, -0.1829],\n",
       "          [-0.2261, -0.2261, -0.2350,  ..., -0.1829, -0.2007, -0.2116],\n",
       "          [-0.2842, -0.2842, -0.2842,  ..., -0.2244, -0.2407, -0.2460]],\n",
       "\n",
       "         [[-0.3825, -0.4242, -0.4242,  ..., -0.3305, -0.2710, -0.2359],\n",
       "          [-0.3975, -0.4242, -0.4242,  ..., -0.2312, -0.2102, -0.2078],\n",
       "          [-0.4023, -0.4242, -0.4242,  ..., -0.2062, -0.1962, -0.1959],\n",
       "          ...,\n",
       "          [-0.2088, -0.2351, -0.2474,  ..., -0.2490, -0.2653, -0.3138],\n",
       "          [-0.2534, -0.2643, -0.2643,  ..., -0.2554, -0.2643, -0.2862],\n",
       "          [-0.2987, -0.3097, -0.3097,  ..., -0.2587, -0.2661, -0.2934]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 1.3575,  1.4983,  1.6492,  ...,  2.2097,  2.2105,  2.2653],\n",
       "          [ 1.3575,  1.4983,  1.6492,  ...,  2.1888,  2.2105,  2.2653],\n",
       "          [ 1.2868,  1.3659,  1.4386,  ...,  2.2075,  2.1986,  2.2533],\n",
       "          ...,\n",
       "          [ 1.3702,  1.4625,  1.5330,  ...,  2.3564,  2.3700,  2.4196],\n",
       "          [ 1.2432,  1.2856,  1.3343,  ...,  2.4618,  2.4707,  2.4847],\n",
       "          [ 1.3231,  1.3649,  1.4110,  ...,  2.4727,  2.4906,  2.4916]],\n",
       "\n",
       "         [[ 1.3448,  1.4962,  1.6619,  ...,  2.2224,  2.2233,  2.2780],\n",
       "          [ 1.3448,  1.4962,  1.6619,  ...,  2.2015,  2.2233,  2.2780],\n",
       "          [ 1.2741,  1.3639,  1.4513,  ...,  2.2381,  2.2292,  2.2840],\n",
       "          ...,\n",
       "          [ 1.3575,  1.4659,  1.5584,  ...,  2.3691,  2.3828,  2.4324],\n",
       "          [ 1.2396,  1.2942,  1.3598,  ...,  2.4745,  2.4834,  2.4974],\n",
       "          [ 1.3358,  1.3776,  1.4237,  ...,  2.4855,  2.5033,  2.5043]],\n",
       "\n",
       "         [[ 1.3829,  1.5451,  1.7256,  ...,  2.2861,  2.2869,  2.3416],\n",
       "          [ 1.3829,  1.5451,  1.7256,  ...,  2.2652,  2.2869,  2.3416],\n",
       "          [ 1.3242,  1.4147,  1.5030,  ...,  2.2958,  2.2869,  2.3416],\n",
       "          ...,\n",
       "          [ 1.3957,  1.4880,  1.5584,  ...,  2.4328,  2.4464,  2.4960],\n",
       "          [ 1.2503,  1.2889,  1.3323,  ...,  2.5381,  2.5470,  2.5611],\n",
       "          [ 1.2340,  1.2758,  1.3219,  ...,  2.5491,  2.5669,  2.5679]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0340,  0.0340,  0.0607,  ...,  0.0085,  0.0085,  0.0085],\n",
       "          [ 0.0340,  0.0340,  0.0696,  ...,  0.0493,  0.0111, -0.0314],\n",
       "          [ 0.0340,  0.0340,  0.0696,  ...,  1.3781,  0.4617,  0.0714],\n",
       "          ...,\n",
       "          [ 0.0340,  0.0393,  0.0467,  ...,  0.0289,  0.0541,  0.0814],\n",
       "          [ 0.0340,  0.0393,  0.0646,  ...,  0.1282,  0.1104,  0.1104],\n",
       "          [ 0.0340,  0.0607,  0.0887,  ...,  0.0722,  0.0722,  0.0722]],\n",
       "\n",
       "         [[-0.1696, -0.1696, -0.1786,  ..., -0.0169, -0.0169, -0.0169],\n",
       "          [-0.1696, -0.1696, -0.1696,  ...,  0.0238, -0.0144, -0.0569],\n",
       "          [-0.1824, -0.1824, -0.1824,  ...,  1.3017,  0.3853, -0.0049],\n",
       "          ...,\n",
       "          [-0.1824, -0.1770, -0.1696,  ..., -0.2218, -0.1877, -0.1605],\n",
       "          [-0.1824, -0.1770, -0.1786,  ..., -0.1136, -0.1315, -0.1315],\n",
       "          [-0.1824, -0.1556, -0.1633,  ..., -0.1824, -0.1824, -0.1714]],\n",
       "\n",
       "         [[-0.3351, -0.3351, -0.3886,  ..., -0.4115, -0.4115, -0.4115],\n",
       "          [-0.3351, -0.3351, -0.3797,  ..., -0.3708, -0.3868, -0.4242],\n",
       "          [-0.3097, -0.3097, -0.3364,  ...,  0.9835,  0.0671, -0.3232],\n",
       "          ...,\n",
       "          [-0.2842, -0.2789, -0.2893,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.2842, -0.2789, -0.2893,  ..., -0.4064, -0.4242, -0.4242],\n",
       "          [-0.2842, -0.2575, -0.2918,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "\n",
       "\n",
       "        [[[ 0.8486,  0.8486,  0.8486,  ...,  0.8480,  0.8474,  0.8467],\n",
       "          [ 0.8486,  0.8486,  0.8486,  ...,  0.7531,  0.7265,  0.7260],\n",
       "          [ 0.8446,  0.8446,  0.8446,  ...,  0.7267,  0.7058,  0.7266],\n",
       "          ...,\n",
       "          [ 1.2814,  1.2546,  1.1821,  ...,  0.8716,  0.8213,  0.7957],\n",
       "          [ 1.2798,  1.2431,  1.1706,  ...,  0.8104,  0.8104,  0.8104],\n",
       "          [ 1.2796,  1.2471,  1.1995,  ...,  1.0252,  1.0257,  1.0366]],\n",
       "\n",
       "         [[ 0.5177,  0.5177,  0.5177,  ...,  0.5298,  0.5440,  0.5540],\n",
       "          [ 0.5177,  0.5177,  0.5177,  ...,  0.4349,  0.4231,  0.4333],\n",
       "          [ 0.5049,  0.5066,  0.5089,  ...,  0.4271,  0.4211,  0.4525],\n",
       "          ...,\n",
       "          [ 1.0013,  0.9907,  0.9403,  ...,  0.6298,  0.5868,  0.5666],\n",
       "          [ 0.9997,  0.9791,  0.9287,  ...,  0.5686,  0.5686,  0.5686],\n",
       "          [ 0.9996,  0.9831,  0.9577,  ...,  0.7452,  0.7530,  0.7693]],\n",
       "\n",
       "         [[ 0.3649,  0.3649,  0.3649,  ...,  0.3134,  0.2390,  0.1849],\n",
       "          [ 0.3649,  0.3649,  0.3649,  ...,  0.2185,  0.1181,  0.0642],\n",
       "          [ 0.4238,  0.4188,  0.4119,  ...,  0.1157,  0.0210, -0.0117],\n",
       "          ...,\n",
       "          [ 0.5177,  0.5230,  0.4948,  ...,  0.1588,  0.0790,  0.0320],\n",
       "          [ 0.5161,  0.5115,  0.4832,  ...,  0.0976,  0.0829,  0.0722],\n",
       "          [ 0.5159,  0.5048,  0.4867,  ...,  0.2615,  0.2472,  0.2475]]]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464 µs ± 5.69 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../weights/ocr_v3.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_input = scaled[0, :].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.7 ms ± 89.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "clf.predict(rf_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ok, let's use the conv model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pigeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
